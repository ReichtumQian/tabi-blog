{"fields":["title","description","path","body"],"pipeline":["trimmer-zh","stopWordFilter-zh","stemmer-zh"],"ref":"id","version":"0.9.5","index":{"body":{"root":{"docs":{},"df":0,"A":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":4.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":3.1622776601683795}},"df":13,"B":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1},"D":{"docs":{},"df":0,"O":{"docs":{},"df":0,"P":{"docs":{},"df":0,"T":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951}},"df":1}}}},"I":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2},"L":{"docs":{},"df":0,"B":{"docs":{},"df":0,"E":{"docs":{},"df":0,"R":{"docs":{},"df":0,"T":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":1}}}}},"P":{"docs":{},"df":0,"I":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}},"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951}},"df":1}}}}}}},"c":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}}}}}}}},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":2,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.23606797749979}},"df":1}}}}}}}}}},"d":{"docs":{},"df":0,"E":{"docs":{},"df":0,"M":{"docs":{},"df":0,"A":{"docs":{},"df":0,"M":{"docs":{},"df":0,"i":{"docs":{},"df":0,"x":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.0}},"df":1}}}}}},"a":{"docs":{},"df":0,"f":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}}}}}},"m":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adam/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":3.4641016151377544},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":2.449489742783178}},"df":5,"W":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":3.4641016151377544}},"df":4}},"p":{"docs":{},"df":0,"t":{"docs":{},"df":0,"F":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":2.23606797749979}},"df":1}}}}}},"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":2}}}}},"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adam/":{"tf":1.0}},"df":1}}}}}},"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}}},"j":{"docs":{},"df":0,"o":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1}}}}}},"f":{"docs":{},"df":0,"f":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}},"l":{"docs":{},"df":0,"g":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.4142135623730951}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951}},"df":1}}}}}}}},"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"n":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}},"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}}},"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}},"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"f":{"docs":{},"df":0,"y":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}}}},"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":2,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":4.123105625617661}},"df":1}}}}},"l":{"docs":{},"df":0,"y":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":2}}}}}},"n":{"docs":{},"df":0,"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}}}}},"p":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}}}}},"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":1}}}}}}}}},"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951}},"df":2,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}},"x":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":2},"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.4142135623730951}},"df":2}}}}}}}}}}}}},"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/archive/":{"tf":1.0}},"df":1}}}}},"g":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}}}}}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":1,"s":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772}},"df":2}}}},"y":{"docs":{},"df":0,"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.7320508075688772}},"df":1,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1}}}}}}}}}}}}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":2.449489742783178}},"df":3,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}}}}}}},"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1,"g":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.4142135623730951}},"df":1}}}}}}},"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}},"B":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":3.0}},"df":10,"A":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.4142135623730951}},"df":1},"B":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1},"E":{"docs":{},"df":0,"R":{"docs":{},"df":0,"T":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.7320508075688772}},"df":1}}},"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{},"df":0,"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":2}}}}}},"l":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":2.449489742783178}},"df":1}},"s":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1},"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"B":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.7320508075688772}},"df":1}}}}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}},"t":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":3,"N":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"m":{"docs":{},"df":0,"2":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1}}}}}},"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}}}}}}},"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.7320508075688772}},"df":1}}}}},"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772}},"df":1}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}}}}}},"e":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}}}}}},"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"g":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951}},"df":1}}},"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772}},"df":1}},"g":{"docs":{"https://reichtumqian.pages.dev/blog/":{"tf":1.0}},"df":1}}},"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":1}}}}}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951}},"df":1}}}}},"o":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}}}}}}}}}}},"u":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":2}},"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}},"C":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.7320508075688772}},"df":6,"I":{"docs":{},"df":0,"F":{"docs":{},"df":0,"A":{"docs":{},"df":0,"R":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}}}},"K":{"docs":{},"df":0,"A":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772}},"df":1}},"L":{"docs":{},"df":0,"I":{"docs":{},"df":0,"P":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":1}},"M":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772}},"df":1}},"N":{"docs":{},"df":0,"N":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1}},"P":{"docs":{},"df":0,"A":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.7320508075688772}},"df":1}},"S":{"docs":{},"df":0,"V":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}},"U":{"docs":{},"df":0,"D":{"docs":{},"df":0,"A":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":2}}},"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"c":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1}}}}}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"p":{"docs":{},"df":0,"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3}}}}}}}}}},"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}}}}},"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}},"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}}}},"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1}}},"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":2}}}},"r":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}},"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772}},"df":1}}}}}}}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":1}}}},"o":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":3,"d":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.4142135623730951}},"df":1}},"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2}},"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}}},"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}}}},"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}},"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}}}}}}}}}}},"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}}}}}}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}},"d":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.4142135623730951}},"df":1},"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.7320508075688772}},"df":5,"s":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1}}}}}}},"j":{"docs":{},"df":0,"u":{"docs":{},"df":0,"g":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}}}},"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":2}}}},"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}}}}}}}},"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1}},"t":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":1}}}}}}}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1}}}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}}},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"b":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3}}}}}}},"o":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.7320508075688772}},"df":6,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951}},"df":4}}}}},"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1}}}},"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":2.0}},"df":1}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}}}},"v":{"docs":{},"df":0,"2":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.4142135623730951}},"df":1}}}},"s":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":3}},"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}}}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}},"o":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":2}}}},"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"I":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"D":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}}}}}}}}}}}},"T":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}}}}}}}}}}}},"x":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951}},"df":1}},"D":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":4.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":5.5677643628300215},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":3.872983346207417},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":2.6457513110645907}},"df":12,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1,"L":{"docs":{},"df":0,"o":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":3.605551275463989}},"df":2}}}}}},"T":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"A":{"docs":{},"df":0,"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":2}}}}}}}}}}}}}}}}},"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":3.7416573867739413}},"df":3,"D":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}}}}}}},"e":{"docs":{},"df":0,"b":{"docs":{},"df":0,"u":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1}}},"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":4.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772}},"df":2,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951}},"df":1}}}}},"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.4142135623730951}},"df":1}}}}}}}}},"u":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1}}}}}}},"e":{"docs":{},"df":0,"p":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}},"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":1}}}},"l":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":4.123105625617661},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.7320508075688772}},"df":6}}},"n":{"docs":{},"df":0,"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}}}}},"s":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}},"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951}},"df":1}}},"p":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}},"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}}},"i":{"docs":{},"df":0,"f":{"docs":{},"df":0,"f":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}}},"s":{"docs":{},"df":0,"c":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.4142135623730951}},"df":1}}}}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"b":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"S":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}}}}}}}}},"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":3,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}}}}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":3,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}}}}},"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.4142135623730951}},"df":1}}}}},"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":3.0}},"df":2}}},"y":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":2}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":2.23606797749979}},"df":3}}}}}}}},"E":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":4.795831523312719},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":3.605551275463989},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":4.358898943540674},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.0}},"df":6,"M":{"docs":{},"df":0,"A":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772}},"df":1}},"W":{"docs":{},"df":0,"C":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":3}},"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}},"f":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":2}}}}}}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3}}}}},"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}}}}}},"m":{"docs":{},"df":0,"b":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":2}}}}}}},"p":{"docs":{},"df":0,"i":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2}}}}}}}},"n":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":1},"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}}},"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"p":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.7320508075688772}},"df":1}}}}},"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}}}}}}}}}},"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951}},"df":1}}}},"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1}}}},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.0}},"df":3}}}}},"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"b":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1}}}}}}},"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}}}}}}},"r":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adam/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":2}}}}}}}}},"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}}}}}}},"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}}}}}},"e":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1}},"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.4142135623730951}},"df":1}}}}}}},"x":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772}},"df":1}}}}}},"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}}}},"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}}}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3}}}}}}}},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951}},"df":1}}}}}}}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}}}}},"F":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":3.4641016151377544},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":3.3166247903554},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":4.69041575982343},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.6457513110645907}},"df":4,"F":{"docs":{},"df":0,"N":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":2}},"P":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1},"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":6,"b":{"docs":{},"df":0,"o":{"docs":{},"df":0,"o":{"docs":{},"df":0,"k":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}}}}}},"l":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":3}}},"s":{"docs":{},"df":0,"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"M":{"docs":{},"df":0,"N":{"docs":{},"df":0,"I":{"docs":{},"df":0,"S":{"docs":{},"df":0,"T":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1}}}}}}}}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}}},"e":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.7320508075688772}},"df":5,"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}}}}}}}},"r":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}},"s":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":4.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":4}}}},"x":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":4.358898943540674}},"df":1}}}}}},"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951}},"df":1}}}},"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":3,"g":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.4142135623730951}},"df":1,"t":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.23606797749979}},"df":1},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":2.0}},"df":5}}}}}}},"m":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2}}}}}}}},"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}}},"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":3}}}}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"w":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.0}},"df":1}}}}}}},"e":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772}},"df":1}}},"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":2}},"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":5,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":3}}}}}}}},"r":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}}},"G":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.7320508075688772}},"df":1,"L":{"docs":{},"df":0,"U":{"docs":{},"df":0,"E":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":1}}},"P":{"docs":{},"df":0,"T":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1},"U":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":3}},"R":{"docs":{},"df":0,"P":{"docs":{},"df":0,"O":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1}}},"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951}},"df":1}}}}}}},"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1,"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}}},"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1}}}}},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}}}}},"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}},"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"H":{"docs":{},"df":0,"u":{"docs":{},"df":0,"b":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1}}},"h":{"docs":{},"df":0,"u":{"docs":{},"df":0,"b":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}}},"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"b":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951}},"df":1}}}}},"o":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{},"df":0,"S":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}}}}}},"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":3}}}}},"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1}}},"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951}},"df":1}}}}},"p":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.4142135623730951}},"df":1}}},"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"p":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}}}}}},"H":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":3.0}},"df":7,"J":{"docs":{},"df":0,"B":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.23606797749979}},"df":1}},"a":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":1}}}}}},"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.7320508075688772}},"df":3}}}}}}}}},"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}},"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,"d":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"f":{"docs":{},"df":0,"f":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.0}},"df":1}}}}}}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1},"v":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":2.6457513110645907}},"df":1}}},"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}}},"r":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951}},"df":6,"a":{"docs":{},"df":0,"f":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}}},"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.7320508075688772}},"df":1}}}}}},"f":{"docs":{},"df":0,"A":{"docs":{},"df":0,"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"P":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}},"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}}}}},"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"p":{"docs":{},"df":0,"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}}}}}}}},"o":{"docs":{},"df":0,"k":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}}},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}},"w":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":1,"e":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}}}}}},"u":{"docs":{},"df":0,"b":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":2},"g":{"docs":{},"df":0,"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":6}}}}}},"y":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}},"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1}}}}}}}}}},"I":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":3,"D":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":3},"L":{"docs":{},"df":0,"S":{"docs":{},"df":0,"V":{"docs":{},"df":0,"R":{"docs":{},"df":0,"C":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951}},"df":1}}}}},"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}},"y":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772}},"df":1}}}}},"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1}}}}}}},"f":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772}},"df":1},"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1,"F":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}}}}}},"N":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951}},"df":1}}}}}},"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}},"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}}}}}}}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}}}}}}},"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}},"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":6,"c":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}},"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0}},"df":1}}}}}}}}},"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":1},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":3}}}}}}}}},"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1,"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":1}}}}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":1}}}}}}}},"j":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}}}}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772}},"df":1}}}}}},"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0}},"df":1}}}}}}}}},"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":6}}}}}}}}}},"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":2}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951}},"df":1}}}}}}}},"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"u":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.4142135623730951}},"df":1}}}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}}}}}}}},"J":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.7320508075688772}},"df":5,"P":{"docs":{},"df":0,"E":{"docs":{},"df":0,"G":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951}},"df":1}}},"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"b":{"docs":{},"df":0,"i":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1,"a":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}}}}}}}},"K":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":3.0}},"df":6,"L":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":3.4641016151377544},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":5.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":5.196152422706632}},"df":3},"T":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1},"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951}},"df":1}}}}},"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"J":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}}}}}}}}}},"r":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":2}}}}},"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"b":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1}}}}}}}},"L":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":3.872983346207417},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":3.3166247903554},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":4.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":3.4641016151377544},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.449489742783178}},"df":14,"L":{"docs":{},"df":0,"M":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":5,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.0}},"df":1}}},"M":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}},"N":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.7320508075688772}},"df":1},"P":{"docs":{},"df":0,"C":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":2.0}},"df":2}},"T":{"docs":{},"df":0,"I":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.7320508075688772}},"df":1},"V":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.4142135623730951}},"df":1}},"a":{"docs":{},"df":0,"S":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":2.8284271247461903}},"df":1}}}}},"b":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}}},"g":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":3},"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1}}}}}}}},"m":{"docs":{},"df":0,"b":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951}},"df":1}}}},"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":4}}}}}},"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.0}},"df":2,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1},"s":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1}}}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/":{"tf":1.0}},"df":1}}}},"w":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2},"y":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":2}}}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1},"r":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.7320508075688772}},"df":1,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":2.0}},"df":8}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}},"f":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1}}}}},"s":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":2}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":5},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":2}}}},"i":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772}},"df":1},"f":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"y":{"docs":{},"df":0,"c":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}}}}}}},"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.4142135623730951}},"df":1}}}}}}},"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":3}}}}}}}},"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":5,"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.4142135623730951}},"df":2}}}}}}}},"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.8284271247461903}},"df":1}},"p":{"docs":{},"df":0,"s":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"z":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951}},"df":1}}}}}}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.0}},"df":2}}}},"o":{"docs":{},"df":0,"R":{"docs":{},"df":0,"A":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":2.8284271247461903}},"df":4}},"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}},"g":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951}},"df":1,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}}}},"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}}}}}}}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"C":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":1}}}}}}}},"s":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":2.8284271247461903}},"df":1}},"w":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":2}},"y":{"docs":{},"df":0,"a":{"docs":{},"df":0,"p":{"docs":{},"df":0,"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"o":{"docs":{},"df":0,"v":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":3.0}},"df":2}}}}}}}},"M":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":3.7416573867739413},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":4.242640687119285},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.7320508075688772}},"df":5,"A":{"docs":{},"df":0,"E":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.7320508075688772}},"df":1},"R":{"docs":{},"df":0,"S":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":3.0}},"df":1}},"X":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"H":{"docs":{},"df":0,"S":{"docs":{},"df":0,"A":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951}},"df":1}}},"I":{"docs":{},"df":0,"N":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.0}},"df":1}},"L":{"docs":{},"df":0,"E":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951}},"df":2},"M":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1},"P":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}},"N":{"docs":{},"df":0,"I":{"docs":{},"df":0,"S":{"docs":{},"df":0,"T":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}},"S":{"docs":{},"df":0,"A":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.7320508075688772}},"df":2}},"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":3}},"m":{"docs":{},"df":0,"b":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1,"a":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.7320508075688772}},"df":1}}},"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"u":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}},"i":{"docs":{},"df":0,"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}},"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2}},"p":{"docs":{},"df":0,"p":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}}}}}},"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1}}}}}},"s":{"docs":{},"df":0,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}}}},"t":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"x":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":2}}}},"x":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":1}}}}}}},"u":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":2}}}}}},"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}}},"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}},"m":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}}}}}}},"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951}},"df":6,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"g":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2}}}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"F":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}}}}},"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.7320508075688772}},"df":1}}}}},"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1}}}}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}},"u":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1}}}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}},"o":{"docs":{},"df":0,"E":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951}},"df":1}},"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3,"A":{"docs":{},"df":0,"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":2}}}}}}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951}},"df":1}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3}}},"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":2.449489742783178}},"df":2,"L":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}}}}}}}},"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adam/":{"tf":1.0}},"df":1,"u":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2}}}}}},"r":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}},"s":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}},"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.7320508075688772}},"df":3,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":1}}}}}}}},"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":4.123105625617661},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":3.4641016151377544}},"df":2,"N":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"1":{"docs":{},"df":0,"D":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}},"W":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"A":{"docs":{},"df":0,"u":{"docs":{},"df":0,"x":{"docs":{},"df":0,"A":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}}}}}}}}}}}}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.4142135623730951}},"df":1}}}}}}},"N":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":3.4641016151377544}},"df":5,"L":{"docs":{},"df":0,"P":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}},"T":{"docs":{},"df":0,"K":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}},"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}},"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1}}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}},"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}},"t":{"docs":{},"df":0,"w":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.4142135623730951}},"df":1}}}}}},"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":2}}}}},"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.7320508075688772}},"df":1},"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.7320508075688772}},"df":1}}}}}}},"r":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":2}}}}}}},"p":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1},"s":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1},"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}},"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}}}}}},"O":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":3,"D":{"docs":{},"df":0,"E":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}},"b":{"docs":{},"df":0,"j":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":5}}}}}}}},"f":{"docs":{},"df":0,"f":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.23606797749979}},"df":1,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}},"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1}}}}}},"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"g":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":3.4641016151377544}},"df":1}}}},"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":2,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1},"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.23606797749979}},"df":1}}}}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1,"V":{"docs":{},"df":0,"L":{"docs":{},"df":0,"A":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1},"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":2}}}},"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772}},"df":1}}}}}},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.23606797749979}},"df":5,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":2}}}}},"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1}}}}},"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951}},"df":1}}}}}}}}},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":8}}}}}}},"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"w":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}}}}},"u":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3},"t":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":1}}}}},"p":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"p":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}},"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"w":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}}}},"P":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":6.48074069840786},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":5.656854249492381},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":2.6457513110645907}},"df":7,"A":{"docs":{},"df":0,"T":{"docs":{},"df":0,"H":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}}},"D":{"docs":{},"df":0,"E":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":1}},"E":{"docs":{},"df":0,"F":{"docs":{},"df":0,"T":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}},"I":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1,"L":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"M":{"docs":{},"df":0,"P":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.449489742783178}},"df":3}},"P":{"docs":{},"df":0,"L":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"a":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":8}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":3,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3}}}}}}},"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}},"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{},"df":0,"M":{"docs":{},"df":0,"N":{"docs":{},"df":0,"I":{"docs":{},"df":0,"S":{"docs":{},"df":0,"T":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.0}},"df":1}}}}}}}},"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}}}}},"t":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}}},"e":{"docs":{},"df":0,"f":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.4142135623730951}},"df":2}},"r":{"docs":{},"df":0,"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}},"s":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}}}}},"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772}},"df":1}}},"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}}},"i":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":2.449489742783178}},"df":3},"y":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}}}},"i":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772}},"df":1,"c":{"docs":{},"df":0,"k":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}},"o":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}},"o":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":3}}},"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":3.4641016151377544}},"df":1}}}},"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"y":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2}}}}}}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1}}}}}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1}}}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951}},"df":1,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}},"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}}}}}}},"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}},"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":2.0}},"df":2}}}}}}}},"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":2}}}}}},"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1}}}}},"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":3.0}},"df":1}}},"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":3}}}}}},"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2}}},"o":{"docs":{},"df":0,"b":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}}}}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}},"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":4}}}},"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.0}},"df":1}}}},"j":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":2}}},"s":{"docs":{"https://reichtumqian.pages.dev/projects/":{"tf":1.0}},"df":1}}}}},"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.4142135623730951}},"df":2}}}}},"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}}}}},"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.23606797749979}},"df":1},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772}},"df":1}}}}}},"s":{"docs":{},"df":0,"i":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":1}},"y":{"docs":{},"df":0,"T":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":2.0}},"df":3}}}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":2.6457513110645907}},"df":2}}},"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.4142135623730951}},"df":4}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":2.449489742783178}},"df":7}}}}}}},"Q":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":4.58257569495584},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":4.242640687119285}},"df":6,"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}},"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.449489742783178}},"df":1}}}}}}}}}}},"w":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772}},"df":1}}}},"R":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":3.4641016151377544},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":6.082762530298219},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.0}},"df":17,"E":{"docs":{},"df":0,"C":{"docs":{},"df":0,"A":{"docs":{},"df":0,"D":{"docs":{},"df":0,"A":{"docs":{},"df":0,"M":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.7320508075688772}},"df":1}}}}},"P":{"docs":{},"df":0,"L":{"docs":{},"df":0,"A":{"docs":{},"df":0,"C":{"docs":{},"df":0,"E":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}},"S":{"docs":{},"df":0,"T":{"docs":{},"df":0,"O":{"docs":{},"df":0,"R":{"docs":{},"df":0,"E":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":1}}}}}},"G":{"docs":{},"df":0,"B":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1}},"I":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1},"L":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":6.164414002968976}},"df":1},"T":{"docs":{},"df":0,"N":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"a":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":2}}}}}},"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":1}}},"k":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951}},"df":4,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.0}},"df":1}}}}},"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}},"z":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772}},"df":1}}}},"e":{"docs":{},"df":0,"L":{"docs":{},"df":0,"U":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":2}},"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1}}}}}},"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}},"c":{"docs":{},"df":0,"A":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":2.0}},"df":1}}}},"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":2.0}},"df":1}}}},"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}}}}},"g":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":3.605551275463989}},"df":1}}}}}}}}}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772}},"df":1}}}}}}}}}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}}}}}},"m":{"docs":{},"df":0,"o":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772}},"df":2},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}},"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951}},"df":1}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":2}}}}}}}}}}}},"s":{"docs":{},"df":0,"N":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.7320508075688772}},"df":1}}},"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}},"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"t":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":4}}}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}},"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":2}}}}}}}},"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":3}}}}}}}}},"o":{"docs":{},"df":0,"b":{"docs":{},"df":0,"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}},"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772}},"df":1}}}},"u":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1}}},"S":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":4.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.7320508075688772}},"df":3,"A":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":1},"C":{"docs":{},"df":0,"P":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}},"F":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772}},"df":1,"T":{"docs":{"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":5.385164807134504}},"df":2}},"G":{"docs":{},"df":0,"D":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":2.23606797749979}},"df":1}},"H":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.4142135623730951}},"df":1},"O":{"docs":{},"df":0,"A":{"docs":{},"df":0,"P":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.449489742783178}},"df":1}}},"S":{"docs":{},"df":0,"H":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.7320508075688772}},"df":1}},"W":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.23606797749979}},"df":1},"a":{"docs":{},"df":0,"d":{"docs":{},"df":0,"d":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":1}}}},"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1}}}}}}},"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772}},"df":1},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951}},"df":1}}}}},"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951}},"df":1}}}}}},"i":{"docs":{},"df":0,"K":{"docs":{},"df":0,"n":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{},"df":0,"E":{"docs":{},"df":0,"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}}},"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}},"o":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":1}},"r":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":3.0}},"df":1}}}},"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":4}}}},"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}}}}}}}}},"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":4}}}}}}}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":5,"S":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"M":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}}}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1},"u":{"docs":{},"df":0,"p":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.7320508075688772}},"df":2}}}},"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"o":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}},"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}},"i":{"docs":{},"df":0,"f":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":2.0}},"df":1}}}}}}},"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772}},"df":1,"u":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.6457513110645907}},"df":1}}}},"m":{"docs":{},"df":0,"P":{"docs":{},"df":0,"O":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}},"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"E":{"docs":{},"df":0,"n":{"docs":{},"df":0,"v":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}},"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":2.0}},"df":1}}}}}}}},"z":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":2.0}},"df":4}}},"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951}},"df":1,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":2}}}}},"o":{"docs":{},"df":0,"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1,"Q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}}}}},"o":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2,"f":{"docs":{},"df":0,"t":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"x":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.7320508075688772}},"df":1}}}}},"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}},"m":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772}},"df":1}},"p":{"docs":{},"df":0,"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.449489742783178}},"df":1}}}},"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}}},"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}},"r":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}},"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}}}}}}}}},"i":{"docs":{},"df":0,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951}},"df":2}}}}},"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":2}}},"c":{"docs":{},"df":0,"k":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}},"r":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":1}},"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":3,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951}},"df":2}}}}},"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}}}}}}},"e":{"docs":{},"df":0,"p":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.7320508075688772}},"df":4,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}},"o":{"docs":{},"df":0,"p":{"docs":{},"df":0,"w":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}},"u":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.7320508075688772}},"df":1}}}}}},"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.4142135623730951}},"df":2}}}}}}},"h":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}},"f":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}}}}}}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":5.477225575051661}},"df":1}},"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}},"y":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":3}}}}}},"T":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":4.795831523312719},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":5.385164807134504},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":3.4641016151377544},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":7,"a":{"docs":{},"df":0,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":3.4641016151377544}},"df":1}}}}}},"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":2}}}}},"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}},"s":{"docs":{},"df":0,"k":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951}},"df":1}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.7320508075688772}},"df":1}}}},"r":{"docs":{},"df":0,"d":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":2.0}},"df":1}}}}}},"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":3.7416573867739413},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":2.0}},"df":6,"s":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.7320508075688772}},"df":1}}}}},"r":{"docs":{},"df":0,"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1}}}}}},"s":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":1}},"x":{"docs":{},"df":0,"t":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}}}},"h":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":3.4641016151377544},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":10,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":3},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951}},"df":1,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}},"y":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}},"r":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2,"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}}}},"s":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}},"t":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":4.0}},"df":1}},"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":2}},"i":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":4}}},"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":2}}},"o":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}}}}}}}}}},"o":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1,"A":{"docs":{},"df":0,"l":{"docs":{},"df":0,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}}},"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951}},"df":1}}}}}}}}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}},"p":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0}},"df":1},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":4.358898943540674},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":3}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951}},"df":3,"A":{"docs":{},"df":0,"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":3}}}}}}}}}}}}}},"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"f":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":4}}}}}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1}}}}}}}}}}}},"u":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":4}}},"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":5}}}}},"w":{"docs":{},"df":0,"o":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2}},"y":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"Y":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":1}}}}}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}},"U":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":3.0}},"df":4,"n":{"docs":{},"df":0,"b":{"docs":{},"df":0,"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":2}}}}}}},"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}}}}}}}}}}},"p":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}},"V":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":4.58257569495584},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":3.7416573867739413},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":4.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":4.242640687119285}},"df":7,"P":{"docs":{},"df":0,"T":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}},"S":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.4142135623730951}},"df":1,"C":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.7320508075688772}},"df":1}}}}},"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}},"u":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.7320508075688772}},"df":1}}},"r":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0}},"df":1,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.7320508075688772}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":2}}}},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1}}}}}}},"y":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1}}}}}},"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}},"r":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}}}},"u":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}},"i":{"docs":{},"df":0,"T":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":2.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}},"e":{"docs":{},"df":0,"w":{"docs":{},"df":0,"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":1}}}}}}},"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951}},"df":1}}},"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}}}}},"W":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":4.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.7320508075688772}},"df":7,"8":{"docs":{},"df":0,"A":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"S":{"docs":{},"df":0,"D":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.0}},"df":1}},"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"k":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0}},"df":1},"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951}},"df":1}},"r":{"docs":{},"df":0,"m":{"docs":{},"df":0,"u":{"docs":{},"df":0,"p":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.0}},"df":1}}}}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":3.3166247903554},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":3.3166247903554}},"df":8,"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":4.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":7,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":3.4641016151377544},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":2}}}}},"l":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/":{"tf":1.0}},"df":1}}}}}},"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1}}},"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772}},"df":1}},"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}},"k":{"docs":{},"df":0,"i":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":1}},"s":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"t":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3}}}},"X":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":6.244997998398398},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":4.123105625617661}},"df":3,"W":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"Y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.0}},"df":2},"Z":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":1,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}},"a":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":4.795831523312719},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":4.898979485566356},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":4.47213595499958},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":4.58257569495584},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":2.449489742783178}},"df":10,"b":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":2}}}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}},"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":3}}}},"c":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}},"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":1}}}},"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":2}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}}},"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":2,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":2}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}},"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":4}}}},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":4.47213595499958},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951}},"df":3,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":3.605551275463989}},"df":1}}}}}},"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}},"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adam/":{"tf":1.0}},"df":1,"w":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1}},"p":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":2}}}}},"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1},"r":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}},"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951}},"df":1}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}}},"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}}}}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}},"j":{"docs":{},"df":0,"o":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1}}}},"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":1}}}},"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1}}}}}}}},"o":{"docs":{},"df":0,"p":{"docs":{},"df":0,"t":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}},"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1}}}}}},"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}},"f":{"docs":{},"df":0,"f":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.0}},"df":2}}}},"g":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1}}}}},"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.0}},"df":1}}}},"i":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}},"l":{"docs":{},"df":0,"g":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":3}}}}}}}},"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.4142135623730951}},"df":3}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}}}},"l":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":7,"o":{"docs":{},"df":0,"w":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}},"m":{"docs":{},"df":0,"o":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":3}}}},"p":{"docs":{},"df":0,"h":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":4.242640687119285}},"df":3}}},"s":{"docs":{},"df":0,"o":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":4}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1}}}}}}}}},"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"y":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":1}}}}},"m":{"docs":{},"df":0,"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}},"p":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":3.7416573867739413},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":3.4641016151377544},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":2.449489742783178}},"df":8,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"f":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}},"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":7,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":2.23606797749979}},"df":1}}}}},"l":{"docs":{},"df":0,"y":{"docs":{},"df":0,"z":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}},"d":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":3.3166247903554},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":5.830951894845301},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":4.58257569495584},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":4.242640687119285},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":4.795831523312719},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":4.795831523312719}},"df":11},"g":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}}},"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":2.6457513110645907}},"df":1}}}}}},"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}}}},"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1}}}}},"s":{"docs":{},"df":0,"w":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}},"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2}},"p":{"docs":{},"df":0,"p":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.4142135623730951}},"df":1,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":2}}}},"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}},"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}},"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}},"x":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":5,"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}},"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":3}}}}}}}}}}}}},"r":{"docs":{},"df":0,"b":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}},"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/archive/":{"tf":1.0}},"df":1}}}}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":3.3166247903554},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.7320508075688772}},"df":6},"g":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":8,"u":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}},"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":8,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":1}}},"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}},"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}}}},"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":5.196152422706632}},"df":10},"y":{"docs":{},"df":0,"m":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}}}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":12,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}}}}}}},"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}},"o":{"docs":{},"df":0,"g":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":2.23606797749979}},"df":1}}}},"n":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1}}}}}}}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":2},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}}},"g":{"docs":{},"df":0,"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1}}}}},"o":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}},"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}},"x":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1}}}},"b":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":5,"P":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1},"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{},"df":0,"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":4}}}}}},"l":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.4142135623730951}},"df":1}},"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":3.1622776601683795}},"df":1},"s":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":2.6457513110645907}},"df":4,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":3.3166247903554}},"df":1},"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951}},"df":1}}}}},"i":{"docs":{},"df":0,"c":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951}},"df":1}}},"t":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":3.3166247903554},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":7,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951}},"df":1}}}}}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.7320508075688772}},"df":7,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":2}}}}},"e":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}},"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.4142135623730951}},"df":7,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}}}}},"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":1},"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}},"i":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":3}}},"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772}},"df":1}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}},"e":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}}}},"s":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}},"t":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":2},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3}}},"w":{"docs":{},"df":0,"e":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.7320508075688772}},"df":4}}}}},"y":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951}},"df":1}}}}},"f":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2}}}}},"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1},"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":2,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1},"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1}}}},"g":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"p":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}},"u":{"docs":{},"df":0,"p":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}},"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.4142135623730951}},"df":2},"l":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1},"r":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}},"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1}}}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}},"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":3}},"g":{"docs":{"https://reichtumqian.pages.dev/blog/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-adam/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":44}}},"m":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951}},"df":2,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"x":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951}},"df":3}}}}}},"n":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1},"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}},"l":{"docs":{},"df":0,"d":{"docs":{},"df":0,"s":{"docs":{},"df":0,"y":{"docs":{},"df":0,"m":{"docs":{},"df":0,"b":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":5.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":7.0710678118654755}},"df":3}}}}}}}},"o":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":2}},"t":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":5}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.23606797749979}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}}}}},"u":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1,"d":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}},"g":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1},"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":2}},"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.7320508075688772}},"df":7}},"c":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":4.242640687119285},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.7320508075688772}},"df":5,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772}},"df":1}}},"l":{"docs":{},"df":0,"c":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}}}}},"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772}},"df":1,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}}}},"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":2}}}},"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.7320508075688772}},"df":7,"n":{"docs":{},"df":0,"o":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}}},"o":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0}},"df":3},"p":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1,"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}}}},"r":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1},"r":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}},"s":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.4142135623730951}},"df":2}}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"p":{"docs":{},"df":0,"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":3}}}}}}}}},"e":{"docs":{},"df":0,"g":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}}},"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}},"d":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1,"o":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.449489742783178}},"df":13,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":7}}}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1,"r":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}},"h":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1,"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1}}},"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772}},"df":2,"s":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}}}}},"r":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.0}},"df":1}}},"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{},"df":0,"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951}},"df":2}}}}}}},"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1}}},"o":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}}},"u":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951}},"df":1}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}},"s":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":4,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}}}}}}}}}}},"i":{"docs":{},"df":0,"p":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}},"m":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772}},"df":1},"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951}},"df":1}},"s":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1,"d":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1},"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2},"s":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}},"o":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":3,"d":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":2}},"e":{"docs":{},"df":0,"f":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":2.449489742783178}},"df":3,"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}}}}}}}},"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":2.6457513110645907}},"df":2}}},"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}},"u":{"docs":{},"df":0,"m":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}},"m":{"docs":{},"df":0,"b":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}}}}}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0}},"df":1}},"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3}},"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}},"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}},"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":2}}},"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}},"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951}},"df":1}}}}}}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":3}}}}},"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":4.123105625617661},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":2},"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}},"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}}}}},"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}}}}},"g":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}}}},"j":{"docs":{},"df":0,"u":{"docs":{},"df":0,"g":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}}}},"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}}},"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951}},"df":4,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2}}}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}}}},"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2}}}}}}}}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1}}}}}},"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951}},"df":1}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":4}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}},"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}}},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"b":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}},"o":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":3.605551275463989},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":5,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1}}}}},"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951}},"df":2}}}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":3}}}}},"v":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}},"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}},"x":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":1}}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}}}}}}}}},"p":{"docs":{},"df":0,"y":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}},"r":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}},"s":{"docs":{},"df":0,"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951}},"df":3}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}}}},"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.0}},"df":1}}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":4}},"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":2}},"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772}},"df":1}}}}}}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.4142135623730951}},"df":3,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}},"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":2}}}}}},"o":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2}}},"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}},"s":{"docs":{},"df":0,"v":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"u":{"docs":{},"df":0,"p":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951}},"df":1},"r":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2}}}},"s":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1}},"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3}}}}}},"d":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":3.605551275463989},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":15,"a":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1,"i":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0}},"df":3},"m":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}},"n":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1},"o":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":1},"t":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":2.0}},"df":9,"c":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":2}}}}},"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}}}}}},"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":6,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":4}}}}}}},"d":{"docs":{},"df":0,"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}}}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":7,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":3.872983346207417}},"df":2}},"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}}}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}}}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}}},"e":{"docs":{},"df":0,"p":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}},"f":{"docs":{},"df":0,"a":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":2.449489742783178}},"df":1}}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951}},"df":3,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":2}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}}}},"g":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}},"e":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}},"l":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":4.123105625617661},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":3.605551275463989}},"df":4}}},"m":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}},"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}}}}},"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0}},"df":1},"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951}},"df":4,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951}},"df":1},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951}},"df":2}}}},"s":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2}}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":2}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}}},"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":1}}}}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":1}}}}}}}},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}},"s":{"docs":{},"df":0,"c":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"b":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}}}},"p":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}},"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772}},"df":1}}}}}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}},"r":{"docs":{},"df":0,"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}}}},"v":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}}}}}}}}},"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"p":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}}}}}}}},"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":3}}}}},"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1},"o":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":5}},"f":{"docs":{},"df":0,"f":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":5,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}}}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}},"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.0}},"df":1}}}},"m":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.4142135623730951}},"df":1,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":3,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":3,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1}}}}}}}}}}}},"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":2}},"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":2.23606797749979}},"df":3,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}},"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}}}},"s":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1}}}},"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}},"o":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}},"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}},"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":1}}},"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}}}}}}}}}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772}},"df":1,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":2,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2}},"g":{"docs":{},"df":0,"u":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"b":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":3.3166247903554},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951}},"df":2,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":3}}}}}}}}}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.23606797749979}},"df":2}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}}},"o":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":5,"c":{"docs":{},"df":0,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}}}},"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":3}},"g":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1},"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}}},"n":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1},"g":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":3.605551275463989},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.449489742783178}},"df":8},"u":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}},"w":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.8284271247461903}},"df":2,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":2.0}},"df":2}}}}}}}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}}},"w":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":2}}},"i":{"docs":{},"df":0,"f":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}},"o":{"docs":{},"df":0,"p":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0}},"df":1,"y":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}}}},"u":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":9,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":1}},"i":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772}},"df":1}}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":4}}}}},"y":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":1}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.7320508075688772}},"df":3}}}}}}}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":2.8284271247461903}},"df":5,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":6}},"r":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}}},"f":{"docs":{},"df":0,"f":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}}}},"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}}}}}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}}}}},"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}}},"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}}}},"m":{"docs":{},"df":0,"b":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951}},"df":1,"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772}},"df":2,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}}},"p":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}}}},"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}},"d":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.4142135623730951}},"df":9},"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.0}},"df":1}}}}}},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}}},"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"p":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}},"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":3}}}}}}}}}},"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":2,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":2}}}},"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951}},"df":4}}}}}},"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951}},"df":1}}}}},"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"b":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1}}}}}}},"v":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}}}}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}},"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.23606797749979}},"df":2,"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}}},"s":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}}}}}}},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951}},"df":1}}}}}}},"t":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.7320508075688772}},"df":4}},"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":2,"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":2,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1},"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}}}}},"e":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.0}},"df":2}},"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":2}}}}}}}},"w":{"docs":{},"df":0,"c":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}},"x":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}},"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":6}}}}}},"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772}},"df":1}}}}}}}}}}},"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"b":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}},"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":3}}}},"p":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}}}}},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1}}}},"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}}}}}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}},"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}}}}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"r":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1}}}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}},"f":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":4.47213595499958},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":4.242640687119285},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":3.7416573867739413},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":3.605551275463989},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":5.385164807134504}},"df":14,"a":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":3,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0}},"df":2},"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}},"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}},"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}},"c":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":2}}}}},"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":3}}}}}},"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951}},"df":1,"b":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1}}}}}},"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1},"w":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}},"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}},"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":2}},"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":4}},"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":3,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":2.8284271247461903}},"df":4},"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772}},"df":1}}}},"r":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951}},"df":4}}},"s":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":2}}}},"x":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":4}},"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.7320508075688772}},"df":1}}}}}},"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2}}}},"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":2.23606797749979}},"df":2},"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"u":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1},"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":1}}}}},"l":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}},"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":2}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}},"r":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":5.656854249492381},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":3.605551275463989},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":10,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.0}},"df":3}}},"g":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":3.0}},"df":1,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":3.7416573867739413},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":2.23606797749979}},"df":4}}}}}}},"m":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}},"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":2.449489742783178}},"df":5,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}}}}}}}},"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":2}},"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}},"p":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":6.082762530298219},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":3.605551275463989},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":3.3166247903554},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":3.3166247903554},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":3.4641016151377544}},"df":18,"1":{"docs":{},"df":0,"N":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}},"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"w":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}}}}},"e":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2,"z":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}}}},"o":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":4.123105625617661},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":7},"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}}},"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}},"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":9,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":2}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":2}}}}}}},"r":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}}}}}}},"g":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":4.69041575982343},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":5.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":2.0}},"df":10,"a":{"docs":{},"df":0,"i":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":3,"n":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}},"m":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.7320508075688772}},"df":4}}},"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772}},"df":1},"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":2,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.6457513110645907}},"df":1}}}}}}}},"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":1,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":3},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772}},"df":1}}}}}}}},"q":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":2.8284271247461903}},"df":6},"t":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":1}}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}},"i":{"docs":{},"df":0,"b":{"docs":{},"df":0,"b":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951}},"df":4},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}},"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"b":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}}}}},"o":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":2}},"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":2}},"o":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1},"g":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}}}},"u":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":3}},"p":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951}},"df":1}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":4.242640687119285}},"df":2,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":4,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951}},"df":1}}}}},"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.7320508075688772}},"df":1}}}}}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}}}}},"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"p":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951}},"df":1}}}}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":6},"u":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":1}}}},"z":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}},"h":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":2.0}},"df":4,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"f":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}},"n":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1,"f":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}},"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}},"r":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772}},"df":3},"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":3.1622776601683795}},"df":4},"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2}}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1,"a":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3},"v":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0}},"df":1}}}},"f":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1},"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":4}}}}},"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"d":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}},"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"o":{"docs":{},"df":0,"m":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"p":{"docs":{},"df":0,"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951}},"df":1}}}}}}}}}}},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}},"u":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1},"w":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":2}},"u":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":2,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}},"b":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":2},"g":{"docs":{},"df":0,"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0}},"df":2,"f":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":4}}}}}}}}},"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}},"o":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1}},"y":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1,"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2}}}}}}}}}}}},"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}}}}},"i":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":5.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":3.3166247903554},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":7.14142842854285},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":3.7416573867739413},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":3.1622776601683795}},"df":12,"F":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951}},"df":1},"d":{"docs":{},"df":0,"2":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}}}}}},"e":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2},"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":3}}},"f":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":2}},"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1},"x":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":1}},"f":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.4142135623730951}},"df":2,"f":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}},"g":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.4142135623730951}},"df":1,"n":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}},"i":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951}},"df":2},"j":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":2.23606797749979}},"df":3},"k":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772}},"df":1},"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":4,"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}}}}}},"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":1}}}},"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}}},"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}}},"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}}}}},"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772}},"df":3}}}}}}},"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":3.872983346207417},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":6.708203932499369},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":3.3166247903554},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":4.242640687119285},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":3.1622776601683795}},"df":21,"2":{"docs":{},"df":0,"1":{"docs":{},"df":0,"k":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}}},"c":{"docs":{},"df":0,"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951}},"df":1},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":1}}}}}}},"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}},"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"x":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772}},"df":1}},"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.23606797749979}},"df":4}},"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1}}}}}}},"f":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":2}}}}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}}},"l":{"docs":{},"df":0,"u":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":1}}}}}},"o":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":1,"r":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}}}}}}},"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":2.23606797749979}},"df":6}}},"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1}}}}}}}},"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":1,"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":2.449489742783178}},"df":1}}}}},"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}}}}}}},"j":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}}}},"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}},"p":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":6,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951}},"df":4}}}},"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}}}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2}}}}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":10,"e":{"docs":{},"df":0,"g":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":1}}}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}},"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}}}},"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}},"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}},"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951}},"df":1}}}}}}}},"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}},"o":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":4},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":2}}}}},"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.7320508075688772}},"df":1}}}}}}},"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951}},"df":1}}}}}},"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}}}}},"o":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.4142135623730951}},"df":1},"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":3.605551275463989},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":5.5677643628300215},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":4.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":3.7416573867739413},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":3.7416573867739413},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.4142135623730951}},"df":10,"s":{"docs":{},"df":0,"u":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":6,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1},"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":2}}},"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}},"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951}},"df":1}}}}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.449489742783178}},"df":2,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"f":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}},"j":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":5.5677643628300215},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":3.3166247903554}},"df":5,"h":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.4142135623730951}},"df":1},"i":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1,"a":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":3,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1},"o":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":5},"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":2}}},"k":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772}},"df":1},"o":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3}}}}}},"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":2}}},"u":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}},"k":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":5.196152422706632},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":3.605551275463989},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":5.196152422706632},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":4.123105625617661}},"df":13,"e":{"docs":{"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":2,"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}},"r":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":2}}}}},"h":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1},"l":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":2},"n":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":2.0}},"df":2}}}}}}}},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":4}}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1},"u":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":5,"a":{"docs":{},"df":0,"i":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1}}}},"l":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1,"b":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.0}},"df":2,"2":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":4}}}},"m":{"docs":{},"df":0,"b":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":3.7416573867739413},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":5.477225575051661},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":3.7416573867739413}},"df":10}}}},"n":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2,"g":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951}},"df":2}},"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":4}}}}}},"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":4,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":3},"s":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}},"s":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1}}}}},"y":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.0}},"df":7,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":4}}}}},"d":{"docs":{},"df":0,"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.7320508075688772}},"df":5}}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":2,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2}},"r":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.7320508075688772}},"df":2,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":4.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":2.6457513110645907}},"df":7}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}}},"f":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":4.58257569495584},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":3.4641016151377544},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.449489742783178}},"df":11,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.7320508075688772}},"df":2}}}}}}},"i":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1},"n":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":2,"g":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":3}}}},"q":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":5},"s":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":2}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}},"i":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":2,"a":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":2}},"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}},"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":1}}}},"w":{"docs":{},"df":0,"e":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}}}}}}}},"k":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}}}},"m":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951}},"df":1,"i":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.7320508075688772}},"df":2}}}},"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":4,"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1}}}}}}}},"s":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.4142135623730951}},"df":1}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}}}}}},"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}},"l":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":2},"o":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}},"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1,"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.4142135623730951}},"df":1}}}},"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951}},"df":1}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}},"g":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":5.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":2.449489742783178}},"df":5,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}}},"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":2.0}},"df":2,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":2.23606797749979}},"df":2}}}},"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951}},"df":1}},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772}},"df":1}}}}}}}}}}}},"o":{"docs":{},"df":0,"p":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1}},"r":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":2}},"s":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":9}},"w":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.4142135623730951}},"df":3}},"p":{"docs":{},"df":0,"c":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1}},"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1},"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":6},"u":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":5},"o":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":2}}},"m":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":8,"a":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0}},"df":3,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.7320508075688772}},"df":1},"g":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.449489742783178}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}}},"i":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":4,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}}}},"j":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}},"k":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}},"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"u":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}},"i":{"docs":{},"df":0,"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772}},"df":1}}}}},"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}},"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"p":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772}},"df":2,"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951}},"df":1}}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}},"s":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":1}}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}}}},"t":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}},"h":{"docs":{},"df":0,"b":{"docs":{},"df":0,"b":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":4.795831523312719},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":3.605551275463989},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":5.196152422706632},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":5.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.0}},"df":19},"f":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":8.660254037844387},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":7.681145747868608},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":7.937253933193772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":3.605551275463989},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":9.273618495495704},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":5.5677643628300215},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":7}},"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":3.3166247903554},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":10.344080432788601},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":4.242640687119285},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":3.4641016151377544},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":3.0}},"df":12}}},"r":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":3.872983346207417},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":12}}},"m":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}}},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951}},"df":1}}},"x":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":5}}}},"x":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":2.449489742783178}},"df":5,"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951}},"df":1}},"i":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":1}},"u":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}},"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1}}}}},"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.4142135623730951}},"df":1}},"s":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1},"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}},"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":2}}}}}}},"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":2},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}},"m":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}},"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.0}},"df":1},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}},"y":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}}}},"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.7320508075688772}},"df":7,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":3.605551275463989},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.7320508075688772}},"df":3}}}},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":2}}}}}},"i":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":3.3166247903554}},"df":3},"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.23606797749979}},"df":9,"i":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.4142135623730951}},"df":1}}}}},"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.7320508075688772}},"df":1}}}}},"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772}},"df":1},"x":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772}},"df":2}}}}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951}},"df":2,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1}}}},"u":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}},"r":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}}}},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}},"k":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}}},"l":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}},"l":{"docs":{},"df":0,"p":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772}},"df":1}},"m":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1},"o":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":3.3166247903554},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":3.4641016151377544},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":3.3166247903554},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":3.1622776601683795}},"df":12,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":3}},"r":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}},"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":2}}}}},"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1},"u":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772}},"df":2}}}}}},"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.4142135623730951}},"df":1}}}}},"r":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3}},"s":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}},"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":2}},"l":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":2,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2},"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":2}}}}}}}},"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":2.449489742783178}},"df":1}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":4.123105625617661}},"df":1}}}}}},"y":{"docs":{"https://reichtumqian.pages.dev/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951}},"df":2}},"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":6.855654600401044},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":13,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":3.4641016151377544},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":4.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.7320508075688772}},"df":11}}},"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}},"m":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":6,"d":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.7320508075688772}},"df":1}}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.23606797749979}},"df":1}}}}},"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951}},"df":1}},"g":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1}}}}}},"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"b":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}}},"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1}},"q":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":4},"t":{"docs":{},"df":0,"w":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.23606797749979}},"df":3,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951}},"df":2}}}}}},"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":2}}}},"w":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":4}},"m":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1},"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":3.3166247903554},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":2.6457513110645907}},"df":2},"o":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2},"r":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":3,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":2}}}}}}}}}}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":4,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}}},"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}}}},"q":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.0}},"df":1},"t":{"docs":{},"df":0,"k":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}},"u":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":5.0}},"df":1,"m":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":3,"b":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":5}}},"e":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.4142135623730951}},"df":1},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}}}}}},"o":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":3.3166247903554},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":4.898979485566356},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":3,"b":{"docs":{},"df":0,"j":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":2.23606797749979}},"df":2,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1}}}}}}}},"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}}}}}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}}},"c":{"docs":{},"df":0,"c":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}},"d":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772}},"df":1}},"f":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":3.605551275463989},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":5.477225575051661},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":4.795831523312719},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":3.7416573867739413},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":5.0990195135927845},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":5.196152422706632},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":3.3166247903554},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":4.123105625617661},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.449489742783178}},"df":13,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3}}}},"l":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":2,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":3}}}},"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":4.47213595499958},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":4.0}},"df":9,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":2,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":2}},"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}},"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":5}},"t":{"docs":{},"df":0,"o":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}},"p":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1,"e":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951}},"df":8}}}}}}}}}},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":4,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}},"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}}},"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":4,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":4.242640687119285}},"df":1}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}},"u":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0}},"df":1}}},"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951}},"df":1,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}}}}}}},"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":6,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.0}},"df":1}}}},"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":3}}},"g":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":2},"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":4}}}}}},"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"g":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}}}}}},"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":2}}}},"u":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3},"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":2,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":3.872983346207417}},"df":1}}}}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.7320508075688772}},"df":2,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2}}}}}}},"u":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":9,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":4}}}}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}},"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}},"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"p":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951}},"df":1}}}},"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772}},"df":1}}},"w":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}}}}}}}},"w":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1}}},"p":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":7.745966692414834},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":3.605551275463989},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":4.58257569495584},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":3.3166247903554},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.4142135623730951}},"df":9,"H":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0}},"df":1},"M":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951}},"df":1},"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}},"w":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951}},"df":1}}}}}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}},"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}}},"m":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.7320508075688772}},"df":1,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.7320508075688772}},"df":7,"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":3.4641016151377544},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":5}}}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}}}},"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1}}},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":7.3484692283495345},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":4.242640687119285},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":4.69041575982343},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":4.898979485566356}},"df":7,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}}}},"c":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}}}}}},"s":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":2}},"t":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951}},"df":2}},"h":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":3},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":2,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}},"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.4142135623730951}},"df":1}}}},"e":{"docs":{},"df":0,"f":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":2.6457513110645907}},"df":2}},"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":2.0}},"df":1}}}},"g":{"docs":{},"df":0,"z":{"docs":{},"df":0,"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}}}}}}}}}},"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":5,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}},"f":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":5}}}}}}}},"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":1}}}}}}},"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"x":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":1}}}}}}},"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}},"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"b":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1}}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}}}}}}}},"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951}},"df":1}}},"i":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.449489742783178}},"df":3},"y":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}}}},"i":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":4.358898943540674},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":3.1622776601683795}},"df":2,"n":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}}},"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}},"m":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":1},"o":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":3,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.8284271247461903}},"df":1}}}},"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":3.0}},"df":1}}}},"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}},"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":1}},"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951}},"df":1}}}}}}},"t":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/":{"tf":1.0}},"df":1}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}},"w":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":2}}}}}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.7320508075688772}},"df":3,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}}}}}}}}},"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"u":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}}},"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}},"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951}},"df":1}}},"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}},"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}},"r":{"docs":{},"df":0,"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}},"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772}},"df":2}}}}}}},"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":2.23606797749979}},"df":2}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":2.23606797749979}},"df":3}}}}}}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}},"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":3,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}}}}}},"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":1}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}},"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1}}}}}},"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}}}},"o":{"docs":{},"df":0,"b":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}},"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}}}}}}},"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3}}}},"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}},"s":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}}}}}},"d":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":2,"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":2}}}},"j":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.8284271247461903}},"df":2,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.4142135623730951}},"df":2,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":2}}},"s":{"docs":{"https://reichtumqian.pages.dev/projects/":{"tf":1.0}},"df":1}}}}},"m":{"docs":{},"df":0,"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}},"p":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}},"o":{"docs":{},"df":0,"f":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0}},"df":1}},"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}},"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}},"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":2}}}},"o":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}},"t":{"docs":{},"df":0,"o":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.7320508075688772}},"df":1}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}},"x":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}},"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.449489742783178}},"df":1}}}}}},"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}},"s":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":2,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1}}}}},"y":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":6,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":2.0}},"df":2}}},"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951}},"df":1}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":10}}}}}}},"q":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":4.358898943540674},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.0}},"df":3,"D":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1},"i":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1,"e":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1},"u":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951}},"df":1}}}},"u":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1,"a":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":3.4641016151377544},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":2.0}},"df":17,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":2.0}},"df":1}}}}}},"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":3.3166247903554}},"df":1}}}},"n":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":2,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":1}}}}}}}},"z":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":3.0}},"df":1}}}}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":1,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":1}}}}}}},"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"k":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}}},"o":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":3.7416573867739413}},"df":3}}}},"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.7320508075688772}},"df":3,"a":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":2}}}}}},"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1,"d":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1,"o":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":1,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}},"g":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951}},"df":2}}},"k":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":5,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951}},"df":1}}}}},"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":3.872983346207417},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":5,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}},"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}}}},"z":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}},"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}},"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951}},"df":2,"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}}},"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1},"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}}},"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":2.0}},"df":1,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}}}},"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}}}}}},"d":{"docs":{},"df":0,"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2}},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}}},"f":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.4142135623730951}},"df":1}}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}},"g":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}},"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}},"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":4}}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}}}}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}},"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}},"u":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1}},"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}},"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}},"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":1,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}}}}},"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"i":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}}}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":2.449489742783178}},"df":2}}}}}},"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}},"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}},"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1}}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}}}}}}},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.0}},"df":1},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}},"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":5}}},"m":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.4142135623730951}},"df":2}}}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}}},"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1}}}}}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}},"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}},"i":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1,"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":4.58257569495584},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":3.4641016151377544},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.449489742783178}},"df":11}}}},"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1},"o":{"docs":{},"df":0,"b":{"docs":{},"df":0,"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951}},"df":1}}}},"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.0}},"df":1}}},"w":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}},"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":3,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":3}}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":3.4641016151377544},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":8.717797887081348},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":3.3166247903554},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":3.4641016151377544},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.7320508075688772}},"df":11,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}}}},"i":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.23606797749979}},"df":1}},"m":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2},"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":4,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951}},"df":1}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}},"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":2}}},"y":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}}}}},"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951}},"df":1}},"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}},"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.0}},"df":2,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":4}}}}},"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{},"df":0,"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.23606797749979}},"df":2,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.0}},"df":1}}}}}},"m":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951}},"df":1}}}},"o":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":2.23606797749979}},"df":1}},"r":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":2}}},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"t":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0}},"df":1}}}}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}},"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951}},"df":3}}}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":2,"d":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1},"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}},"f":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":5}},"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}}},"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":1}}}}}}}},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":2}}}},"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":1}}}}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":8,"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"u":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772}},"df":2},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":2,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":3}}}}},"u":{"docs":{},"df":0,"p":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}},"f":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"h":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951}},"df":1,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":2}},"p":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":2}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}},"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}}},"e":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}},"i":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":8,"f":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.0}},"df":1}}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1,"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}}}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":1},"u":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1,"l":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}},"w":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":3}},"u":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":3,"f":{"docs":{},"df":0,"f":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}}}}}},"i":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":2,"g":{"docs":{},"df":0,"m":{"docs":{},"df":0,"o":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}},"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.8284271247461903}},"df":1,"i":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}}}}}}}}}}},"m":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":4.358898943540674},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":4,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}},"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}},"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}}}},"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}}}}}}}}}}},"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.23606797749979}},"df":3}}}},"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/":{"tf":1.0}},"df":1}},"x":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1},"z":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":3.3166247903554},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.4142135623730951}},"df":9,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}}}},"k":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}},"p":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}},"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}}},"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":4,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2},"s":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}},"o":{"docs":{},"df":0,"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.23606797749979}},"df":2,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}}},"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}},"u":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1}}}}}}},"m":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":4,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}},"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":1}}}}},"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":4}},"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}},"r":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1},"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}},"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":2}}}},"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}},"i":{"docs":{},"df":0,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}},"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}}}},"q":{"docs":{},"df":0,"r":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.23606797749979}},"df":1}}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}},"c":{"docs":{},"df":0,"k":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}},"g":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}},"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}}},"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.23606797749979}},"df":9},"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}}}}}}},"e":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}},"m":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1},"p":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":5}},"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1}}},"o":{"docs":{},"df":0,"p":{"docs":{},"df":0,"w":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772}},"df":1}}}}}}},"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951}},"df":1,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":2}}},"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1}}}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":2.23606797749979}},"df":1}}}}}},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}},"u":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.23606797749979}},"df":1}}},"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}},"y":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}},"u":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1,"a":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":2}},"b":{"docs":{},"df":0,"j":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":2}}}},"o":{"docs":{},"df":0,"p":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772}},"df":1}}}}}}},"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":6,"e":{"docs":{},"df":0,"q":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.23606797749979}},"df":2}}}},"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}}}}}},"c":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":2}}}}}}},"h":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":4}},"f":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772}},"df":2}}}}}}}}}},"m":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":2.0}},"df":14},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":7.416198487095663}},"df":1,"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1}}}}}}}},"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}}}}}}},"w":{"docs":{},"df":0,"e":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951}},"df":1}}},"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}}}}},"y":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":2.449489742783178}},"df":1,"h":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}}}}}}}}}}}},"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}}}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.0}},"df":2,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}}}}}}}}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":9.797958971132712},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":10.392304845413264},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":5.0990195135927845},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":4.123105625617661},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":6.244997998398398},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":6.6332495807108},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":5.477225575051661},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":4.123105625617661},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":7.3484692283495345},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":6.244997998398398},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":10.344080432788601}},"df":17,"B":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1},"a":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.4142135623730951}},"df":2},"k":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}},"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":2}}}}},"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.7320508075688772}},"df":2,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":1}}}}},"s":{"docs":{},"df":0,"k":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":3.3166247903554},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":2.6457513110645907}},"df":3,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":4.358898943540674}},"df":4}}},"u":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":4.795831523312719},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":4.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.449489742783178}},"df":5}},"c":{"docs":{},"df":0,"p":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.4142135623730951}},"df":1}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951}},"df":1,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.23606797749979}},"df":1}}}}},"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"q":{"docs":{},"df":0,"u":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}}}}},"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}},"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0}},"df":3}}}},"r":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951}},"df":1,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":3},"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.4142135623730951}},"df":1}}}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":1}}},"s":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.4142135623730951}},"df":3}},"x":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":3.4641016151377544},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":2.0}},"df":11,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}}}},"h":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":2.0}},"df":3,"a":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":4},"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":3.4641016151377544},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":4.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":8}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":5.0990195135927845},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":7.416198487095663},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":7.280109889280518},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":4.47213595499958},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":6.4031242374328485},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":8.306623862918075},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":6.324555320336759},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":7.280109889280518},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":10,"i":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":3}},"m":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2},"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":4},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}}},"r":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":4}},"s":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3}},"t":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":10.583005244258363},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":4.47213595499958},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":3.7416573867739413},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":7.483314773547883},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":6.164414002968976},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":8.06225774829855},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":3.3166247903554},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":6.324555320336759}},"df":10}},"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}},"i":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":3}},"o":{"docs":{},"df":0,"s":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":4}}}}},"u":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":1}}},"i":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":1,"l":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951}},"df":3}}},"m":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951}},"df":5,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":3.7416573867739413},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.7320508075688772}},"df":11}}},"n":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":1}}},"o":{"docs":{"https://reichtumqian.pages.dev/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":3.872983346207417},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":4.69041575982343},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":4.898979485566356},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":4.795831523312719},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":4.123105625617661},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":19,"k":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.7320508075688772}},"df":2,"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":2.0}},"df":2}}}},"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":4}},"p":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":3.4641016151377544},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":11,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.449489742783178}},"df":1}}}}}}}}},"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.7320508075688772}},"df":8,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"f":{"docs":{},"df":0,"o":{"docs":{"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":2.23606797749979}},"df":1}}}},"v":{"docs":{},"df":0,"i":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":2}}}}}}}}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.4142135623730951}},"df":1}}},"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772}},"df":1}}}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":5,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":2.0}},"df":2}}}},"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.7320508075688772}},"df":5},"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951}},"df":1}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":3.3166247903554},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.7320508075688772}},"df":6}}}}},"j":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1}}}}}}},"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"f":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.7320508075688772}},"df":1,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.4142135623730951}},"df":1}}}}},"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":2.0}},"df":4}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}}}}}}}},"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}},"l":{"docs":{"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":2.23606797749979}},"df":1},"u":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2}}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1},"u":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":2,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":4}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":3.0}},"df":5}}}}},"w":{"docs":{},"df":0,"o":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":4}},"x":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":2}},"y":{"docs":{},"df":0,"p":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}}}},"u":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":5.196152422706632},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":9.899494936611665},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":4.898979485566356},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":4.795831523312719},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":5.830951894845301}},"df":9,"J":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1},"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"b":{"docs":{},"df":0,"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":3}}}}}}},"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":3,"b":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":2.449489742783178}},"df":1}}}}},"l":{"docs":{},"df":0,"y":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}}},"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}}}}},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}},"p":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":3,"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.6457513110645907}},"df":1}}}}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":6,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1},"r":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":2.23606797749979}},"df":2},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772}},"df":1}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":4}}},"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}}}}},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":1}}}}},"v":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":6,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1,"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":3}}}}}}},"u":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}},"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":2.23606797749979}},"df":1}}}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"p":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}}}}}},"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":2}}}},"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}},"p":{"docs":{},"df":0,"h":{"docs":{},"df":0,"i":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":3.605551275463989},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":2}}},"y":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}},"s":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}},"d":{"docs":{},"df":0,"o":{"docs":{},"df":0,"t":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":2.23606797749979}},"df":1}}}},"e":{"docs":{},"df":0,"c":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.449489742783178}},"df":2,"t":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.0}},"df":6,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":2}}}}},"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}}},"r":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}},"u":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}},"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}},"i":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":2},"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}},"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}}},"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1}}}}}},"w":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":3.872983346207417}},"df":2,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}},"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":2},"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"r":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1,"u":{"docs":{},"df":0,"p":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772}},"df":1}}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772}},"df":1},"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":6,"a":{"docs":{},"df":0,"k":{"docs":{},"df":0,"l":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}},"b":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.4142135623730951}},"df":1},"i":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":4,"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":4.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":4.358898943540674},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":8,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":4.795831523312719},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":6}}}}},"n":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":7},"r":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}},"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"e":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":4},"r":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.7320508075688772}},"df":7,"a":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}},"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":4}},"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":6}}},"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"k":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"x":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}}}}}},"l":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"t":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":3.605551275463989},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":3.1622776601683795}},"df":9,"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":4}}}}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":3,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}}}}},"u":{"docs":{},"df":0,"l":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.7320508075688772}},"df":1}}}}},"x":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":6.082762530298219},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":6.48074069840786},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":6.928203230275509},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":5.656854249492381},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":6.4031242374328485},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":6.6332495807108},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":7.280109889280518},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":9.486832980505138},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":6.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":3.605551275463989},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":3.605551275463989},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":3.7416573867739413},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":7.681145747868608},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":5.744562646538029},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":5.656854249492381},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":6.244997998398398},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":8.12403840463596}},"df":23,"E":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951}},"df":1},"H":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.4142135623730951}},"df":2},"L":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951}},"df":1},"P":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1},"f":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951}},"df":1},"i":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":3,"a":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":4,"g":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1},"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951}},"df":7}}},"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"w":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.4142135623730951}},"df":1}}}}}}}}}},"u":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1,"e":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":2},"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"x":{"docs":{},"df":0,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}}},"x":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951}},"df":1}}},"y":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":4.795831523312719},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":3.4641016151377544},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":3.605551275463989},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":2.23606797749979}},"df":10,"a":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.4142135623730951}},"df":1}},"e":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"i":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1,"e":{"docs":{},"df":0,"l":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.4142135623730951}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}},"m":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":2}},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":3}},"u":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":3}},"u":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0}},"df":6,"a":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":9}}},"z":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":5.291502622129181},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":6.6332495807108},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.7320508075688772}},"df":6,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":5}}},"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1,"g":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}}},"i":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":3}}},"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}}}}},"i":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":2},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0}},"df":3}}},"u":{"docs":{},"df":0,"i":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2},"o":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0}},"df":3}}},"一":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":5,"下":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":7},"个":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":3.4641016151377544},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":3.0}},"df":29,"个":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}},"些":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":6},"份":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1},"半":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1},"块":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1},"天":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1},"套":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":2},"定":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":3},"层":{"docs":{"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":1},"批":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1},"旦":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":3},"条":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":3},"枚":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1},"样":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":7},"次":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":4},"步":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":3},"点":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":3,"点":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1}},"直":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1},"种":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":6},"系":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1,"列":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}},"组":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":3},"维":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1},"致":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":2,"性":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":2}},"般":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":18,"性":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1},"来":{"docs":{},"df":0,"说":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0}},"df":1}}},"节":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1},"起":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1},"轮":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":1},"遍":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0}},"df":1},"部":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1,"分":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"项":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":2}},"万":{"docs":{},"df":0,"能":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"三":{"docs":{},"df":0,"个":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":2},"步":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0}},"df":1},"维":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1},"者":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1}},"上":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":20,"传":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1},"升":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.4142135623730951}},"df":2},"述":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":7},"限":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0}},"df":1},"面":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":8}},"下":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":13,"划":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1,"线":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"游":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0}},"df":1},"溢":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":2},"界":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951}},"df":1},"载":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":5,"速":{"docs":{},"df":0,"度":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}}},"降":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.4142135623730951}},"df":5},"面":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":7}},"不":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":21,"了":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1},"仅":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951}},"df":1},"会":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1},"再":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951}},"df":1},"准":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1},"到":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1},"变":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":3.3166247903554},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":2.0}},"df":4,"性":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1}},"可":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1},"同":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":12},"在":{"docs":{"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":1,"乎":{"docs":{"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":1}},"够":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1},"失":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1},"妨":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1},"必":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":1,"要":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":1}},"想":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1},"是":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":6,"太":{"docs":{},"df":0,"好":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}}},"来":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1},"用":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1},"确":{"docs":{},"df":0,"定":{"docs":{},"df":0,"性":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1}}},"管":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2},"能":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":4},"行":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1},"要":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":3},"见":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1}},"与":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.0}},"df":24},"专":{"docs":{},"df":0,"家":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1},"用":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"且":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":9},"两":{"docs":{},"df":0,"个":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":15},"侧":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2},"层":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1},"步":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":1},"点":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1},"种":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":5},"者":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1}},"严":{"docs":{},"df":0,"格":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951}},"df":1},"重":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"个":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":2.23606797749979}},"df":6,"个":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}},"中":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":4.123105625617661},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":3.3166247903554},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.7320508075688772}},"df":30,"转":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1},"选":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1},"间":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":2}},"临":{"docs":{},"df":0,"时":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}},"为":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":3.3166247903554},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.23606797749979}},"df":31,"了":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":9},"什":{"docs":{},"df":0,"么":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951}},"df":2}}},"主":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1,"动":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1},"要":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":6},"观":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1,"臆":{"docs":{},"df":0,"断":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1}}}},"之":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1,"前":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.4142135623730951}},"df":2},"后":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":1},"间":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":4}},"乘":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":3,"法":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":2.0}},"df":3},"积":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":2}},"也":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":23,"就":{"docs":{},"df":0,"是":{"docs":{},"df":0,"说":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1}}}},"习":{"docs":{},"df":0,"惯":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1,"于":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}}},"乱":{"docs":{},"df":0,"跑":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1}},"事":{"docs":{},"df":0,"件":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1},"实":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1,"上":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1}},"物":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1},"项":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"二":{"docs":{},"df":0,"个":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":2},"次":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1},"维":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.4142135623730951}},"df":3},"进":{"docs":{},"df":0,"制":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":2}},"项":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":2}},"于":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":16},"互":{"docs":{},"df":0,"动":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"交":{"docs":{},"df":0,"叉":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":3.7416573867739413}},"df":1},"替":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1},"给":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}},"亦":{"docs":{},"df":0,"然":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}},"产":{"docs":{},"df":0,"生":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":5}},"人":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1,"类":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"什":{"docs":{},"df":0,"么":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":5}},"仅":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":3},"今":{"docs":{},"df":0,"天":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1}},"介":{"docs":{},"df":0,"绍":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":4}},"从":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":23,"头":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951}},"df":1,"开":{"docs":{},"df":0,"始":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}}},"而":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":6}},"仓":{"docs":{},"df":0,"库":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":2}},"代":{"docs":{},"df":0,"入":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":4},"码":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":9},"表":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}},"令":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":3},"以":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":11,"上":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1},"下":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.7320508075688772}},"df":8},"为":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1},"及":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.4142135623730951}},"df":6}},"件":{"docs":{},"df":0,"夹":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":3}},"价":{"docs":{},"df":0,"值":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}},"任":{"docs":{},"df":0,"何":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":9},"务":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":4.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":4},"意":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":5}},"仿":{"docs":{},"df":0,"照":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0}},"df":1}},"伏":{"docs":{},"df":0,"笔":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1}},"众":{"docs":{},"df":0,"所":{"docs":{},"df":0,"周":{"docs":{},"df":0,"知":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}}}},"优":{"docs":{},"df":0,"化":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":4.123105625617661},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":2.449489742783178}},"df":10},"点":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.4142135623730951}},"df":2}},"会":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":3.3166247903554},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":24},"传":{"docs":{},"df":0,"入":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951}},"df":3},"播":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":3},"给":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1},"输":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1,"速":{"docs":{},"df":0,"度":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}}},"送":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1},"递":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":3}},"估":{"docs":{},"df":0,"计":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951}},"df":2,"值":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}}},"似":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":4.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":3.3166247903554}},"df":4},"但":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":3,"是":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":14}},"位":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1,"于":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":1},"置":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":3}},"低":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2,"点":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1}},"余":{"docs":{},"df":0,"下":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1}},"作":{"docs":{},"df":0,"为":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":4},"用":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":4,"域":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":1}}},"你":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.4142135623730951}},"df":3},"使":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":3,"得":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":5},"用":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":3.7416573867739413},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":23}},"例":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":4,"如":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":20},"子":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":4}},"供":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":2},"依":{"docs":{},"df":0,"次":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1},"稀":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0}},"df":1,"记":{"docs":{},"df":0,"得":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0}},"df":1}}},"赖":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":2}},"便":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1,"捷":{"docs":{"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":1}},"保":{"docs":{},"df":0,"存":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.4142135623730951}},"df":3},"持":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":4},"证":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":3}},"信":{"docs":{},"df":0,"任":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1,"度":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1}},"号":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":5},"念":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.4142135623730951}},"df":1},"息":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":3.605551275463989},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":6,"熵":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":3.0}},"df":1},"论":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951}},"df":2},"量":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":3}}},"修":{"docs":{},"df":0,"改":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.4142135623730951}},"df":5}},"值":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":8},"假":{"docs":{},"df":0,"设":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":11}},"偏":{"docs":{},"df":0,"差":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1},"离":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":3},"置":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.7320508075688772}},"df":2}},"做":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":4,"法":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"停":{"docs":{},"df":0,"止":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1},"留":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1}},"偶":{"docs":{},"df":0,"数":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1}},"像":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.4142135623730951}},"df":7},"允":{"docs":{},"df":0,"许":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":4}},"元":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":2,"素":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":8},"组":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0}},"df":2}},"充":{"docs":{},"df":0,"分":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2,"条":{"docs":{},"df":0,"件":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1}}},"当":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}},"先":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":8,"验":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":2.8284271247461903}},"df":1,"概":{"docs":{},"df":0,"率":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":2.0}},"df":1}}}},"免":{"docs":{},"df":0,"费":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}},"入":{"docs":{},"df":0,"门":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1}},"全":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":2,"免":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1,"费":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}},"家":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1},"局":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.23606797749979}},"df":1},"部":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}},"公":{"docs":{},"df":0,"司":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":2},"平":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1,"性":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1}},"式":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":3}},"关":{"docs":{},"df":0,"于":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":6},"系":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":4},"键":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":2,"字":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":1}}},"其":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.0}},"df":26,"中":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.0}},"df":21},"他":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.7320508075688772}},"df":2},"余":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1},"后":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1},"实":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}},"具":{"docs":{},"df":0,"体":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":7},"备":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1},"有":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951}},"df":1}},"典":{"docs":{},"df":0,"型":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":2}},"兼":{"docs":{},"df":0,"容":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":2,"性":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}}},"内":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":5,"含":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1},"存":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":3},"容":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":3},"积":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1},"部":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.4142135623730951}},"df":5}},"再":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":6,"也":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1},"次":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}},"冗":{"docs":{},"df":0,"余":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":1}},"写":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":5,"入":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1},"出":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1},"法":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.4142135623730951}},"df":1}},"决":{"docs":{},"df":0,"定":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":2},"策":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.7320508075688772}},"df":1}},"冻":{"docs":{},"df":0,"结":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":2}},"准":{"docs":{},"df":0,"备":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":7},"确":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}},"减":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0}},"df":1,"少":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1},"法":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1},"缓":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}},"几":{"docs":{},"df":0,"个":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":2},"乎":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":4}},"出":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":4,"不":{"docs":{},"df":0,"来":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1}},"发":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":5},"来":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":2},"现":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":4},"过":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1}},"函":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1,"数":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":3.3166247903554},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":4.47213595499958},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":3.7416573867739413},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.449489742783178}},"df":23}},"分":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":2,"为":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":1},"工":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1},"布":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":3.605551275463989},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.7320508075688772}},"df":6,"式":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}},"成":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":2},"批":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1},"析":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":3},"段":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951}},"df":1},"法":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":1},"离":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1,"性":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}},"类":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.4142135623730951}},"df":3},"解":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0}},"df":1},"词":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":4,"器":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0}},"df":3}},"辨":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"率":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"量":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1},"钟":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}},"切":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":3,"分":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951}},"df":1},"割":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}},"划":{"docs":{},"df":0,"线":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"列":{"docs":{},"df":0,"出":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.4142135623730951}},"df":1},"表":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":2.0}},"df":5}},"则":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.23606797749979}},"df":17},"刚":{"docs":{},"df":0,"刚":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}},"创":{"docs":{},"df":0,"建":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":2.0}},"df":8}},"初":{"docs":{},"df":0,"值":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":2},"始":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":12,"化":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":7},"条":{"docs":{},"df":0,"件":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951}},"df":1}},"状":{"docs":{},"df":0,"态":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":4}}}},"判":{"docs":{},"df":0,"据":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":2.0}},"df":1},"断":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":3}},"利":{"docs":{},"df":0,"用":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":2}},"到":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.4142135623730951}},"df":22,"达":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":2,"某":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1}}},"刻":{"docs":{},"df":0,"画":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}},"前":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":7,"提":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1},"述":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1},"面":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":4}},"剩":{"docs":{},"df":0,"余":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}},"力":{"docs":{},"df":0,"学":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1},"系":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":3}},"办":{"docs":{},"df":0,"法":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"功":{"docs":{},"df":0,"能":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.7320508075688772}},"df":3}},"加":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":1,"上":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1},"入":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":2},"快":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1},"法":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1},"载":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":2.8284271247461903}},"df":6},"速":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":3}},"动":{"docs":{},"df":0,"作":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772}},"df":1},"力":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":3,"学":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1},"系":{"docs":{},"df":0,"统":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":3}}},"态":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.0}},"df":3},"量":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":2.23606797749979}},"df":1}},"包":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":2,"含":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":15},"括":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.4142135623730951}},"df":3}},"化":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951}},"df":1},"区":{"docs":{},"df":0,"别":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":3},"域":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":3},"间":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"升":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1},"半":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":2},"协":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1,"方":{"docs":{},"df":0,"差":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}}},"单":{"docs":{},"df":0,"一":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1},"个":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1},"位":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1},"元":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":2,"测":{"docs":{},"df":0,"试":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":1}}},"步":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1},"独":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1},"词":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"占":{"docs":{},"df":0,"位":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1}},"卡":{"docs":{},"df":0,"尔":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951}},"df":1,"曼":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951}},"df":1}}},"即":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":17,"使":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1},"可":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":2},"将":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}},"却":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1},"卷":{"docs":{},"df":0,"积":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.7320508075688772}},"df":1}},"压":{"docs":{},"df":0,"缩":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1,"包":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}}},"原":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":4,"先":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1},"因":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1},"地":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":2.23606797749979}},"df":1},"始":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":11,"数":{"docs":{},"df":0,"据":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.7320508075688772}},"df":1}}},"本":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":2},"来":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":1},"样":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1},"点":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":2},"理":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}},"去":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":8,"取":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0}},"df":1}},"参":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951}},"df":1,"数":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":4.242640687119285},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":4.123105625617661},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":3.1622776601683795}},"df":14,"设":{"docs":{},"df":0,"置":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}}},"考":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":3}},"又":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":2},"及":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":2},"反":{"docs":{},"df":0,"之":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":2,"亦":{"docs":{},"df":0,"然":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}}},"向":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.4142135623730951}},"df":2},"复":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2},"映":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1},"馈":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1}},"发":{"docs":{},"df":0,"现":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":4}},"取":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":5,"决":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1,"于":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"出":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":2},"消":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.4142135623730951}},"df":1},"自":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0}},"df":1}},"受":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951}},"df":1,"到":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":2}},"变":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":3,"为":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1},"分":{"docs":{},"df":0,"法":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":1}},"化":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.4142135623730951}},"df":5},"性":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1},"换":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":3},"量":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":2.0}},"df":3,"名":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1}}},"叙":{"docs":{},"df":0,"述":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2}},"古":{"docs":{},"df":0,"老":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}},"句":{"docs":{},"df":0,"子":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}},"另":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":4},"只":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":12,"是":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1},"有":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1},"用":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1},"能":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":2},"要":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":2}},"可":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":7,"以":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":3.3166247903554},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.7320508075688772}},"df":28},"分":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1,"离":{"docs":{},"df":0,"性":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}},"取":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1},"控":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":2.0}},"df":2,"性":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":2}},"知":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1},"能":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":8},"行":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1},"视":{"docs":{"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":1,"化":{"docs":{"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":1}},"读":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1,"性":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}}},"右":{"docs":{},"df":0,"侧":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":2}},"叶":{"docs":{},"df":0,"子":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"各":{"docs":{},"df":0,"个":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1},"有":{"docs":{},"df":0,"不":{"docs":{},"df":0,"同":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1}}},"样":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1},"种":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":2,"各":{"docs":{},"df":0,"样":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}}}},"合":{"docs":{},"df":0,"并":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.7320508075688772}},"df":2},"度":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1},"适":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":2}},"同":{"docs":{},"df":0,"一":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1,"个":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1}},"于":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1},"时":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":5},"样":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1},"步":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":3.1622776601683795}},"df":1},"理":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1}},"名":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":2.23606797749979}},"df":1,"为":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1},"字":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":1},"称":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":4},"词":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"后":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":13,"台":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":1},"面":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}},"向":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":3,"前":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1},"量":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.0}},"df":11,"场":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1}}},"吗":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1},"否":{"docs":{},"df":0,"则":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":2}},"含":{"docs":{},"df":0,"义":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":4}},"启":{"docs":{},"df":0,"动":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1},"用":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951}},"df":1}},"吸":{"docs":{},"df":0,"引":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1}},"告":{"docs":{},"df":0,"诉":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1}},"呢":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1},"周":{"docs":{},"df":0,"期":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":2},"知":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}},"命":{"docs":{},"df":0,"令":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":5,"行":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.4142135623730951}},"df":3}},"名":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":2}},"咋":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1},"和":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":32},"哈":{"docs":{},"df":0,"密":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.6457513110645907}},"df":1,"顿":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.6457513110645907}},"df":1,"量":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.6457513110645907}},"df":1}}}},"响":{"docs":{},"df":0,"应":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951}},"df":1}},"哪":{"docs":{},"df":0,"些":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1},"里":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":2}},"唯":{"docs":{},"df":0,"一":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}},"商":{"docs":{},"df":0,"用":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}},"器":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":4.242640687119285},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":9},"回":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0}},"df":1,"到":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1},"归":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1},"答":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1},"调":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1},"顾":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":3}},"因":{"docs":{},"df":0,"为":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":7},"此":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":19}},"困":{"docs":{},"df":0,"难":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2}},"固":{"docs":{},"df":0,"定":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":7}},"国":{"docs":{},"df":0,"内":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}},"图":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":3.1622776601683795}},"df":2,"像":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":4,"处":{"docs":{},"df":0,"理":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}}},"标":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1},"片":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":2.0}},"df":3}},"在":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.23606797749979}},"df":31,"乎":{"docs":{"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":1},"于":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":3},"线":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"地":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":5,"方":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":2}},"场":{"docs":{},"df":0,"景":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}},"均":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1,"值":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1},"匀":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.7320508075688772}},"df":1}},"坐":{"docs":{},"df":0,"标":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2,"卡":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}},"块":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2},"埋":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1},"基":{"docs":{},"df":0,"于":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0}},"df":2},"本":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":6,"概":{"docs":{},"df":0,"念":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0}},"df":1}}},"石":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":1},"础":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.4142135623730951}},"df":5},"类":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1}},"堆":{"docs":{},"df":0,"叠":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}},"填":{"docs":{},"df":0,"充":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":2}},"增":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1,"加":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":2},"强":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":2},"长":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":2}},"处":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.4142135623730951}},"df":3,"理":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":3.3166247903554}},"df":5,"器":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951}},"df":1}}},"复":{"docs":{},"df":0,"制":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1,"到":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}},"杂":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":6,"度":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}}},"外":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":2,"部":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1},"面":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}},"多":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":5,"个":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":8},"少":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":2},"数":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":3}},"够":{"docs":{},"df":0,"用":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":1}},"大":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772}},"df":7,"于":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":2},"化":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.4142135623730951}},"df":3},"多":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":3,"数":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":3}},"家":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.4142135623730951}},"df":1},"小":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":5},"致":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1},"部":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"分":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"量":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":2}},"太":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1},"奇":{"docs":{},"df":0,"异":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":2}},"套":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1},"好":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":10,"几":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":1,"个":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":1}}},"如":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":5,"下":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":9},"何":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":12},"果":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":3.3166247903554},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.23606797749979}},"df":23}},"始":{"docs":{},"df":0,"终":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951}},"df":1,"保":{"docs":{},"df":0,"持":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1}}}},"娃":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1},"子":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":6,"目":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1,"录":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1}},"集":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}},"字":{"docs":{},"df":0,"典":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":3},"符":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.4142135623730951}},"df":1,"串":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.4142135623730951}},"df":1}}},"存":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1,"储":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":2},"在":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":6}},"学":{"docs":{},"df":0,"习":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":16,"曲":{"docs":{},"df":0,"线":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}}}},"它":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.4142135623730951}},"df":10,"们":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":10}},"安":{"docs":{},"df":0,"全":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":2,"性":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"装":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":4,"包":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.4142135623730951}},"df":1}}},"完":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":2,"全":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.7320508075688772}},"df":5,"免":{"docs":{},"df":0,"费":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}}},"备":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1},"成":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":4},"整":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":4},"毕":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":2},"美":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2}},"官":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":2,"方":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.7320508075688772}},"df":3}},"定":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.7320508075688772}},"df":2,"义":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":18},"式":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1},"性":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":3.605551275463989},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":3},"理":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.7320508075688772}},"df":3}},"实":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1,"例":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1},"战":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1},"时":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1},"现":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.7320508075688772}},"df":6},"际":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":7,"上":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1}}},"容":{"docs":{},"df":0,"器":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":3.7416573867739413}},"df":1},"性":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1},"易":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":2},"许":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1}},"密":{"docs":{},"df":0,"度":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":2}},"对":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":21,"于":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.7320508075688772}},"df":14},"偶":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":2.23606797749979}},"df":1},"应":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":11},"数":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":2.449489742783178}},"df":3},"模":{"docs":{},"df":0,"型":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":2}},"称":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.7320508075688772}},"df":1,"性":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951}},"df":1}},"角":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":2.449489742783178}},"df":2},"调":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":1},"象":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":6},"齐":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}},"寻":{"docs":{},"df":0,"找":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":5}},"导":{"docs":{},"df":0,"出":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1},"数":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":3},"致":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":4}},"封":{"docs":{},"df":0,"装":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}},"将":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.0}},"df":24},"小":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":8,"于":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0}},"df":1}},"少":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1},"尝":{"docs":{},"df":0,"试":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":2}},"就":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":12,"是":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":16,"说":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1}}},"尺":{"docs":{},"df":0,"寸":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":2}},"尽":{"docs":{},"df":0,"可":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1,"能":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}},"局":{"docs":{},"df":0,"部":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":5}},"层":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":3.0}},"df":5,"层":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1},"次":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1,"结":{"docs":{},"df":0,"构":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1}}}},"展":{"docs":{},"df":0,"开":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":3,"式":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2}}},"属":{"docs":{},"df":0,"于":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951}},"df":1},"性":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":2.449489742783178}},"df":2}},"嵌":{"docs":{},"df":0,"套":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1}},"工":{"docs":{},"df":0,"作":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":3},"具":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":7,"箱":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1}}},"左":{"docs":{},"df":0,"侧":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":3}},"巧":{"docs":{},"df":0,"妙":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1}},"巨":{"docs":{},"df":0,"大":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":3}},"巩":{"docs":{},"df":0,"固":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951}},"df":1}},"差":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":2,"别":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":2},"异":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1}},"已":{"docs":{},"df":0,"经":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":3}},"布":{"docs":{},"df":0,"式":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}},"师":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1},"希":{"docs":{},"df":0,"望":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":8}},"带":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":3,"入":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0}},"df":1},"来":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"常":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1,"数":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":3},"用":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":3},"见":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.4142135623730951}},"df":4}},"干":{"docs":{},"df":0,"扰":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1}},"平":{"docs":{},"df":0,"台":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1},"均":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":3,"值":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"常":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":1},"方":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1},"行":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1},"衡":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":3.872983346207417}},"df":1,"点":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":3.872983346207417}},"df":1}},"面":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}},"并":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":19,"且":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":7},"用":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1},"非":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}},"广":{"docs":{},"df":0,"播":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":2.0}},"df":1}},"序":{"docs":{},"df":0,"列":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.7320508075688772}},"df":2}},"库":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.4142135623730951}},"df":10},"应":{"docs":{},"df":0,"用":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2},"该":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":2}},"底":{"docs":{},"df":0,"层":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"庞":{"docs":{},"df":0,"大":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}},"度":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":3.872983346207417},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":3,"越":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1},"量":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.4142135623730951}},"df":2}},"延":{"docs":{},"df":0,"伸":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1},"续":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1},"迟":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1}},"建":{"docs":{},"df":0,"议":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":3}},"开":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1,"发":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1},"启":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951}},"df":1},"头":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1},"始":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":5},"式":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2},"销":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":3}},"弃":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1},"式":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":2,"子":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.4142135623730951}},"df":3}},"引":{"docs":{},"df":0,"入":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":4},"出":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1},"擎":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.4142135623730951}},"df":1}},"张":{"docs":{},"df":0,"量":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":3}},"弹":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1,"性":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951}},"df":1}},"强":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951}},"df":1,"大":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":1},"烈":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1,"建":{"docs":{},"df":0,"议":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}}}},"归":{"docs":{},"df":0,"一":{"docs":{},"df":0,"化":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":3}},"宿":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1}},"当":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951}},"df":9,"作":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":1},"前":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":8,"目":{"docs":{},"df":0,"录":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1}}}},"形":{"docs":{},"df":0,"式":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0}},"df":2},"成":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":3},"状":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":3}},"影":{"docs":{},"df":0,"响":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":2.23606797749979}},"df":6}},"彻":{"docs":{},"df":0,"底":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}},"往":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1,"往":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":3}},"径":{"docs":{},"df":0,"向":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951}},"df":2}},"待":{"docs":{},"df":0,"定":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1}},"很":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":8,"多":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":3},"大":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.4142135623730951}},"df":4},"小":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1},"少":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}},"得":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":4,"到":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.23606797749979}},"df":10}},"循":{"docs":{},"df":0,"环":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951}},"df":1}},"微":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":3,"分":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2,"方":{"docs":{},"df":0,"程":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2}}},"小":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":2.0}},"df":1},"调":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":8}},"心":{"docs":{},"df":0,"思":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":5}},"必":{"docs":{},"df":0,"然":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2},"要":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":5,"条":{"docs":{},"df":0,"件":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2}}},"须":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.7320508075688772}},"df":4}},"快":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1,"速":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":5}},"忽":{"docs":{},"df":0,"略":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":2}},"怀":{"docs":{},"df":0,"疑":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1}},"态":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1},"怎":{"docs":{},"df":0,"么":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}},"思":{"docs":{},"df":0,"想":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":8},"维":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1}},"性":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":3.4641016151377544}},"df":5,"格":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.7320508075688772}},"df":1},"能":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1},"质":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":4}},"总":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":3,"数":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":2},"是":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0}},"df":2},"结":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":5},"能":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1}},"恢":{"docs":{},"df":0,"复":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.4142135623730951}},"df":2}},"情":{"docs":{},"df":0,"况":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":11}},"惩":{"docs":{},"df":0,"罚":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.7320508075688772}},"df":2}},"惯":{"docs":{},"df":0,"于":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}},"想":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":6,"法":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951}},"df":1},"要":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":2}},"意":{"docs":{},"df":0,"味":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":3,"着":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":3}}},"感":{"docs":{},"df":0,"觉":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}},"成":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":2.0}},"df":1,"功":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1},"员":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1},"本":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":2},"立":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1}},"我":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":3,"们":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":4.123105625617661},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":3.3166247903554},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.8284271247461903}},"df":29}},"或":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":7,"者":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":8}},"截":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1},"所":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":7,"以":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":2},"在":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1},"有":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":17},"示":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"手":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":3,"中":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1},"动":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.4142135623730951}},"df":2}},"打":{"docs":{},"df":0,"乱":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1},"包":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.7320508075688772}},"df":1},"印":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}},"执":{"docs":{},"df":0,"行":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.4142135623730951}},"df":9}},"扩":{"docs":{},"df":0,"展":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":2}},"扫":{"docs":{},"df":0,"描":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1}},"扰":{"docs":{},"df":0,"动":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":3}},"批":{"docs":{},"df":0,"次":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":3.0}},"df":4},"量":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":2}},"找":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1,"到":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":7}},"把":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":5},"抓":{"docs":{},"df":0,"取":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}},"投":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1,"影":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":3}},"折":{"docs":{},"df":0,"腾":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1}},"抛":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.7320508075688772}},"df":1,"掷":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1}},"报":{"docs":{},"df":0,"告":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1},"错":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":2}},"抽":{"docs":{},"df":0,"取":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1},"象":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1,"类":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}}},"拉":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1,"姆":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.7320508075688772}},"df":2},"格":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":2.6457513110645907}},"df":2,"朗":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":2.6457513110645907}},"df":2}}},"拟":{"docs":{},"df":0,"合":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":3}},"拥":{"docs":{},"df":0,"有":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}},"括":{"docs":{},"df":0,"号":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1}},"拼":{"docs":{},"df":0,"接":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951}},"df":1}},"拿":{"docs":{},"df":0,"到":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}},"持":{"docs":{},"df":0,"续":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}},"指":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":5,"向":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":3},"定":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":5},"数":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":2,"函":{"docs":{},"df":0,"数":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1}}},"标":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2}},"按":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":2,"照":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":3},"钮":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1}},"捕":{"docs":{},"df":0,"捉":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}},"损":{"docs":{},"df":0,"失":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.7320508075688772}},"df":2}},"换":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1,"成":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}},"据":{"docs":{},"df":0,"库":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":1}},"掉":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2},"探":{"docs":{},"df":0,"测":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}},"接":{"docs":{},"df":0,"收":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":4},"着":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1},"触":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1},"近":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":3}},"控":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":3.7416573867739413}},"df":1,"制":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":3.872983346207417}},"df":13,"数":{"docs":{},"df":0,"据":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"策":{"docs":{},"df":0,"略":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1}}}},"推":{"docs":{},"df":0,"导":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0}},"df":3},"广":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2},"理":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.7320508075688772}},"df":1},"移":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1},"荐":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.4142135623730951}},"df":1},"送":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":2}},"描":{"docs":{},"df":0,"述":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.7320508075688772}},"df":6}},"提":{"docs":{},"df":0,"供":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":11,"数":{"docs":{},"df":0,"据":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}}},"出":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1},"前":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2,"准":{"docs":{},"df":0,"备":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}},"升":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":2.23606797749979}},"df":1},"取":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1},"高":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":4}},"搞":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2,"坏":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1},"懂":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1},"错":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}},"搭":{"docs":{},"df":0,"建":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}},"摘":{"docs":{},"df":0,"要":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1}},"操":{"docs":{},"df":0,"作":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":7}},"支":{"docs":{},"df":0,"持":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.7320508075688772}},"df":5}},"收":{"docs":{},"df":0,"敛":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":3},"费":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}},"改":{"docs":{},"df":0,"动":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":2.0}},"df":1},"变":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1},"进":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.4142135623730951}},"df":1,"版":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1}}},"放":{"docs":{},"df":0,"入":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":1},"出":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1},"到":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":2},"在":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":2},"大":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1},"缩":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1},"置":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}},"效":{"docs":{},"df":0,"果":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1},"率":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":2}},"敏":{"docs":{},"df":0,"感":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1,"度":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}}},"散":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":4.0}},"df":2},"数":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":4,"值":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":2},"字":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":2},"学":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951}},"df":9},"据":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":4.358898943540674},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":4.898979485566356},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":15,"分":{"docs":{},"df":0,"布":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1}},"处":{"docs":{},"df":0,"理":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":1}},"库":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":1},"格":{"docs":{},"df":0,"式":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"流":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1},"管":{"docs":{},"df":0,"理":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}},"类":{"docs":{},"df":0,"型":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}}},"量":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":3}},"整":{"docs":{},"df":0,"个":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":6},"体":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1},"理":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":4}},"文":{"docs":{},"df":0,"件":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":8,"夹":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":3}},"本":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":2},"档":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1},"章":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":2}},"断":{"docs":{},"df":0,"定":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1},"点":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":2}},"新":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":8,"建":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1},"版":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}},"方":{"docs":{},"df":0,"便":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":3},"向":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":2.449489742783178}},"df":3},"差":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951}},"df":2},"式":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":8},"案":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":2},"法":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":11},"程":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":3.1622776601683795}},"df":5}},"施":{"docs":{},"df":0,"加":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":2}},"旁":{"docs":{},"df":0,"边":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":2}},"无":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":3,"法":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":2},"约":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":2,"束":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":2}},"论":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2,"是":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1}}},"既":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":2,"然":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1}},"日":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":2.6457513110645907}},"df":2,"志":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":4}},"旧":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951}},"df":1},"时":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":2.0}},"df":18,"候":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":4},"刻":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":2},"变":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.4142135623730951}},"df":1},"间":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.7320508075688772}},"df":4,"延":{"docs":{},"df":0,"迟":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1}},"推":{"docs":{},"df":0,"移":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1}},"段":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1}}},"明":{"docs":{},"df":0,"显":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1},"白":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2}},"映":{"docs":{},"df":0,"射":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.4142135623730951}},"df":4}},"是":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":4.898979485566356},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":3.7416573867739413},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":3.4641016151377544},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":4.0}},"df":34,"不":{"docs":{},"df":0,"是":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}},"否":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.7320508075688772}},"df":4},"非":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":2}},"显":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":1,"存":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0}},"df":1},"然":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":2},"著":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}},"普":{"docs":{},"df":0,"通":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}},"暂":{"docs":{},"df":0,"停":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.4142135623730951}},"df":1},"时":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2}},"曲":{"docs":{},"df":0,"线":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":4},"面":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":2.449489742783178}},"df":1}},"更":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":8,"加":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":3},"好":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1},"新":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.7320508075688772}},"df":12}},"替":{"docs":{},"df":0,"代":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1},"换":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2}},"最":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.4142135623730951}},"df":13,"优":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":3.3166247903554}},"df":5,"性":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1},"控":{"docs":{},"df":0,"制":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.6457513110645907}},"df":2}}},"低":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":3,"点":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1}},"初":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":1},"合":{"docs":{},"df":0,"适":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"后":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":2},"大":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.7320508075688772}},"df":6,"化":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.4142135623730951}},"df":3}},"小":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.6457513110645907}},"df":4,"值":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1},"化":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.23606797749979}},"df":2}},"快":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":4},"新":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1},"终":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951}},"df":8},"近":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2},"高":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1,"点":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1}}},"有":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":19,"关":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1},"所":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1},"效":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":3},"时":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":2,"候":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":1}},"没":{"docs":{},"df":0,"有":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":2}},"点":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":3,"儿":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":3}},"限":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951}},"df":1}},"朝":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.4142135623730951}},"df":1},"期":{"docs":{},"df":0,"望":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":6,"值":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1}}},"未":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":2,"来":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1},"经":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1}},"末":{"docs":{},"df":0,"尾":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1},"端":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1}},"本":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1,"原":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1},"地":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":2.0}},"df":3},"数":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1},"文":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1},"次":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":2},"篇":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1},"质":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":3},"身":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":6}},"机":{"docs":{},"df":0,"制":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":2},"变":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.7320508075688772}},"df":1},"器":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951}},"df":1}},"权":{"docs":{},"df":0,"重":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":2.0}},"df":7}},"李":{"docs":{},"df":0,"雅":{"docs":{},"df":0,"普":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951}},"df":1}}},"条":{"docs":{},"df":0,"件":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":3.0}},"df":8}},"来":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":16,"回":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1},"源":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1},"自":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":2},"说":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":3}},"极":{"docs":{},"df":0,"值":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1},"小":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1}},"构":{"docs":{},"df":0,"建":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":2},"成":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":4},"造":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1}},"架":{"docs":{},"df":0,"构":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.4142135623730951}},"df":3}},"某":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1,"个":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":7},"些":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1}},"查":{"docs":{},"df":0,"看":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}},"标":{"docs":{},"df":0,"准":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":3},"签":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":3},"记":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":1},"量":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.4142135623730951}},"df":2}},"栏":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1},"树":{"docs":{},"df":0,"状":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":2}},"样":{"docs":{},"df":0,"本":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.4142135623730951}},"df":6,"数":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}}},"核":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.7320508075688772}},"df":2,"心":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":10,"思":{"docs":{},"df":0,"想":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":5}}}},"根":{"docs":{},"df":0,"据":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":5},"本":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.4142135623730951}},"df":1,"原":{"docs":{},"df":0,"因":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1}}},"目":{"docs":{},"df":0,"录":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.4142135623730951}},"df":1}}},"格":{"docs":{},"df":0,"式":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":2.6457513110645907}},"df":7},"拉":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1,"姆":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1}}},"框":{"docs":{},"df":0,"架":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":3}},"桶":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1},"梯":{"docs":{},"df":0,"度":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":3.605551275463989},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":2.0}},"df":9}},"检":{"docs":{},"df":0,"查":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":3}},"楚":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0}},"df":1},"概":{"docs":{},"df":0,"念":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":5},"率":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":3.3166247903554},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":4.58257569495584},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951}},"df":5,"分":{"docs":{},"df":0,"布":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.449489742783178}},"df":1}},"密":{"docs":{},"df":0,"度":{"docs":{},"df":0,"函":{"docs":{},"df":0,"数":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":2}}}},"模":{"docs":{},"df":0,"型":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951}},"df":1}}},"览":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2},"述":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}},"模":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":2,"块":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":4},"型":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":4.242640687119285},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.7320508075688772}},"df":19},"式":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":3},"拟":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":1}},"横":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1},"次":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":2.0}},"df":1,"数":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":2}},"正":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":2,"交":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":2},"切":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.7320508075688772}},"df":1},"则":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951}},"df":1},"向":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0}},"df":1},"定":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.7320508075688772}},"df":1},"常":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1},"数":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1},"确":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":3},"面":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.7320508075688772}},"df":1}},"此":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":3,"处":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":2},"时":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":4},"项":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1}},"步":{"docs":{},"df":0,"长":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":2},"骤":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":3}},"毁":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1},"每":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":3,"个":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":15},"层":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":2},"次":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":2},"步":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}},"比":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":5,"如":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.4142135623730951}},"df":3,"说":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}},"特":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1},"较":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":2}},"毕":{"docs":{},"df":0,"竟":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}},"永":{"docs":{},"df":0,"不":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1},"远":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1}},"求":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1,"和":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1},"导":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":2.6457513110645907}},"df":1},"解":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.7320508075688772}},"df":4}},"没":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":4,"有":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":10}},"沿":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":2,"着":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":5}},"法":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":2.8284271247461903}},"df":2,"则":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"泛":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1,"化":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1}},"注":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1,"入":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":3},"册":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951}},"df":1},"意":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":4,"事":{"docs":{},"df":0,"项":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}}}},"泰":{"docs":{},"df":0,"勒":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2}},"活":{"docs":{},"df":0,"动":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1}},"流":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1,"式":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951}},"df":1},"形":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1},"程":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":2}},"测":{"docs":{},"df":0,"试":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":3.605551275463989},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":4.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":8,"函":{"docs":{},"df":0,"数":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":3.0}},"df":2}},"数":{"docs":{},"df":0,"据":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1}},"环":{"docs":{},"df":0,"境":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}},"用":{"docs":{},"df":0,"例":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":2}}},"量":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}},"浮":{"docs":{},"df":0,"点":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1,"数":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}}},"消":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951}},"df":1,"失":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"涉":{"docs":{},"df":0,"及":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}},"混":{"docs":{},"df":0,"乱":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1},"合":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0}},"df":4}},"添":{"docs":{},"df":0,"加":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":2}},"清":{"docs":{},"df":0,"晰":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1},"理":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.7320508075688772}},"df":1},"空":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.4142135623730951}},"df":1},"零":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":2.0}},"df":1}},"渐":{"docs":{},"df":0,"近":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951}},"df":1},"进":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.0}},"df":2}},"源":{"docs":{},"df":0,"于":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1},"程":{"docs":{},"df":0,"序":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}}},"满":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1,"足":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.0}},"df":11}},"激":{"docs":{},"df":0,"增":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1},"活":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1}},"火":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1},"灾":{"docs":{},"df":0,"难":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1}},"点":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":8,"儿":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":3},"击":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.4142135623730951}},"df":1},"数":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1},"点":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1}},"炼":{"docs":{},"df":0,"金":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}},"烧":{"docs":{},"df":0,"杯":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1}},"然":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":4.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":3.3166247903554}},"df":4,"后":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":7}},"熟":{"docs":{},"df":0,"悉":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}},"熵":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":4.0}},"df":1},"爆":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1},"版":{"docs":{},"df":0,"本":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":4}},"特":{"docs":{},"df":0,"定":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1},"征":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":2,"值":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1}},"性":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1},"殊":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":3}},"状":{"docs":{},"df":0,"态":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":3.0}},"df":6,"方":{"docs":{},"df":0,"程":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":1}}}},"独":{"docs":{},"df":0,"立":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"率":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":5},"环":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":1,"境":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":5}},"现":{"docs":{},"df":0,"代":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2},"在":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":3},"成":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":3},"有":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":1},"象":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1}},"理":{"docs":{},"df":0,"器":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951}},"df":2},"想":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":2},"解":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.4142135623730951}},"df":6},"论":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":5}},"生":{"docs":{},"df":0,"命":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":2,"周":{"docs":{},"df":0,"期":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":2}}},"成":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":3}},"用":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":14,"于":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":10},"到":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":1},"户":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951}},"df":2},"来":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":4},"法":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.7320508075688772}},"df":3}},"由":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":9,"于":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":9}},"界":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951}},"df":2},"略":{"docs":{},"df":0,"去":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"疑":{"docs":{},"df":0,"问":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}},"的":{"docs":{},"df":0,"话":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":4}},"监":{"docs":{},"df":0,"控":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.4142135623730951}},"df":1}},"盒":{"docs":{},"df":0,"子":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1}},"目":{"docs":{},"df":0,"录":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":5},"标":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":7},"的":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951}},"df":2}},"直":{"docs":{},"df":0,"到":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":2},"接":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":12},"观":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":2}},"相":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1,"乘":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1},"互":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":2,"依":{"docs":{},"df":0,"赖":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":1}},"影":{"docs":{},"df":0,"响":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}}},"似":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":2,"性":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}},"关":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":5,"性":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951}},"df":1}},"切":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.4142135623730951}},"df":1},"反":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1},"同":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":5},"等":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1},"邻":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"看":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1,"不":{"docs":{},"df":0,"见":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1}},"出":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951}},"df":3},"到":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.4142135623730951}},"df":1},"看":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1},"起":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1,"来":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}}},"真":{"docs":{},"df":0,"实":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.4142135623730951}},"df":4},"的":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1}},"着":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":3},"瞬":{"docs":{},"df":0,"态":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1}},"矛":{"docs":{},"df":0,"盾":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1}},"知":{"docs":{},"df":0,"识":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":4,"结":{"docs":{},"df":0,"构":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}},"道":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}},"矩":{"docs":{},"df":0,"阵":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":4.47213595499958},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":3.3166247903554},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":2.8284271247461903}},"df":10}},"码":{"docs":{},"df":0,"数":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0}},"df":1}},"破":{"docs":{},"df":0,"坏":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"硬":{"docs":{},"df":0,"件":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1},"币":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":3.0}},"df":1},"盘":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}},"确":{"docs":{},"df":0,"保":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1},"定":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":4,"性":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1}}},"磁":{"docs":{},"df":0,"盘":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"示":{"docs":{},"df":0,"例":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.7320508075688772}},"df":4}},"社":{"docs":{},"df":0,"区":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.7320508075688772}},"df":1}},"神":{"docs":{},"df":0,"经":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.7320508075688772}},"df":7,"网":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":6,"络":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":6}}}},"离":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1,"散":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":3},"群":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772}},"df":1}},"种":{"docs":{},"df":0,"子":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":2}},"科":{"docs":{},"df":0,"学":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1,"计":{"docs":{},"df":0,"算":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}}}},"秩":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":3},"积":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1,"分":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1},"累":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2}},"称":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951}},"df":2,"为":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.7320508075688772}},"df":5}},"移":{"docs":{},"df":0,"动":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":2}},"程":{"docs":{},"df":0,"序":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951}},"df":3},"度":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.4142135623730951}},"df":6}},"稍":{"docs":{},"df":0,"微":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}},"稳":{"docs":{},"df":0,"定":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":5.385164807134504},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":3,"性":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":3.605551275463989},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":2},"等":{"docs":{},"df":0,"价":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1}}}},"空":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1,"间":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":5}},"突":{"docs":{},"df":0,"然":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"站":{"docs":{},"df":0,"点":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}},"端":{"docs":{},"df":0,"口":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":3.1622776601683795}},"df":1,"映":{"docs":{},"df":0,"射":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}}}},"笔":{"docs":{},"df":0,"记":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2}},"符":{"docs":{},"df":0,"合":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1}},"第":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":2.449489742783178}},"df":3,"一":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":5,"个":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":4},"项":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":2}},"二":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":5,"个":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":2},"项":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":2}}},"等":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":9,"于":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1},"价":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":9},"同":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1,"于":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"式":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":2.6457513110645907}},"df":2},"待":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1},"高":{"docs":{},"df":0,"线":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":2.8284271247461903}},"df":1}}},"答":{"docs":{},"df":0,"案":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1}},"策":{"docs":{},"df":0,"略":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":2}},"筛":{"docs":{},"df":0,"选":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951}},"df":1}},"简":{"docs":{},"df":0,"化":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2},"单":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":5},"称":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}},"算":{"docs":{},"df":0,"子":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":2},"法":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":2.23606797749979}},"df":7},"符":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"管":{"docs":{},"df":0,"理":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":5,"器":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.4142135623730951}},"df":1}}},"类":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":2.449489742783178}},"df":7,"似":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":5},"别":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.4142135623730951}},"df":3},"型":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":4},"比":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"粗":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1},"精":{"docs":{},"df":0,"度":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":3},"细":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"系":{"docs":{},"df":0,"列":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":3},"数":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1},"统":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":5.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":3.3166247903554},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":3.872983346207417},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.0}},"df":8,"对":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1}}},"索":{"docs":{},"df":0,"引":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}},"紧":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951}},"df":1,"凑":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1},"张":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"累":{"docs":{},"df":0,"积":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.7320508075688772}},"df":2},"计":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}},"约":{"docs":{},"df":0,"束":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":4.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.7320508075688772}},"df":4,"条":{"docs":{},"df":0,"件":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":4}}}},"线":{"docs":{},"df":0,"性":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":2.0}},"df":7,"化":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":2.0}},"df":2}}},"组":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":2.0}},"df":1,"合":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.0}},"df":1},"成":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":3},"织":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":3}},"细":{"docs":{},"df":0,"节":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}},"终":{"docs":{},"df":0,"值":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951}},"df":2},"点":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2}},"经":{"docs":{},"df":0,"典":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":2},"历":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1},"过":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.4142135623730951}},"df":2},"验":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":2.0}},"df":1}},"结":{"docs":{},"df":0,"束":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1},"构":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":2.6457513110645907}},"df":7},"果":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":3},"论":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0}},"df":3}},"给":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":4,"出":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":3},"定":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951}},"df":11}},"统":{"docs":{},"df":0,"一":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1},"计":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":3,"学":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}}},"继":{"docs":{},"df":0,"承":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":3}},"续":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1},"维":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":4,"度":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":2.0}},"df":3},"护":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}},"缓":{"docs":{},"df":0,"存":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":2.23606797749979}},"df":1,"数":{"docs":{},"df":0,"据":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}}}},"编":{"docs":{},"df":0,"写":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":2},"码":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.7320508075688772}},"df":2,"数":{"docs":{},"df":0,"据":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0}},"df":1}}}},"网":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1,"上":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1},"络":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":4.358898943540674},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.4142135623730951}},"df":8,"层":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":3.1622776601683795}},"df":2},"结":{"docs":{},"df":0,"构":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":2.0}},"df":1}}}},"美":{"docs":{},"df":0,"观":{"docs":{"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":1}},"翻":{"docs":{},"df":0,"译":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}},"老":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":3},"考":{"docs":{},"df":0,"虑":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.7320508075688772}},"df":9}},"而":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":16,"且":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951}},"df":3},"是":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":5},"言":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":4}},"耗":{"docs":{},"df":0,"时":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":2}},"耦":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1,"合":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1,"度":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}}},"联":{"docs":{},"df":0,"系":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1}},"肯":{"docs":{},"df":0,"定":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":3}},"背":{"docs":{},"df":0,"后":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1},"景":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":3}},"能":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":3.7416573867739413},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.7320508075688772}},"df":13,"力":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":2},"否":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":2},"够":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":4},"量":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":2.8284271247461903}},"df":1}},"脚":{"docs":{},"df":0,"本":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951}},"df":4}},"臆":{"docs":{},"df":0,"断":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1}},"自":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":2,"动":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":8,"化":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":2}},"发":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1},"定":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":3,"义":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":3}},"己":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":6},"带":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1},"治":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.7320508075688772}},"df":1},"然":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":2,"语":{"docs":{},"df":0,"言":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}}},"由":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2}},"至":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":2,"少":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1}},"节":{"docs":{},"df":0,"点":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.7320508075688772}},"df":2},"省":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"若":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":9},"范":{"docs":{},"df":0,"例":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1},"围":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1},"数":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1}},"获":{"docs":{},"df":0,"取":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.7320508075688772}},"df":1},"得":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":2}},"菜":{"docs":{},"df":0,"单":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1,"中":{"docs":{},"df":0,"选":{"docs":{},"df":0,"择":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1}}}}},"虽":{"docs":{},"df":0,"然":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":6}},"行":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1,"为":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":3},"走":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1}},"衡":{"docs":{},"df":0,"量":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":5}},"补":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1},"表":{"docs":{},"df":0,"征":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1},"现":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":3},"示":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":19},"达":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":3},"述":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1}},"被":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":18},"裁":{"docs":{},"df":0,"剪":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"装":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951}},"df":1,"饰":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":2}},"要":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":6,"求":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":3}},"覆":{"docs":{},"df":0,"盖":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"见":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":7,"到":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0}},"df":1}},"观":{"docs":{},"df":0,"察":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1},"测":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951}},"df":3}},"规":{"docs":{},"df":0,"划":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":1},"则":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":3}},"视":{"docs":{},"df":0,"为":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1},"作":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":6}},"解":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.7320508075688772}},"df":3,"决":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":4,"方":{"docs":{},"df":0,"案":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1}}},"压":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951}},"df":1},"放":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1,"出":{"docs":{},"df":0,"来":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}}},"析":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":3},"读":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1},"释":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":2}},"计":{"docs":{},"df":0,"学":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2},"数":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0}},"df":1,"器":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0}},"df":1}},"算":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":4.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.4142135623730951}},"df":13}},"认":{"docs":{},"df":0,"为":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.7320508075688772}},"df":2}},"让":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.7320508075688772}},"df":7},"训":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1,"练":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":4.795831523312719},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":3.4641016151377544},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.7320508075688772}},"df":13,"任":{"docs":{},"df":0,"务":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}},"器":{"docs":{"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0}},"df":1},"方":{"docs":{},"df":0,"法":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}},"记":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":2,"不":{"docs":{},"df":0,"清":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0}},"df":1}},"录":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":3},"得":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0}},"df":1}},"讲":{"docs":{},"df":0,"解":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":2}},"许":{"docs":{},"df":0,"多":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"论":{"docs":{},"df":0,"文":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":8}},"设":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":4,"定":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0}},"df":1},"置":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":8},"计":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}},"证":{"docs":{},"df":0,"据":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.4142135623730951}},"df":1},"明":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0}},"df":3}},"评":{"docs":{},"df":0,"估":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":4}},"词":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":2},"试":{"docs":{},"df":0,"用":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":2}},"话":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":2},"该":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":12},"详":{"docs":{},"df":0,"细":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951}},"df":1}},"语":{"docs":{},"df":0,"言":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":3}},"误":{"docs":{},"df":0,"差":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.4142135623730951}},"df":1}},"说":{"docs":{},"df":0,"明":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":6}},"请":{"docs":{},"df":0,"求":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.4142135623730951}},"df":1}},"诺":{"docs":{},"df":0,"夫":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951}},"df":1}},"读":{"docs":{},"df":0,"取":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.7320508075688772}},"df":4,"数":{"docs":{},"df":0,"据":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}}}},"调":{"docs":{},"df":0,"整":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":5},"用":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":5}},"贝":{"docs":{},"df":0,"叶":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":2.0}},"df":1,"斯":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":2.0}},"df":1}}},"负":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951}},"df":4,"号":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1},"数":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":2},"责":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.7320508075688772}},"df":4}},"贴":{"docs":{},"df":0,"合":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1}},"赋":{"docs":{},"df":0,"予":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.4142135623730951}},"df":1},"值":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}},"走":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.0}},"df":1},"起":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1,"名":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1},"来":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":4}},"超":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":4,"大":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1},"过":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}},"越":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.8284271247461903},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":3,"来":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1,"越":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}}},"趋":{"docs":{},"df":0,"于":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951}},"df":1},"近":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1}},"足":{"docs":{},"df":0,"够":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.7320508075688772}},"df":2}},"跑":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1},"距":{"docs":{},"df":0,"离":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":4}},"路":{"docs":{},"df":0,"径":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":4},"线":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}},"轨":{"docs":{},"df":0,"迹":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":3.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.7320508075688772}},"df":4}},"转":{"docs":{},"df":0,"化":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2},"发":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":3.1622776601683795}},"df":1},"向":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1},"换":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.7320508075688772}},"df":5,"成":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}}},"轮":{"docs":{},"df":0,"数":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"软":{"docs":{},"df":0,"件":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}},"轻":{"docs":{},"df":0,"易":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}},"较":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1},"辅":{"docs":{},"df":0,"助":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":3}},"输":{"docs":{},"df":0,"入":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":2.0}},"df":10},"出":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951}},"df":12}},"辨":{"docs":{},"df":0,"析":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":1},"率":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"边":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":2,"值":{"docs":{},"df":0,"问":{"docs":{},"df":0,"题":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1}}},"界":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":1,"条":{"docs":{},"df":0,"件":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":1}}},"缘":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.4142135623730951}},"df":1}},"达":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951}},"df":2,"到":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":3}},"过":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":2,"于":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":2},"去":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.4142135623730951}},"df":2},"滤":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1},"程":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":7}},"运":{"docs":{},"df":0,"作":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1},"动":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":2},"算":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":3,"符":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"行":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.7320508075688772}},"df":4}},"近":{"docs":{},"df":0,"似":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.4142135623730951}},"df":2},"期":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":5}},"返":{"docs":{},"df":0,"回":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":2.23606797749979}},"df":8,"值":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.4142135623730951}},"df":1}}},"还":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.4142135623730951}},"df":4,"是":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":5}},"这":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":13,"个":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":9},"些":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":6},"样":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":6},"种":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":3},"里":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":14}},"进":{"docs":{},"df":0,"一":{"docs":{},"df":0,"步":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":2}},"入":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":2},"制":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":2},"程":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":3},"行":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":18},"阶":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":1}},"远":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2,"大":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1,"于":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1}},"程":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":2.0}},"df":1}},"违":{"docs":{},"df":0,"反":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.4142135623730951}},"df":1}},"连":{"docs":{},"df":0,"乘":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1},"接":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":3},"续":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951}},"df":6,"函":{"docs":{},"df":0,"数":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1}}}},"迫":{"docs":{},"df":0,"使":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}},"迭":{"docs":{},"df":0,"代":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":4}},"追":{"docs":{},"df":0,"溯":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":1,"到":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"踪":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"送":{"docs":{},"df":0,"入":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":1},"给":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"适":{"docs":{},"df":0,"应":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":3},"用":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}},"选":{"docs":{},"df":0,"出":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1},"择":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":4}},"逐":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.4142135623730951}},"df":2,"个":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"递":{"docs":{},"df":0,"减":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951}},"df":1},"进":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1}},"通":{"docs":{},"df":0,"常":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":8},"用":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951}},"df":2},"过":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.7320508075688772}},"df":15},"道":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.4142135623730951}},"df":1}},"速":{"docs":{},"df":0,"度":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":3}},"造":{"docs":{},"df":0,"成":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":1}},"逻":{"docs":{},"df":0,"辑":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":5}},"逼":{"docs":{},"df":0,"近":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951}},"df":1}},"遇":{"docs":{},"df":0,"到":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}},"遍":{"docs":{},"df":0,"历":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":2}},"遗":{"docs":{},"df":0,"忘":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.7320508075688772}},"df":3}},"遭":{"docs":{},"df":0,"到":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"避":{"docs":{},"df":0,"免":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}},"那":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":2,"么":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":13},"些":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":3},"样":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1},"里":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"邻":{"docs":{},"df":0,"域":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1}},"部":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1,"分":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":5},"署":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0}},"df":1}},"都":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":16},"配":{"docs":{},"df":0,"置":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.7320508075688772}},"df":8,"文":{"docs":{},"df":0,"件":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":2}}}},"采":{"docs":{},"df":0,"样":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1},"用":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1},"集":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"释":{"docs":{},"df":0,"放":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"里":{"docs":{},"df":0,"面":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}},"重":{"docs":{},"df":0,"写":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951}},"df":1},"复":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":2},"新":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":4},"点":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1},"要":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":2.6457513110645907}},"df":3,"性":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951}},"df":1}}},"量":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":2,"化":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":2.6457513110645907}},"df":3}},"针":{"docs":{},"df":0,"对":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}},"钩":{"docs":{},"df":0,"子":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}},"链":{"docs":{},"df":0,"式":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":1,"法":{"docs":{},"df":0,"则":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}}}},"错":{"docs":{},"df":0,"误":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":3,"处":{"docs":{},"df":0,"理":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1}}}},"键":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951}},"df":1},"长":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":3,"度":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.7320508075688772}},"df":3},"期":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}},"门":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1},"闭":{"docs":{},"df":0,"合":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1},"环":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1}},"问":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":2,"题":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":2.6457513110645907},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":3.7416573867739413},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":2.449489742783178}},"df":12}},"阅":{"docs":{},"df":0,"读":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":12}},"阈":{"docs":{},"df":0,"值":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":1}},"防":{"docs":{},"df":0,"止":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":2}},"阶":{"docs":{},"df":0,"梯":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0}},"df":1},"段":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"附":{"docs":{},"df":0,"上":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1},"近":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":2}},"陈":{"docs":{},"df":0,"述":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1}},"降":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"低":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"限":{"docs":{},"df":0,"制":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":4}},"除":{"docs":{},"df":0,"了":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":3},"以":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1},"非":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":2}},"随":{"docs":{},"df":0,"时":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1},"机":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":3,"变":{"docs":{},"df":0,"量":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.7320508075688772}},"df":1}},"性":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}},"着":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":2}},"难":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":2},"雅":{"docs":{},"df":0,"普":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.4142135623730951}},"df":1}},"集":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":3.1622776601683795},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":11,"中":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":6},"合":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":4}},"零":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":3},"需":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":4,"求":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":2},"要":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":17}},"非":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":8,"对":{"docs":{},"df":0,"称":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1}},"常":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":8,"低":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}},"线":{"docs":{},"df":0,"性":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.7320508075688772}},"df":4}}},"面":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1,"板":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.4142135623730951}},"df":1},"相":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1}},"鞍":{"docs":{},"df":0,"点":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.4142135623730951}},"df":1}},"项":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951}},"df":3,"目":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":3}},"顺":{"docs":{},"df":0,"序":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":3}},"预":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":2.23606797749979},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":5,"先":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":2},"处":{"docs":{},"df":0,"理":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":2.449489742783178},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":2.0}},"df":2}},"备":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.4142135623730951}},"df":2},"定":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1},"测":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":4}},"领":{"docs":{},"df":0,"域":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2}},"额":{"docs":{},"df":0,"外":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0}},"df":2}},"首":{"docs":{},"df":0,"先":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":2}},"驱":{"docs":{},"df":0,"动":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1}},"验":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":2.8284271247461903}},"df":1,"证":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":4}},"高":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":4,"位":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1},"度":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1},"效":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":2},"斯":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0}},"df":1,"分":{"docs":{},"df":0,"布":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0}},"df":1}}},"点":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1},"线":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":2.8284271247461903}},"df":1},"维":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1},"阶":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"麻":{"docs":{},"df":0,"烦":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}},"默":{"docs":{},"df":0,"认":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":2.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.7320508075688772},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.4142135623730951}},"df":7,"值":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"默":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}}}},"description":{"root":{"docs":{},"df":0,"A":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adam/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":2,"W":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1}},"p":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0}},"df":1}}}}},"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adam/":{"tf":1.0}},"df":1}}}}}}},"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}}}}}}},"p":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}},"x":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0}},"df":1},"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":2}}}}}}}}}}}}},"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/archive/":{"tf":1.0}},"df":1}}}}}}},"B":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}}}}}}},"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/":{"tf":1.0}},"df":1}}},"u":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1}}},"C":{"docs":{},"df":0,"L":{"docs":{},"df":0,"M":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}}}}}}}}}},"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1}}}}},"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1}}}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}}}}}}},"D":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"L":{"docs":{},"df":0,"o":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}}}}}},"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}}}}}},"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1}},"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1}}}}}}}},"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0}},"df":1}}}}}}}}},"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":1}}}},"E":{"docs":{},"df":0,"W":{"docs":{},"df":0,"C":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}},"f":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}}}}}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}}}}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adam/":{"tf":1.0}},"df":1}}}}}}}}}},"F":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0}},"df":1}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3}},"s":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":2}}}},"x":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":1}}}}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}}}}}}}},"H":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"v":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0}},"df":1}}}},"u":{"docs":{},"df":0,"g":{"docs":{},"df":0,"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0}},"df":1}}}}}}},"I":{"docs":{},"df":0,"n":{"docs":{},"df":0,"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0}},"df":1}}}}}}}}},"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1}}}}}}}}}},"K":{"docs":{},"df":0,"L":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":2},"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}}}}}},"L":{"docs":{},"df":0,"P":{"docs":{},"df":0,"C":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1}},"a":{"docs":{},"df":0,"S":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1}}}}},"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}}}}}},"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/":{"tf":1.0}},"df":1}}}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2}}}}}},"s":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}},"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":1}}}}}}},"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1}}}}}}}}},"o":{"docs":{},"df":0,"R":{"docs":{},"df":0,"A":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":2}},"w":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0}},"df":1}}},"M":{"docs":{},"df":0,"A":{"docs":{},"df":0,"E":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}},"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"x":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0}},"df":1}}}}},"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":2}}}}},"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}},"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adam/":{"tf":1.0}},"df":1,"u":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0}},"df":1}}}}}}},"u":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}}}}}}},"N":{"docs":{},"df":0,"T":{"docs":{},"df":0,"K":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}},"e":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}}}}}},"O":{"docs":{},"df":0,"n":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}},"p":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}}}}}},"P":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}}}}}}}}},"e":{"docs":{},"df":0,"f":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":2}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}}}}},"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":1}}},"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1}}}}}}},"o":{"docs":{},"df":0,"j":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/projects/":{"tf":1.0}},"df":1}}}}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1}}}}}}},"y":{"docs":{},"df":0,"T":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1}}}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":2}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":6}}}}}}},"R":{"docs":{},"df":0,"L":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1},"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"k":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0}},"df":1}},"z":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}},"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}}}}}}}},"S":{"docs":{},"df":0,"F":{"docs":{},"df":0,"T":{"docs":{"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":2}}}}}}}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}},"T":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}}}}}},"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0}},"df":2}}}}},"h":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}}}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}}}},"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"f":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":3}}}}}}}}}}},"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3}}}}}},"V":{"docs":{},"df":0,"S":{"docs":{},"df":0,"C":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1}}}}}},"W":{"docs":{},"df":0,"e":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":3}}}}},"h":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}},"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}},"b":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0}},"df":1}},"s":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1}}}},"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}},"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1}}},"i":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"m":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1}}}}},"o":{"docs":{},"df":0,"f":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":2}},"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/":{"tf":1.0}},"df":1}}}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2},"t":{"docs":{},"df":0,"o":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"f":{"docs":{},"df":0,"o":{"docs":{"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":1}}}}}}}},"r":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0}},"df":1}}},"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0}},"df":1}}}}},"w":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3}}}},"上":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1},"不":{"docs":{},"df":0,"变":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1}},"与":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":7},"中":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":2},"乘":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1},"交":{"docs":{},"df":0,"叉":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1}},"介":{"docs":{},"df":0,"绍":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}},"代":{"docs":{},"df":0,"码":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0}},"df":3}},"优":{"docs":{},"df":0,"化":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}},"似":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1},"使":{"docs":{},"df":0,"用":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}},"先":{"docs":{},"df":0,"验":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1}},"全":{"docs":{},"df":0,"家":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}},"公":{"docs":{},"df":0,"式":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1}},"分":{"docs":{},"df":0,"类":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"力":{"docs":{},"df":0,"系":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1}},"动":{"docs":{},"df":0,"力":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1,"系":{"docs":{},"df":0,"统":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1}}}},"原":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1},"可":{"docs":{},"df":0,"控":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1,"性":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1}},"视":{"docs":{"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":1,"化":{"docs":{"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":1}}},"同":{"docs":{},"df":0,"步":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}},"后":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1},"器":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1},"图":{"docs":{},"df":0,"像":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"基":{"docs":{},"df":0,"础":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1}},"好":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1},"子":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1},"学":{"docs":{},"df":0,"习":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}},"定":{"docs":{},"df":0,"义":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1},"性":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1}},"实":{"docs":{},"df":0,"现":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":1}},"对":{"docs":{},"df":0,"数":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1}},"工":{"docs":{},"df":0,"具":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}},"巩":{"docs":{},"df":0,"固":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}},"库":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":5},"度":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1},"弹":{"docs":{},"df":0,"性":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}},"形":{"docs":{},"df":0,"状":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"微":{"docs":{},"df":0,"调":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":4}},"快":{"docs":{},"df":0,"速":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1}},"性":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":2},"总":{"docs":{},"df":0,"结":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0}},"df":3}},"手":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1},"拉":{"docs":{},"df":0,"格":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1,"朗":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1}}},"控":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1,"制":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2}},"搭":{"docs":{},"df":0,"建":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}},"操":{"docs":{},"df":0,"作":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0}},"df":3}},"散":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1},"数":{"docs":{},"df":0,"学":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"文":{"docs":{},"df":0,"件":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}},"方":{"docs":{},"df":0,"式":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}},"日":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1},"时":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1},"最":{"docs":{},"df":0,"优":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2,"控":{"docs":{},"df":0,"制":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2}}}},"权":{"docs":{},"df":0,"重":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}},"架":{"docs":{},"df":0,"构":{"docs":{"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":1}},"核":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1},"格":{"docs":{},"df":0,"式":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0}},"df":1}},"桶":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1},"概":{"docs":{},"df":0,"率":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1},"览":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2}},"模":{"docs":{},"df":0,"型":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1}},"正":{"docs":{},"df":0,"切":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}},"求":{"docs":{},"df":0,"导":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"法":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1},"测":{"docs":{},"df":0,"试":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1,"环":{"docs":{},"df":0,"境":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}}}},"然":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1},"熵":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1},"环":{"docs":{},"df":0,"境":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}},"用":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1},"矩":{"docs":{},"df":0,"阵":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}},"示":{"docs":{},"df":0,"例":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":1}},"神":{"docs":{},"df":0,"经":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}},"稳":{"docs":{},"df":0,"定":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1,"性":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1}}},"端":{"docs":{},"df":0,"口":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}},"等":{"docs":{},"df":0,"价":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0}},"df":1}},"算":{"docs":{},"df":0,"法":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":2}},"系":{"docs":{},"df":0,"统":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":2}},"约":{"docs":{},"df":0,"束":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":1}},"线":{"docs":{},"df":0,"性":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":2}},"结":{"docs":{},"df":0,"构":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":2}},"网":{"docs":{},"df":0,"络":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":2,"结":{"docs":{},"df":0,"构":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1}}}},"能":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1},"自":{"docs":{},"df":0,"定":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1,"义":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}}},"获":{"docs":{},"df":0,"取":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1}},"训":{"docs":{},"df":0,"练":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"论":{"docs":{},"df":0,"文":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":8}},"调":{"docs":{},"df":0,"用":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}},"贝":{"docs":{},"df":0,"叶":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1,"斯":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1}}},"转":{"docs":{},"df":0,"发":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}},"远":{"docs":{},"df":0,"程":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}},"连":{"docs":{},"df":0,"续":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}},"通":{"docs":{},"df":0,"用":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0}},"df":1}},"问":{"docs":{},"df":0,"题":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":1}},"阅":{"docs":{},"df":0,"读":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":11}},"预":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1},"验":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1}}},"path":{"root":{"docs":{},"df":0,"A":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adam/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":2,"W":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1}},"p":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0}},"df":1}}}}},"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adam/":{"tf":1.0}},"df":1}}}}}}},"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}}}}}}},"p":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}},"x":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0}},"df":1},"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":2}}}}}}}}}}}}},"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/archive/":{"tf":1.0}},"df":1}}}}}}},"B":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}}}}}}},"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/":{"tf":1.0}},"df":1}}},"u":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1}}},"C":{"docs":{},"df":0,"L":{"docs":{},"df":0,"M":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}}}}}}}}}},"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1}}}}},"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1}}}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}}}}}}},"D":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"L":{"docs":{},"df":0,"o":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}}}}}},"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}}}}}},"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1}},"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1}}}}}}}},"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0}},"df":1}}}}}}}}},"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":1}}}},"E":{"docs":{},"df":0,"W":{"docs":{},"df":0,"C":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}},"f":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}}}}}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}}}}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adam/":{"tf":1.0}},"df":1}}}}}}}}}},"F":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0}},"df":1}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3}},"s":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":2}}}},"x":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":1}}}}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}}}}}}}},"H":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"v":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0}},"df":1}}}},"u":{"docs":{},"df":0,"g":{"docs":{},"df":0,"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0}},"df":1}}}}}}},"I":{"docs":{},"df":0,"n":{"docs":{},"df":0,"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0}},"df":1}}}}}}}}},"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1}}}}}}}}}},"K":{"docs":{},"df":0,"L":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":2},"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}}}}}},"L":{"docs":{},"df":0,"P":{"docs":{},"df":0,"C":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1}},"a":{"docs":{},"df":0,"S":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1}}}}},"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}}}}}},"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/":{"tf":1.0}},"df":1}}}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2}}}}}},"s":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}},"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":1}}}}}}},"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1}}}}}}}}},"o":{"docs":{},"df":0,"R":{"docs":{},"df":0,"A":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":2}},"w":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0}},"df":1}}},"M":{"docs":{},"df":0,"A":{"docs":{},"df":0,"E":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}},"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"x":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0}},"df":1}}}}},"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":2}}}}},"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}},"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adam/":{"tf":1.0}},"df":1,"u":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0}},"df":1}}}}}}},"u":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}}}}}}},"N":{"docs":{},"df":0,"T":{"docs":{},"df":0,"K":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}},"e":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}}}}}},"O":{"docs":{},"df":0,"n":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}},"p":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}}}}}},"P":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}}}}}}}}},"e":{"docs":{},"df":0,"f":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":2}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}}}}},"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":1}}},"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1}}}}}}},"o":{"docs":{},"df":0,"j":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/projects/":{"tf":1.0}},"df":1}}}}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1}}}}}}},"y":{"docs":{},"df":0,"T":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1}}}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":2}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":6}}}}}}},"R":{"docs":{},"df":0,"L":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1},"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"k":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0}},"df":1}},"z":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}},"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}}}}}}}},"S":{"docs":{},"df":0,"F":{"docs":{},"df":0,"T":{"docs":{"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":2}}}}}}}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}},"T":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}}}}}},"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0}},"df":2}}}}},"h":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}}}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}}}},"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"f":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":3}}}}}}}}}}},"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3}}}}}},"V":{"docs":{},"df":0,"S":{"docs":{},"df":0,"C":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1}}}}}},"W":{"docs":{},"df":0,"e":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":3}}}}},"h":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}},"a":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adam/":{"tf":1.0}},"df":1,"w":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1}},"p":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0}},"df":1}}}}}}}}},"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}}}}}},"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":2}},"p":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}},"x":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0}},"df":1},"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":2}}}}}}}}}}}}},"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/archive/":{"tf":1.0}},"df":1}}}}}}},"b":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.4142135623730951}},"df":1}},"s":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.4142135623730951}},"df":1}}},"e":{"docs":{},"df":0,"i":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1},"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}}}}}}},"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1}}},"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-adam/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":44}}},"u":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1,"g":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1}}},"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"o":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0}},"df":3}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1},"h":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1},"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1}}},"u":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1}},"l":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}}}}}}}}}},"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1}}}}},"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1}}}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}}}}}}},"d":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1,"i":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0}},"df":3},"n":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1},"o":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":1},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}}}}}},"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}}}}}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":7,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0}},"df":1}}},"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"o":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":5}},"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":2}},"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0}},"df":1}}}}}}}}},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1}}},"u":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":9,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":1}},"i":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1}}},"e":{"docs":{},"df":0,"f":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}}}}}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}}}}}},"w":{"docs":{},"df":0,"c":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}}},"f":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":3,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}}},"e":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3}},"s":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":2}}}},"x":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":1}}}}}},"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.4142135623730951}},"df":1,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}}}}}}}},"g":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":3}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":2,"t":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.4142135623730951}},"df":1}},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":2}},"u":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":3}},"u":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}},"h":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1,"a":{"docs":{},"df":0,"v":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0}},"df":1}}}},"o":{"docs":{},"df":0,"u":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1}},"u":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":2,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}},"g":{"docs":{},"df":0,"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0}},"df":1}}}}},"o":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1}}},"i":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.4142135623730951}},"df":1,"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0}},"df":1}}}}}}}}},"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1}}}}}}}}}},"j":{"docs":{},"df":0,"i":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1,"a":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":3,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1},"o":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":5},"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":2}}},"u":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}},"k":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":2,"r":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}}}}},"l":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":2},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":4}}},"u":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":5,"a":{"docs":{},"df":0,"i":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1}}}},"l":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1,"n":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2,"g":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1,"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}}}}}},"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}}},"s":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1}}}}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2}}}}}},"i":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1},"s":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}},"i":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":2,"a":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":2}},"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":1}}}}}}},"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1}}}}}}}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":2}},"w":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0}},"df":1}},"p":{"docs":{},"df":0,"c":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1}},"u":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":5},"o":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":2}}},"m":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0}},"df":3,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1},"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"x":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0}},"df":1}}}}},"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1},"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":2}}}}},"o":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.4142135623730951}},"df":2,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}},"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0}},"df":1}}}}}}},"u":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}}}}}}},"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1}},"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}}}}},"t":{"docs":{},"df":0,"k":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}}},"o":{"docs":{},"df":0,"f":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.4142135623730951}},"df":2},"n":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}},"p":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}}}}}},"p":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}}}}}}}}},"e":{"docs":{},"df":0,"f":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":2}}},"o":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/":{"tf":1.0}},"df":1}}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}}}}},"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":1}}},"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1}}}}}}},"o":{"docs":{},"df":0,"j":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/projects/":{"tf":1.0}},"df":1}}}}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1}}}}}}},"y":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":2}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":7}}}}}}},"q":{"docs":{},"df":0,"i":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1,"e":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1},"u":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"u":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1,"a":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":2}}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1,"k":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0}},"df":1}},"z":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}}}},"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}}}}}}},"i":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1},"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.4142135623730951}},"df":2,"a":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1}},"h":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":2}}},"e":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}},"i":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":8},"o":{"docs":{},"df":0,"u":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1}},"u":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":3}},"i":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":2},"u":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1,"a":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":2}},"c":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":2}}}}}}}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}}}}}},"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0}},"df":2}}}}},"h":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}}}}},"i":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":1},"o":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.4142135623730951}},"df":1,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":4}},"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"f":{"docs":{},"df":0,"o":{"docs":{"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.4142135623730951}},"df":1}}}}}}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}}}},"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"f":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":3}}}}}}}}}},"l":{"docs":{"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.4142135623730951}},"df":1}},"u":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3}}}}}},"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.4142135623730951}},"df":1}}}}},"v":{"docs":{},"df":0,"s":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1}}}}}},"w":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":2}}},"e":{"docs":{},"df":0,"i":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":4,"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}}}},"n":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":7}},"h":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.4142135623730951}},"df":3}}}},"x":{"docs":{},"df":0,"i":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":3,"a":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":4,"g":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1},"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.4142135623730951}},"df":7}}},"u":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1,"e":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":2},"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}}},"y":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.4142135623730951}},"df":1}},"i":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":3}},"u":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":3}},"u":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.4142135623730951},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0}},"df":6,"a":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1}},"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":9}}},"z":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1,"g":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}}},"i":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":3}}},"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}}}}},"i":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":2},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0}},"df":3}}},"u":{"docs":{},"df":0,"i":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2},"o":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0}},"df":3}}},"上":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1},"不":{"docs":{},"df":0,"变":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1}},"与":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":7},"中":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":2},"乘":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1},"交":{"docs":{},"df":0,"叉":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1}},"介":{"docs":{},"df":0,"绍":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}},"代":{"docs":{},"df":0,"码":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0}},"df":3}},"优":{"docs":{},"df":0,"化":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}},"似":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1},"使":{"docs":{},"df":0,"用":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}},"先":{"docs":{},"df":0,"验":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1}},"全":{"docs":{},"df":0,"家":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}},"公":{"docs":{},"df":0,"式":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1}},"分":{"docs":{},"df":0,"类":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"力":{"docs":{},"df":0,"系":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1}},"动":{"docs":{},"df":0,"力":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1,"系":{"docs":{},"df":0,"统":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1}}}},"原":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1},"可":{"docs":{},"df":0,"控":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1,"性":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1}},"视":{"docs":{"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":1,"化":{"docs":{"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":1}}},"同":{"docs":{},"df":0,"步":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}},"后":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1},"器":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1},"图":{"docs":{},"df":0,"像":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"基":{"docs":{},"df":0,"础":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1}},"好":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1},"子":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1},"学":{"docs":{},"df":0,"习":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}},"定":{"docs":{},"df":0,"义":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1},"性":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1}},"实":{"docs":{},"df":0,"现":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":1}},"对":{"docs":{},"df":0,"数":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1}},"工":{"docs":{},"df":0,"具":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}},"巩":{"docs":{},"df":0,"固":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}},"库":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":5},"度":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1},"弹":{"docs":{},"df":0,"性":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}},"形":{"docs":{},"df":0,"状":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"微":{"docs":{},"df":0,"调":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":4}},"快":{"docs":{},"df":0,"速":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1}},"性":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":2},"总":{"docs":{},"df":0,"结":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0}},"df":3}},"手":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1},"拉":{"docs":{},"df":0,"格":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1,"朗":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1}}},"控":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1,"制":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2}},"搭":{"docs":{},"df":0,"建":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}},"操":{"docs":{},"df":0,"作":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0}},"df":3}},"散":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1},"数":{"docs":{},"df":0,"学":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"文":{"docs":{},"df":0,"件":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}},"方":{"docs":{},"df":0,"式":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}},"日":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1},"时":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1},"最":{"docs":{},"df":0,"优":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2,"控":{"docs":{},"df":0,"制":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2}}}},"权":{"docs":{},"df":0,"重":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}},"架":{"docs":{},"df":0,"构":{"docs":{"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":1}},"核":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1},"格":{"docs":{},"df":0,"式":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0}},"df":1}},"桶":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1},"概":{"docs":{},"df":0,"率":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1},"览":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2}},"模":{"docs":{},"df":0,"型":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1}},"正":{"docs":{},"df":0,"切":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}},"求":{"docs":{},"df":0,"导":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"法":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1},"测":{"docs":{},"df":0,"试":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1,"环":{"docs":{},"df":0,"境":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}}}},"然":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1},"熵":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1},"环":{"docs":{},"df":0,"境":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}},"用":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1},"矩":{"docs":{},"df":0,"阵":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}},"示":{"docs":{},"df":0,"例":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":1}},"神":{"docs":{},"df":0,"经":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}},"稳":{"docs":{},"df":0,"定":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1,"性":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1}}},"端":{"docs":{},"df":0,"口":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}},"等":{"docs":{},"df":0,"价":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0}},"df":1}},"算":{"docs":{},"df":0,"法":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":2}},"系":{"docs":{},"df":0,"统":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":2}},"约":{"docs":{},"df":0,"束":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":1}},"线":{"docs":{},"df":0,"性":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":2}},"结":{"docs":{},"df":0,"构":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":2}},"网":{"docs":{},"df":0,"络":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":2,"结":{"docs":{},"df":0,"构":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1}}}},"能":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1},"自":{"docs":{},"df":0,"定":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1,"义":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}}},"获":{"docs":{},"df":0,"取":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1}},"训":{"docs":{},"df":0,"练":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"论":{"docs":{},"df":0,"文":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":8}},"调":{"docs":{},"df":0,"用":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}},"贝":{"docs":{},"df":0,"叶":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1,"斯":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1}}},"转":{"docs":{},"df":0,"发":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}},"远":{"docs":{},"df":0,"程":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}},"连":{"docs":{},"df":0,"续":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}},"通":{"docs":{},"df":0,"用":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0}},"df":1}},"问":{"docs":{},"df":0,"题":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":1}},"阅":{"docs":{},"df":0,"读":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":11}},"预":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1},"验":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1}}},"title":{"root":{"docs":{},"df":0,"A":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adam/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":2,"W":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1}},"p":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0}},"df":1}}}}},"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adam/":{"tf":1.0}},"df":1}}}}}}},"n":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}}}}}}},"p":{"docs":{},"df":0,"p":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}},"x":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0}},"df":1},"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":2}}}}}}}}}}}}},"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/archive/":{"tf":1.0}},"df":1}}}}}}},"B":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"k":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}}}}}}},"l":{"docs":{},"df":0,"o":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/":{"tf":1.0}},"df":1}}},"u":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1}}},"C":{"docs":{},"df":0,"L":{"docs":{},"df":0,"M":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"o":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"d":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}}}}}}}}}},"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"o":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2,"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"b":{"docs":{},"df":0,"i":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1}}}}},"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1}}}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}}}}}}},"D":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"L":{"docs":{},"df":0,"o":{"docs":{},"df":0,"a":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}}}}}},"s":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":1}}}}}},"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1}},"o":{"docs":{},"df":0,"u":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0}},"df":1}}}}}}}},"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0}},"df":1}}}}}}}}},"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":1}}}},"E":{"docs":{},"df":0,"W":{"docs":{},"df":0,"C":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}},"f":{"docs":{},"df":0,"f":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1}}}}}}}},"l":{"docs":{},"df":0,"a":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}}}}}},"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adam/":{"tf":1.0}},"df":1}}}}}}}}}},"F":{"docs":{},"df":0,"a":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0}},"df":1}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3}},"s":{"docs":{},"df":0,"h":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":2}}}},"x":{"docs":{},"df":0,"t":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":1}}}}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1},"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}}}}}}}},"H":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"v":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0}},"df":1}}}},"u":{"docs":{},"df":0,"g":{"docs":{},"df":0,"g":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0}},"df":1}}}}}}},"I":{"docs":{},"df":0,"n":{"docs":{},"df":0,"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0}},"df":1}}}}}}}}},"v":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1}}}}}}}}}},"K":{"docs":{},"df":0,"L":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":2},"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}}}}}},"L":{"docs":{},"df":0,"P":{"docs":{},"df":0,"C":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1}},"a":{"docs":{},"df":0,"S":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1}}}}},"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"u":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}}}}}},"r":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":2}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/":{"tf":1.0}},"df":1}}}}},"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2}}}}}},"s":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}},"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":1}}}}}}},"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"e":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1}}}}}}}}},"o":{"docs":{},"df":0,"R":{"docs":{},"df":0,"A":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":2}},"w":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0}},"df":1}}},"M":{"docs":{},"df":0,"A":{"docs":{},"df":0,"E":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}},"a":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"i":{"docs":{},"df":0,"x":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0}},"df":1}}}}},"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":2}}}}},"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}},"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adam/":{"tf":1.0}},"df":1,"u":{"docs":{},"df":0,"m":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0}},"df":1}}}}}}},"u":{"docs":{},"df":0,"o":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}},"t":{"docs":{},"df":0,"a":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}}}}}}},"N":{"docs":{},"df":0,"T":{"docs":{},"df":0,"K":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}},"e":{"docs":{},"df":0,"u":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}}}}}},"O":{"docs":{},"df":0,"n":{"docs":{},"df":0,"l":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}},"p":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":1}},"i":{"docs":{},"df":0,"z":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}}}}}},"P":{"docs":{},"df":0,"a":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0}},"df":1,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}}}}}}}}},"e":{"docs":{},"df":0,"f":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":2}}},"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}}}}}}}},"i":{"docs":{},"df":0,"m":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":1}}},"n":{"docs":{},"df":0,"c":{"docs":{},"df":0,"i":{"docs":{},"df":0,"p":{"docs":{},"df":0,"l":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0}},"df":1}}}}}}},"o":{"docs":{},"df":0,"j":{"docs":{},"df":0,"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"t":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/projects/":{"tf":1.0}},"df":1}}}}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"t":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1}}}}}}},"y":{"docs":{},"df":0,"T":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1}}}}},"t":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0}},"df":2}}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":6}}}}}}},"R":{"docs":{},"df":0,"L":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1},"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"k":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"tf":1.0}},"df":1}},"z":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}},"e":{"docs":{},"df":0,"c":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":1}}}},"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}}}}}}}}}}}},"S":{"docs":{},"df":0,"F":{"docs":{},"df":0,"T":{"docs":{"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"u":{"docs":{},"df":0,"c":{"docs":{},"df":0,"c":{"docs":{},"df":0,"e":{"docs":{},"df":0,"s":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"v":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":2}}}}}}}},"p":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}}}}},"T":{"docs":{},"df":0,"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}}}}}},"e":{"docs":{},"df":0,"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0}},"df":2}}}}},"h":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1,"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{},"df":0,"i":{"docs":{},"df":0,"c":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}}}}}}}},"r":{"docs":{},"df":0,"a":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}}}},"n":{"docs":{},"df":0,"s":{"docs":{},"df":0,"f":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1}},"o":{"docs":{},"df":0,"r":{"docs":{},"df":0,"m":{"docs":{},"df":0,"e":{"docs":{},"df":0,"r":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":3}}}}}}}}}}},"u":{"docs":{},"df":0,"n":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3}}}}}},"V":{"docs":{},"df":0,"S":{"docs":{},"df":0,"C":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1}}}}}},"W":{"docs":{},"df":0,"e":{"docs":{},"df":0,"i":{"docs":{},"df":0,"g":{"docs":{},"df":0,"h":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":3}}}}},"h":{"docs":{},"df":0,"y":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":1}}},"a":{"docs":{},"df":0,"n":{"docs":{},"df":0,"d":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":2}}},"b":{"docs":{},"df":0,"a":{"docs":{},"df":0,"l":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0}},"df":1}},"s":{"docs":{},"df":0,"e":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1}}}},"f":{"docs":{},"df":0,"o":{"docs":{},"df":0,"r":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0}},"df":1}}},"g":{"docs":{},"df":0,"e":{"docs":{},"df":0,"t":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1}}},"i":{"docs":{},"df":0,"n":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0}},"df":1}},"m":{"docs":{},"df":0,"o":{"docs":{},"df":0,"d":{"docs":{},"df":0,"e":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1}}}}},"o":{"docs":{},"df":0,"f":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0}},"df":2}},"p":{"docs":{},"df":0,"o":{"docs":{},"df":0,"s":{"docs":{},"df":0,"t":{"docs":{},"df":0,"s":{"docs":{"https://reichtumqian.pages.dev/":{"tf":1.0}},"df":1}}}}},"s":{"docs":{"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0}},"df":2},"t":{"docs":{},"df":0,"o":{"docs":{"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0}},"df":1,"r":{"docs":{},"df":0,"c":{"docs":{},"df":0,"h":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"f":{"docs":{},"df":0,"o":{"docs":{"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":1}}}}}}}},"r":{"docs":{},"df":0,"l":{"docs":{"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0}},"df":1}}},"u":{"docs":{},"df":0,"s":{"docs":{},"df":0,"i":{"docs":{},"df":0,"n":{"docs":{},"df":0,"g":{"docs":{"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"tf":1.0}},"df":1}}}}},"w":{"docs":{},"df":0,"i":{"docs":{},"df":0,"t":{"docs":{},"df":0,"h":{"docs":{"https://reichtumqian.pages.dev/blog/blog-adamw/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":3}}}},"上":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1},"不":{"docs":{},"df":0,"变":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1}},"与":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":7},"中":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"tf":1.0}},"df":2},"乘":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1},"交":{"docs":{},"df":0,"叉":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1}},"介":{"docs":{},"df":0,"绍":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}},"代":{"docs":{},"df":0,"码":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0}},"df":3}},"优":{"docs":{},"df":0,"化":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}},"似":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1},"使":{"docs":{},"df":0,"用":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}},"先":{"docs":{},"df":0,"验":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1}},"全":{"docs":{},"df":0,"家":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1}},"公":{"docs":{},"df":0,"式":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1}},"分":{"docs":{},"df":0,"类":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"力":{"docs":{},"df":0,"系":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1}},"动":{"docs":{},"df":0,"力":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1,"系":{"docs":{},"df":0,"统":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1}}}},"原":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1},"可":{"docs":{},"df":0,"控":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1,"性":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0}},"df":1}},"视":{"docs":{"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":1,"化":{"docs":{"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":1}}},"同":{"docs":{},"df":0,"步":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}},"后":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1},"器":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1},"图":{"docs":{},"df":0,"像":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"基":{"docs":{},"df":0,"础":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1}},"好":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1},"子":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1},"学":{"docs":{},"df":0,"习":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}},"定":{"docs":{},"df":0,"义":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1},"性":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1}},"实":{"docs":{},"df":0,"现":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":1}},"对":{"docs":{},"df":0,"数":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1}},"工":{"docs":{},"df":0,"具":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}},"巩":{"docs":{},"df":0,"固":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}},"库":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":5},"度":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1},"弹":{"docs":{},"df":0,"性":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}},"形":{"docs":{},"df":0,"状":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"微":{"docs":{},"df":0,"调":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":4}},"快":{"docs":{},"df":0,"速":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1}},"性":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":2},"总":{"docs":{},"df":0,"结":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0}},"df":3}},"手":{"docs":{"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"tf":1.0}},"df":1},"拉":{"docs":{},"df":0,"格":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1,"朗":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1}}},"控":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1,"制":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2}},"搭":{"docs":{},"df":0,"建":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}},"操":{"docs":{},"df":0,"作":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"tf":1.0}},"df":3}},"散":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1},"数":{"docs":{},"df":0,"学":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"文":{"docs":{},"df":0,"件":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}},"方":{"docs":{},"df":0,"式":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}},"日":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1},"时":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1},"最":{"docs":{},"df":0,"优":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2,"控":{"docs":{},"df":0,"制":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2}}}},"权":{"docs":{},"df":0,"重":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}},"架":{"docs":{},"df":0,"构":{"docs":{"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":1}},"核":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1},"格":{"docs":{},"df":0,"式":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0}},"df":1}},"桶":{"docs":{"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"tf":1.0}},"df":1},"概":{"docs":{},"df":0,"率":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1},"览":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"tf":1.0}},"df":2}},"模":{"docs":{},"df":0,"型":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1}},"正":{"docs":{},"df":0,"切":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}},"求":{"docs":{},"df":0,"导":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"tf":1.0}},"df":1}},"法":{"docs":{"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"tf":1.0}},"df":1},"测":{"docs":{},"df":0,"试":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1,"环":{"docs":{},"df":0,"境":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}}}},"然":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1},"熵":{"docs":{"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"tf":1.0}},"df":1},"环":{"docs":{},"df":0,"境":{"docs":{"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"tf":1.0}},"df":1}},"用":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1},"矩":{"docs":{},"df":0,"阵":{"docs":{"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"tf":1.0}},"df":1}},"示":{"docs":{},"df":0,"例":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"tf":1.0}},"df":1}},"神":{"docs":{},"df":0,"经":{"docs":{"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"tf":1.0}},"df":1}},"稳":{"docs":{},"df":0,"定":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1,"性":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0}},"df":1}}},"端":{"docs":{},"df":0,"口":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}},"等":{"docs":{},"df":0,"价":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0}},"df":1}},"算":{"docs":{},"df":0,"法":{"docs":{"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":2}},"系":{"docs":{},"df":0,"统":{"docs":{"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":2}},"约":{"docs":{},"df":0,"束":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":1}},"线":{"docs":{},"df":0,"性":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":2}},"结":{"docs":{},"df":0,"构":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":2}},"网":{"docs":{},"df":0,"络":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"tf":1.0}},"df":2,"结":{"docs":{},"df":0,"构":{"docs":{"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"tf":1.0}},"df":1}}}},"能":{"docs":{"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"tf":1.0}},"df":1},"自":{"docs":{},"df":0,"定":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1,"义":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"tf":1.0}},"df":1}}},"获":{"docs":{},"df":0,"取":{"docs":{"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"tf":1.0}},"df":1}},"训":{"docs":{},"df":0,"练":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1}},"论":{"docs":{},"df":0,"文":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":8}},"调":{"docs":{},"df":0,"用":{"docs":{"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"tf":1.0}},"df":1}},"贝":{"docs":{},"df":0,"叶":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1,"斯":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1}}},"转":{"docs":{},"df":0,"发":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}},"远":{"docs":{},"df":0,"程":{"docs":{"https://reichtumqian.pages.dev/blog/mutagen/":{"tf":1.0}},"df":1}},"连":{"docs":{},"df":0,"续":{"docs":{"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0}},"df":1}},"通":{"docs":{},"df":0,"用":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"tf":1.0}},"df":1}},"问":{"docs":{},"df":0,"题":{"docs":{"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"tf":1.0}},"df":1}},"阅":{"docs":{},"df":0,"读":{"docs":{"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"tf":1.0},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"tf":1.0}},"df":11}},"预":{"docs":{"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"tf":1.0}},"df":1},"验":{"docs":{"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"tf":1.0}},"df":1}}}},"documentStore":{"save":true,"docs":{"https://reichtumqian.pages.dev/":{"body":"Welcome to my site!\n","description":"","id":"https://reichtumqian.pages.dev/","path":"/","title":"Latest posts"},"https://reichtumqian.pages.dev/archive/":{"body":"","description":"","id":"https://reichtumqian.pages.dev/archive/","path":"/archive/","title":"Archive"},"https://reichtumqian.pages.dev/blog/":{"body":"","description":"","id":"https://reichtumqian.pages.dev/blog/","path":"/blog/","title":"Blog"},"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"body":"\n本笔记内容参考：15分钟彻底搞懂！Anaconda Miniconda conda-forge miniforge Mamb​\n\n\nAnaconda 系列\nAnaconda Distribution：Anaconda Distribution 简称 Anaconda 包，就是我们在 Anaconda 官网上下载的安装包内容。其是使用 Python 编写的，提供了大量科学计算领域的二进制文件和 Python 库。\nAnaconda.org：当 Anaconda 爆火后，显然官方维护的库已经不够大家使用了，因此 Anaconda 公司主动提供了一个 anaconda.org​ 平台供大家上传自己的库，并将自己原先整理的 Anaconda Distribution​ 放置在 anaconda.org​ 的 defaults​ 库 Channel 中。\nMiniconda：随着 anaconda.org​ 的出现，大多数情况下我们不希望完整下载 Anaconda Distribution​，毕竟很多时候我们并不想用里面的包，而是只下载一个 conda​ 的包管理器，并从 anaconda.org​ 下载自己想用的包。因此 Anaconda 公司提供了 miniconda​ 工具，只最小程度满足 conda​ 的包管理器，而不去完整按照 Anaconda Distribution​。\nMamba：由于 conda​ 工具本身是用 Python 写的，其在计算依赖等情况下效率非常低，因此社区为了提高 conda​ 的性能，重新实现了那些耗时的模块，这种新实现被称为 Mamba。现在 conda​ 或者 miniforge​ 默认都使用 Mamba。\n注意：一般安装包不要放在 base​环境中，因为 conda 工具本身运行于 base​ 环境，如果把 base​ 环境搞坏了则所有环境都毁了。\nConda-Forge 系列\nConda Forge：随着 Anaconda.org​ 的出现，社区自发组织了一个名为 conda forge​ 的 channel，现在 conda forge​ 已经是更新最快，包内容最多，且完全免费的 channel 了。而 Anaconda 公司现在对商用 defaults​ channel 收费，因此越来越多人转向了 conda forge​。但是由于 conda​ 默认指向 defaults​ 的 channel，如果要使用 conda forge​需要在每个命令后面都加上 -c conda-forge​。\nMiniForge：由于 Anaconda​ 和 Miniconda​ 都默认指向 defaults​ 的 channel，因此社区基于 conda​ 的开源程序重新开发了 miniforge​ 以替代 miniconda​，并且默认均指向 conda-forge​。（但是其实只需要习惯于使用 environment.yml​ 指定 channels​ 就可以）\n注意：现在 conda-forge​ 的兼容性以及包的数量已经被视为超过 defaults​ channel，因此在实际项目中强烈建议只使用 conda-forge​ channel 并且不要使用 defaults​。几乎唯一的特殊情况是要安装特殊优化的包，例如 mkl​。\nEnvironment.yml\n‍\n","description":"","id":"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/","path":"/blog/anaconda-quan-jia-tong/","title":"Anaconda 全家桶介绍"},"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"body":"\nThe proof comes from [1801.10112] Riemannian Walk for Incremental Learning: Understanding Forgetting and Intransigence\n\n\n基本概念\nKL 散度：给定两个分布 $P(x)$ 和 $Q(x)$，它们之间的 KL 散度为\n$$\nD_{KL}(P || Q) = \\mathbb{E}_{x \\sim P}[\\log P(x) - \\log Q(x)].\n$$\n\n为什么 KL 散度不是两个分布的对数直接减一下？因为信息论中真实分布是 $P$，而我们用 $Q$ 去编码数据，因此需要从 $P$ 中去取数据。\n\nFisher 矩阵：给定概率密度函数 $p(x | \\theta)$，Fisher 信息矩阵定义为\n$$\nF(\\theta):=\\mathbb{E}_{x\\sim p(\\cdot\\mid\\theta)}\\Bigg[\\left(\\frac{\\partial}{\\partial\\theta}\\log p(x|\\theta)\\right)\\left(\\frac{\\partial}{\\partial\\theta}\\log p(x|\\theta)\\right)^\\top\\Bigg]\n$$\n其中 $u_i (x;\\theta) :=\\frac{\\partial}{\\partial\\theta_i}\\log p(x|\\theta)$ 为 $\\theta_i$ 的 score function。\nFisher 矩阵的对角元：一般我们假设 score function 的期望为 $0$，即\n$$\n\\mathbb{E}_{x\\sim p(\\cdot|\\theta)}[u_i(x;\\theta)]=0.\n$$\n此时 Fisher 矩阵的对角元素\n$$\nF_{ii} = \\mathbb{E}\\left[u_i^2\\right] = \\mathbb{E} \\left[(u_i - \\mathbb{E}[u_i])^2 \\right] = \\operatorname{Var}(u_i).\n$$\n即表示对于真实数据产生的样本，参数 $\\theta_i$ 对对数似然的一阶梯度的方差。如果方差很大，则说明不同样本会给出很不一样的导数信号，也就是 $\\theta_i$ 很重要。\n\nKL 散度与 Fisher 矩阵的关系\n使用 Fisher 矩阵逼近 KL 散度：设 $\\Delta \\theta \\to 0$，则\n$$\nD_{KL}(p_{\\theta}\\|p_{\\theta+\\Delta\\theta})\\approx\\frac{1}{2}\\Delta\\theta^{\\top}F_{\\theta}\\Delta\\theta,\n$$\n其中 $F_\\theta$ 为 $\\theta$ 处的 Fisher 矩阵。\n证明：这里我们记 $p_\\theta(\\mathbf{z})=p_\\theta(\\mathbf{y}|\\mathbf{x})$ 和 $\\mathbb{E}_{\\mathbf{z}}[\\cdot]=\\mathbb{E}_{\\mathbf{x}\\sim\\mathcal{D},\\mathbf{y}\\sim p_{\\theta}(\\mathbf{y}|\\mathbf{x})}[\\cdot]$。根据 KL 散度的定义\n$$\nD_{KL}(p_{\\theta}(\\mathbf{z})\\|p_{\\theta+\\Delta\\theta}(\\mathbf{z}))=\\mathbb{E}_{\\mathbf{z}}\\left[\\log p_{\\theta}(\\mathbf{z})-\\log p_{\\theta+\\Delta\\theta}(\\mathbf{z})\\right].\n$$\n将 $\\log p_{\\theta + \\Delta \\theta}(\\mathbf{z})$ 在 $\\theta$ 处展开\n$$\n\\log p_{\\theta+\\Delta\\theta}\\approx\\log p_{\\theta}+\\Delta\\theta^{\\top}\\frac{\\partial\\log p_{\\theta}}{\\partial\\theta}+\\frac{1}{2}\\Delta\\theta^{\\top}\\frac{\\partial^{2}\\log p_{\\theta}}{\\partial\\theta^{2}}\\Delta\\theta .\n$$\n将 $\\log p_{\\theta+\\Delta\\theta}$ 的展开式代入到第一个式子，并且消去 $\\mathbb{E}_{\\mathbf{z}}[\\log p_{\\theta}(\\mathbf{z})]$ 得到\n$$\n\\begin{aligned}\nD_{KL}(p_{\\theta}\\|p_{\\theta+\\Delta\\theta})\\approx-:\\Delta\\theta^\\top:\\mathbb{E}_\\mathbf{z}\\left[\\frac{\\partial\\log p_\\theta}{\\partial\\theta}\\right]-\\frac{1}{2}\\Delta\\theta^\\top:\\mathbb{E}_\\mathbf{z}\\left[\\frac{\\partial^2\\log p_\\theta}{\\partial\\theta^2}\\right]\\Delta\\theta\n\\end{aligned} \\tag{1}\n$$\n对于 (1) 式右侧第一项，由于 $\\mathbf{x} \\sim \\mathcal{D}$ 以及 $\\mathbf{y} \\sim p_\\theta(\\mathbf{y}|\\mathbf{x})$，通过计算可以将其消去：\n$$\n\\begin{aligned}\\mathbb{E}_{\\mathbf{z}}\\left[\\frac{\\partial\\log p_{\\theta}(\\mathbf{z})}{\\partial\\theta}\\right]&amp;=\\mathbb{E}_{\\mathbf{x}\\sim\\mathcal{D}}\\left[\\sum_{\\mathbf{y}}p_{\\theta}(\\mathbf{y}|\\mathbf{x})\\frac{\\partial\\log p_{\\theta}(\\mathbf{y}|\\mathbf{x})}{\\partial\\theta}\\right]:,\\\\&amp;=\\mathbb{E}_{\\mathbf{x}\\sim\\mathcal{D}}\\left[\\sum_{\\mathbf{y}}p_{\\theta}(\\mathbf{y}|\\mathbf{x})\\frac{1}{p_{\\theta}(\\mathbf{y}|\\mathbf{x})}\\frac{\\partial p_{\\theta}(\\mathbf{y}|\\mathbf{x})}{\\partial\\theta}\\right]:,\\\\&amp;=\\mathbb{E}_{\\mathbf{x}\\sim\\mathcal{D}}\\left[\\frac{\\partial}{\\partial\\theta}\\sum_{\\mathbf{y}}p_{\\theta}(\\mathbf{y}|\\mathbf{x})\\right]:,\\\\&amp;=\\mathbb{E}_{\\mathbf{x}\\sim\\mathcal{D}}[0]=0:.\\end{aligned} \\tag{2}\n$$\n对于 (1) 式右侧第二项\n$$\n\\frac{\\partial^2\\log p}{\\partial\\theta^2}=\\frac{\\partial}{\\partial\\theta}\\left(\\frac{1}{p}\\frac{\\partial p}{\\partial\\theta}\\right)\n\\Rightarrow\n\\frac{\\partial^2\\log p}{\\partial\\theta^2}=-\\frac{1}{p^2}\\frac{\\partial p}{\\partial\\theta}\\frac{\\partial p}{\\partial\\theta}^\\top+\\frac{1}{p}\\frac{\\partial^2p}{\\partial\\theta^2}\n$$\n其中\n$$\n\\frac{1}{p^2}\\frac{\\partial p}{\\partial\\theta}\\frac{\\partial p}{\\partial\\theta}^\\top=\\left(\\frac{\\partial\\log p}{\\partial\\theta}\\right)\\left(\\frac{\\partial\\log p}{\\partial\\theta}\\right)^\\top\n$$\n因此得到 (1) 式右侧第二项为\n$$\n\\begin{aligned}\n&amp; \\mathbb{E}_{\\mathbf{z}}\\left[-\\frac{\\partial^{2}\\operatorname{log}p_{\\theta}(\\mathbf{z})}{\\partial\\theta^{2}}\\right]=-\\mathbb{E}_{\\mathbf{z}}\\left[\\frac{1}{p_{\\theta}(\\mathbf{z})}\\frac{\\partial^{2}p_{\\theta}(\\mathbf{z})}{\\partial\\theta^{2}}\\right] \\\\\n&amp; +\\mathbb{E}_{\\mathbf{z}}\\left[\\left(\\frac{\\partial\\log p_\\theta(\\mathbf{z})}{\\partial\\theta}\\right)\\left(\\frac{\\partial\\log p_\\theta(\\mathbf{z})}{\\partial\\theta}\\right)^\\top\\right], \\\\\n&amp; =-\\mathbb{E}_{\\mathbf{z}}\\left[\\frac{1}{p_{\\theta}(\\mathbf{z})}\\frac{\\partial^{2}p_{\\theta}(\\mathbf{z})}{\\partial\\theta^{2}}\\right]+\\tilde{F}_{\\theta}.\n\\end{aligned} \\tag{3}\n$$\n这里 $\\tilde{F}_\\theta$ 为 True Fisher，其与 Empirical Fisher 的区别在于其期望是取自模型分布 $\\mathbf{x} \\sim \\mathcal{D}$ 以及 $\\mathbf{y} \\sim p_\\theta(\\mathbf{y}|\\mathbf{x})$ 而非真实分布 $(\\mathbf{x}, \\mathbf{y}) \\sim \\mathcal{D}$：\n$$\n{F}_\\theta=\\mathbb{E}_{\\mathbf{z}\\sim p_\\theta}\n\\begin{bmatrix}\ng(\\mathbf{z};\\theta)g(\\mathbf{z};\\theta)^\\top\n\\end{bmatrix}, \\quad\n{F}_\\theta=\\mathbb{E}_{(\\mathbf{x},\\mathbf{y})\\sim\\mathcal{D}}\\left[g(\\mathbf{x},\\mathbf{y};\\theta)g(\\mathbf{x},\\mathbf{y};\\theta)^\\top\\right]\n$$\n仿照 (2) 的推导过程，我们可以得到 (3) 右侧第一项也为 $0$。并且在 optimum 最优点处，模型的分布 $\\mathbf{x} \\sim \\mathcal{D}, \\mathbf{y} \\sim p_\\theta(\\mathbf{y}|\\mathbf{x})$ 逼近真实分布 $(\\mathbf{x}, \\mathbf{y}) \\sim \\mathcal{D}$，此时 $F_\\theta = \\tilde{F}_\\theta$，因此\n$$\nD_{KL}(p_{\\theta}\\|p_{\\theta+\\Delta\\theta})\\approx \\tilde{F}_{\\theta} \\approx F_\\theta.\n$$\n‍\n‍\n","description":"","id":"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/","path":"/blog/approximate-kl-divergence-using-fisher-information-matrix/","title":"Approximate KL Divergence using Fisher Information Matrix"},"https://reichtumqian.pages.dev/blog/blog-adam/":{"body":"\n\n\n\n\n","description":"","id":"https://reichtumqian.pages.dev/blog/blog-adam/","path":"/blog/blog-adam/","title":"Adam: Adaptive Moment Estimation"},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"body":"AdamW 是对 Adam 的改进版，Adam 在处理 Weight Decay 时存在一些问题，而 AdamW 正解决了该问题。\n\nL2 Regularization 与 Weight Decay\nL2 Regularization 的定义：给定原始损失函数 $f$，使用 L2 Regularization 的优化器修改了损失函数为\n$$\nf_{\\text{total}} (\\theta) = f(\\theta) + \\frac{\\lambda}{2}\\|\\theta\\|_2^2.\n$$\n其中 $\\theta$ 表示模型中的权重参数（一般不包含偏置项 biases），$\\|\\theta\\|_2^2$ 是 $\\theta$ 的 L2 范数平方。当我们对其求梯度可以得到其在 SGD 中的更新格式\n$$\n\\nabla f_{\\text{total}}(\\theta)=\\nabla f(\\theta)+\\lambda\\theta\n\\quad \\Rightarrow \\quad\n\\theta_{t+1}=(1-\\eta\\lambda)\\theta_t-\\eta \\nabla f(\\theta).\n$$\nWeight Decay 的定义：带 Weight Decay 的优化器修改了梯度更新规则为\n$$\ng = \\nabla f(\\theta) + \\lambda \\theta,\n$$\n同理我们可以得到其在 SGD 中的参数更新格式：\n$$\n\\theta_{t+1}=(1-\\eta\\lambda)\\theta_t-\\eta \\nabla f(\\theta)\n$$\nL2 Regularization 与 Weight Decay 的等价性：从上面的推导可以看出，在 SGD 中 L2 Regularization 与 Weight Decay 是等价的。但是这一结论在 Adam 中并不成立。\nL2 Regularization 与 Weight Decay 的目的：两个方法的根本目的是为了防止模型参数过大而导致过拟合（因为 L2 Regularization 损失函数中对大参数进行了惩罚），很多时候当模型参数过大时，其在训练数据上能表现得很好，但是在验证/测试数据上表现很差。\nL2 Regularization 与 Weight Decay 的区别：虽然两者在 SGD 中等价，但是对大参数的惩罚的最根本原因是 L2 Regularization 中修改的损失函数。这也为 Adam 中的错误处理埋下了伏笔。\n\nAdam 中的 Weight Decay\nAdam 中的 Weight Decay 处理方式：Adam 中 Weight Decay 的处理放在了梯度的计算上，即\n$$\ng_t \\leftarrow \\nabla_\\theta f_t(\\theta_{t-1}) + \\lambda \\theta_{t-1}.\n$$\nAdam 中 Weight Decay 处理的问题：Adam with L2 regularization 的最大错误就是\n$$\n\\text{忽略了修改损失函数和修改更新规则的等价性}\n$$\n我们本质上是想要惩罚大参数，也就是实现 L2 Regularization 中的损失函数。而 Adam 延续了 SGD 的定式思维，认为 Weight Decay 中的更新格式就能实现 L2 Regularization 中的损失函数，而事实上 Adam 的自适应机制导致 Weight Decay 的格式被自适应步长所影响，达不到 L2 Regularization 格式的目标。\n\n\nAdamW 的格式\nAdamW 的改进：AdamW 重新实现了原本 L2 Regularization 的目标，将 Weight Decay 从梯度中解耦，放到最后一步计算，从而提高了泛化性。\n\n","description":"","id":"https://reichtumqian.pages.dev/blog/blog-adamw/","path":"/blog/blog-adamw/","title":"AdamW: Adam with Decoupled Weight Decay"},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"body":"KL 散度\nKL 散度（Kullback-Leibler Divergence）是一种非对称的度量，用于量化一个概率分布和另一个参考概率分布的差异。\nKL 散度的定义：给定概率分布 $P(x)$ 和 $Q(x)$，若它们是离散概率分布，则 KL 散度定义为\n$$\nD_{KL} (P ||Q) := \\sum_x P(x) \\log \\frac{P(x)}{Q(x)}.\n$$\n若 $P(x)$ 和 $Q(x)$ 是连续概率分布，对应概率密度函数为 $p(x)$ 和 $q(x)$，则 KL 散度为\n$$\nD_{KL} (P ||Q) := \\int_{-\\infty}^{\\infty} p(x) \\log \\frac{p(x)}{q(x)} \\mathrm{d} x.\n$$\nKL 散度的性质：KL 散度满足除了对称性外的度量性质\n\n非负性：$D_{KL}(P || Q) \\geq 0$，且 $D_{KL}(P || Q) = 0$ 当且仅当 $P(x) \\equiv Q(x)$。\n非对称性：$D_{KL}(P || Q) \\neq D_{KL}(Q || P)$。\n\nKL 散度的信息论解释：$D_{KL}(P || Q)$ 表示使用 $Q$ 来编码 $P$ 时，平均每个样本所需的额外信息量（比特数）。KL 散度越小，说明 $Q$ 对 $P$ 的近似程度越好，因此最小化 KL 散度也是机器学习中常用的优化目标。\n信息熵与交叉熵\n信息熵（Information Entropy）用于衡量一个随机变量的不确定性，一个系统越混乱，越不可预测，则其信息熵越高。交叉熵（Cross Entropy）衡量着我们使用错误的分布 $Q$ 去衡量真实分布 $P$ 时所需要的平均编码长度。\n信息熵的定义：信息熵定义为一个随机变量所包含信息的平均期望，给定离散随机变量 $X$，其可取 $x_1, x_2, \\cdots, x_n$，对应概率 $P(x_1), P(x_2), \\cdots, P(x_n)$，则信息熵定义为\n$$\nH(x) = - \\sum_{i = 1}^n P(x_i) \\log_bP(x_i),\n$$\n其中 $b$ 决定了熵的单位，$b = 2$ 表示 bit，$b=e$ 表示 nat，$b = 10$ 表示 hart。\n交叉熵的定义：给定概率分布 $P(x)$ 和 $Q(x)$，交叉熵函数为\n$$\nH(P, Q) := - \\sum_xP(x)\\log Q(x).\n$$\n交叉熵的信息论理解：如果 $Q$ 能完美预测真实分布 $P$，那么交叉熵就等于真实分布的信息熵 $H(P)$，此时编码成本最低。如果 $Q$ 的预测非常不准，那么交叉熵就会远大于信息熵。因此在机器学习中我们往往希望最小化交叉熵。\n对数似然\n似然函数在统计学中用于评估模型参数对观测数据的拟合程度，似然函数越大说明当前模型的参数对观测数据的拟合程度越高。\n似然函数 Likelihood Function：给定数据集 $X = \\{x_1, x_2, \\cdots, x_n\\}$ 和由参数 $\\theta$ 控制的概率模型 $P(X|\\theta)$，似然函数定义为：\n$$\nL(\\theta|X) := P(X|\\theta) = \\prod_{i = 1}^n P(x_i|\\theta).\n$$\n即表示着在 $\\theta$ 参数情况下，从概率模型中抽取得到数据集 $X$ 的概率。\n最大化似然估计 MLE：显然 $L(\\theta|X)$ 越大，那么模型就越可能生成当前的数据集，也就是更加贴合数据集。因此一般我们的目标是寻找一组参数 $\\hat{\\theta}$，使得似然函数最大化\n$$\n\\hat{\\theta}_{MLE} = \\arg\\max_\\theta L(\\theta|X).\n$$\n对数似然函数 Log-Likelihood Function：由于似然函数的格式是连乘，在计算上既复杂又容易数值下溢，因此通常会使用对数似然函数 Log-Likelihood Function：\n$$\n\\log L(\\theta|X) = \\sum_{i = 1}^n \\log P(x_i|\\theta).\n$$\n可以看出最大化似然估计也等价于最大化对数似然估计，因此实际优化中一般我们都使用最大对数似然。\n三者的关系\nKL 散度与交叉熵：KL 散度为交叉熵与真实分布熵的差，即\n$$\nD_{KL}(P||Q) = H(P,Q) - H(P).\n$$\n因此最小化 KL 散度等价于最小化 Cross-Entropy，而在计算时由于交叉熵更容易计算，因此通常使用交叉熵函数。\nKL 散度与对数似然：这里我们假设数据集由数据分布 $P_{\\text{data}}(x)$ 生成，分布模型为 $P_{\\text{model}}(x|\\theta)$，此时\n$$\nD_{KL}(P_{\\text{data}} || P_{\\text{model}}) = \\sum_{x} P_{\\text{data}}(x) \\log P_{\\text{data}}(x) - \\sum_{x} P_{\\text{data}}(x)\\log P_{\\text{model}}(x)\n$$\n右侧第一项即 $P_{\\text{data}}$ 的信息熵，由于 $P_{\\text{data}}$ 是固定的，因此此项是一个常数，而第二项即 $P_{\\text{data}}$ 和 $P_{\\text{model}}$ 的交叉熵。因此最小化 KL 散度等价于最大化对数似然。\n‍\n","description":"","id":"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/","path":"/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/","title":"KL 散度、交叉熵与对数似然"},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"body":"LaSalle’s Invariance Principle 是 Lyapunov’s Second Method 的延伸和推广。\nLaSalle’s Invariance Principle 的核心思想\n回顾 Lyapunov’s Second Method：Lyapunov’s Second Method 告诉我们，如果能为一个 Dynamical System 找到一个能量函数（Lyapunov 函数） $V(x)$，并且这个能量函数沿着系统的轨迹是严格递减的（$\\dot{V}(x) &lt; 0$），那么系统会渐进稳定（Asymptotically Stable）于能量最低点（通常指原点）。\nLaSalle’s Invariance Principle 的思想：很多时候 $V(x)$ 不一定是严格递减的，例如 $\\dot{V}(x) \\leq 0$，这意味着系统的能量在某些地方可能暂时不变，LaSalle’s Invariance Principle 就是为了解决这个问题。其核心思想为：\n\n能量不增且有下界：$V(x)$ 永不增加且有下界，所以它一定收敛到某个常数；\n寻找能量不变的区域：既然能量最终不再变化，那么 $x(t)$ 一定趋近哪些让能量不再变化的点，即 $E = \\{x: \\dot{V}(x) = 0\\}$；\n在不变区域中寻找归宿：系统轨迹 $x(t)$ 虽然会趋于 $E$，但是其不能在 $E$ 中乱跑，其最终肯定趋于 $E$ 内部的一个不变集 $M$。即一旦 $x(t)$ 进入了 $M$，其就再也出不来了；\n结论：即使 $\\dot{V}(x)$ 只是半负定，我们也能断定系统轨迹 $x(t)$ 最终收敛到 $E$ 中的最大不变集 $M$。\n\n预备知识：不变集\n正不变集 Positively Invariant Set：对于集合 $\\Omega \\subset \\mathbb{R}^n$ 和 Dynamical System $\\dot{x} = f(x)$，若对于任何从集合内部出发的 $x(0) \\in \\Omega$，其后的整个轨迹 $x(t)$ 都停留在 $\\Omega$ 内部，则称其是 positively invariant 的。\n最大不变集 Largest Invariant Set：给定集合 $E$，则 $M \\subset E$ 是 $E$ 的最大不变集是所有完全包含于 $E$ 的系统轨迹的并。即如果一条轨迹始终在 $E$ 内部，则其属于 $M$，一旦其出过 $E$，则其就不属于 $M$ 了。\nLaSalle’s Invariance Principle 定理\nLaSalle’s Invariance Principle：考虑 $\\dot{x} = f(x)$，其中 $x \\in D \\subset \\mathbb{R}^n$，$f:D \\to \\mathbb{R}^n$ 满足局部 Lipschitz 条件。若存在紧集 $\\Omega \\subset D$ 关于该系统 positively invariant，以及连续可微的 $V: \\Omega \\to \\mathbb{R}$ 满足\n$$\n\\dot{V}(x) = \\nabla V(x) \\cdot f(x) \\leq 0, \\quad \\forall x \\in \\Omega.\n$$\n那么对于任意初始条件 $x(0) \\in \\Omega$，系统轨迹 $x(t)$ 都会收敛到 $E = \\{x \\in \\Omega: \\dot{V}(x) = 0\\}$ 的最大不变集 $M$。\n\n上述定理要求我们预先找到一个紧集 $\\Omega$，但是在实际问题中往往很难构造出 $\\Omega$，因此我们可以考虑下面更通用的版本。\n\nLaSalle’s Invariance Principle (Generalized) ：考虑 $\\dot{x} = f(x)$，其中 $x \\in D \\subset \\mathbb{R}^n$，$f:D \\to \\mathbb{R}^n$ 满足局部 Lipschitz 条件。若存在连续可微的 $V: D \\to \\mathbb{R}$ 满足\n$$\n\\dot{V}(x) = \\nabla V(x) \\cdot f(x) \\leq 0, \\quad \\forall x \\in \\Omega.\n$$\n且对于初始条件 $x(0) \\in D$，若其轨迹 $x(t)$ 是有界的且始终保持在 $D$ 内，则 $x(t)$ 收敛到 $E = \\{x \\in \\Omega: \\dot{V}(x) = 0\\}$ 的最大不变集 $M$。\n如何保证轨迹有界？ 若 $V(x)$ 是 Radially Unbounded 的，且 $\\dot{V}(x) \\leq 0$，则 $x(t)$ 是有界的。\n\n径向无界 Radially Unbounded：如果当 $\\|{x}\\| \\to \\infty$ 时，$V({x}) \\to \\infty$，则称 $V({x})$ 是 radially unbounded 的。\n证明：因为当 $\\|x\\| \\to \\infty$ 时，$V(x) \\to \\infty$，这与 $\\dot{V}(x) \\leq 0$ 相矛盾。\n\n‍\n","description":"","id":"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/","path":"/blog/blog-lasalle-s-invariance-principle/","title":"LaSalle's Invariance Principle"},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"body":"背景：全微调（Full Fine-Tuning）\n在 LoRA 出现前，一般进行大模型微调都会执行全微调，即将原模型的所有参数都在下游任务上进行调整。\n网络层的数学表示：这里以线性层（全连接层）为例，假设输入向量为 $x \\in \\mathbb{R}^k$，输出向量为 $h \\in \\mathbb{R}^d$，该层的计算可以表示为：\n$$\nh = W x,\n$$\n其中 $W \\in \\mathbb{R}^{d \\times k}$ 是该层权重矩阵。\n全量微调：假设预训练好的权重矩阵为 $W_0 \\in \\mathbb{R}^{d \\times k}$，Full Fine-Tuning 在新的数据集上更新完整的权重矩阵\n$$\nW = W_0 + \\Delta W,\n$$\n其中 $\\Delta W \\in \\mathbb{R}^{d \\times k}$ 是微调过程中的权重更新量。\nLoRA 的思想假设\n低秩假设：LoRA (Low-Rank Adaptation) 的基本思想是微调过程中，权重更新矩阵 $\\Delta W$ 有很低的 intrinsic rank，即 $\\Delta W$ 尺寸虽然很大，但是其包含的信息可以用远小于其维数的秩 $r$ 来有效表示。\n低秩分解 Low-Rank Decomposition：LoRA 不学习巨大的 $\\Delta W$ 矩阵本身，而是通过 Low-Rank Decomposition 来近似它，即\n$$\n\\Delta W = BA,\n$$\n其中 $B \\in \\mathbb{R}^{d \\times r}$， $A \\in \\mathbb{R}^{r \\times k}$，$0 &lt; r \\ll \\min\\{d, k\\}$ 为 LoRA 近似矩阵的秩。通常 $A$ 使用高斯分布初始化，$B$ 使用零初始化，这样 $\\Delta W$ 就被初始化为 $\\mathcal{O}$。\nLoRA 的更新步骤：在实际程序中，我们一般会见到 lora_r​ 和 lora_alpha​ 两个超参数，因为实际更新的方式为\n$$\nW = W_0 + \\frac{\\alpha}{r}(BA),\n$$\n其中 $r$ 是 LoRA rank，$\\alpha$ 为 scaling factor。一般来说，我们会将 lora_alpha​ 设置得比 lora_r​ 大一点，例如 $\\alpha = 2r$​。\nLoRA 训练与推理：在训练过程中，我们冻结 $W_0$，只更新 $A, B$。而在推理部署时，将 $A,B$ 合并回权重矩阵 $W$，这样我们在推理过程中也不需要额外的内存/显存开销。\n‍\n","description":"","id":"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/","path":"/blog/blog-lora-low-rank-adaptation/","title":"LoRA (Low-Rank Adaptation)"},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"body":"背景\n近期想将我们设计的优化器在 MAE + ViTs 预训练上进行测试，原本想用 Hugging Face​ 的 transformers​ 自带的 run_mae.py​ （见 transformers/examples/pytorch/image-pretraining）进行测试，结果测试出来发现表现不是太好（不知道是不是我哪里搞错了）。比如在 CIFAR-10 上进行预训练，几个 Epoch （对应 200 个 global step） 后 train loss 就不下降了。\n​\n而 Facebook 的官方 mae​ 不带训练日志，而且环境有点儿过于古老了，装起来容易遇到各种 Bug。最后找到了 pengzhiliang/MAE-pytorch 感觉可以用来测试一下，包含完整的训练日志。\n准备数据集（ImageNet-1k）\n我从 Hugging Face 官网下载了 ImageNet 数据集（见 ILSVRC/imagenet-1k · Datasets at Hugging Face ），国内下载速度不行的话可以尝试使用 hf-mirror​ 站点。下载完成内容如下：\n\n\n如果使用 hugging face 的 datasets​ 库加载数据集则不需要自己手动处理 tar.gz​ 文件\n\n训练集压缩包中的图片名称类似于 n02974003_1569_n02974003.JPEG​，其中 n02974003​ 是 class label，1569​ 是 image ID。验证集中的图片名称类似于 ILSVRC2012_val_00027905_n02107908.JPEG​ 。一般的程序读取 ImageFolder 会需要将数据集组织为以下格式\n\n因此我们需要首先将数据集全部解压出来，然后写个脚本按类别分到不同子文件夹。\n\n将所有图片解压到临时文件夹\n\n\n\n运行脚本整理文件结构，首先 mkdir processed_data​ 然后执行脚本\n\n\n运行测试\n\n首先下载代码\n\n\n\n创建环境：由于 requirements.txt​ 中的包版本较老，使用新版 python 大概率装不了各种报错，我这里用 conda 创建一个 python=3.9 的环境，然后去 Previous PyTorch Versions 查看对应的 CUDA 版本。我也提供了 environment.yml​ 可直接更新环境（我用的是 4090）：\n\n\n\n新建一个 run.sh​ 辅助执行\n\n\n\n执行 ./run.sh​ 成功运行程序\n\n\n附上跑了 6 个 Epoch 的学习曲线\n​\n‍\n","description":"","id":"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/","path":"/blog/blog-mae-ce-shi-huan-jing-da-jian/","title":"MAE 测试环境搭建"},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"body":"前面阅读学习了 MSA 算法求解 Optimal Control 问题，但是 MSA 的具体格式是基于神经网络结构的，本次总结了对于更加一般的 Optimal Control 问题，如何使用 MSA 进行求解。\n\nOptimal Control 问题描述\nOptimal Control 问题：这里我们考虑动力系统\n$$\n\\dot{x}(t) = f(t, x(t), u(t)),\n$$\n其中 $t \\in [t_0, t_f]$ 是时间，$x(t) \\in \\mathbb{R}^n$ 是状态向量 state vector，$u(t) \\in \\mathcal{U} \\subset \\mathbb{R}^m$ 是控制向量，初值条件 $x(t_0) = x_0$，不考虑终值条件（如果有的话 Co-State Equation 的终值条件会有点儿不同）。Cost Functional 为\n$$\nJ[u(\\cdot)] = \\phi(t_f, x(t_f)) + \\int_{t_0}^{t_f} L(t, x(t), u(t))\\mathrm{d}t.\n$$\n其中 $\\phi(t_f, x(t_f))$ 是 terminal cost，$L(t, x(t), u(t))$ 是 running cost。\nPMP 格式：考虑 Hamiltonian 函数：\n$$\nH(t,x(t),p(t),u(t)):=L(t,x(t),u(t))+p(t)^\\top f(t,x(t),u(t))\n$$\n其中 $p(t)$ 是 co-state vector。PMP 必要条件包含：\n\nState Equation：如下方程满足初值条件 $x^\\ast(t_0) = x_0$​\n\n$$\n\\dot{x}^*(t)=\\nabla_pH(t,x^*(t),p^*(t),u^*(t))=f(t,x^*(t),u^*(t))\n$$\n\nCo-State Equation：如下方程满足终值条件\n\n$$\n\\dot{p}^*(t)=-\\nabla_xH(t,x^*(t),p^*(t),u^*(t))=-\\left(\\nabla_xL+(\\nabla_xf)^\\top p^*(t)\\right)\n$$\n$$\np^*(t_f)=\\nabla_x\\phi(t_f,x^*(t_f))\n$$\n\nOptimality Condition：\n\n$$\nu^*(t)=\\arg\\min_{u\\in \\mathcal{U}}H(t,x^*(t),p^*(t),u)\n$$\n\n通用 MSA 算法\n\n\n初始化：给定初始控制函数 $u^{(0)}(t)$，设定迭代次数 $K$，初始化计数器 $k = 0$\n\n\n求解 State Equation：给定当前控制函数 $u^{(k)}(t)$，从 $t_0$ 到 $t_f$ 正向求解 state equation\n\n\n$$\n\\dot{x}^{(k)}(t)=f(t,x^{(k)}(t),u^{(k)}(t)), \\quad x^{(k)}(t_0) = x_0.\n$$\n\n求解 Co-State Equation：利用 $x^{(k)}(t)$ 和控制 $u^{(k)}(t)$，从 $t_f$ 到 $t_0$ 反向计算 co-state equation\n\n$$\n\\dot{p}^{(k)}(t)=-\\nabla_xL(t,x^{(k)}(t),u^{(k)}(t))-\\left[\\nabla_xf(t,x^{(k)}(t),u^{(k)}(t))\\right]^Tp^{(k)}(t),\n$$\n$$\np^{(k)}(t_f)=\\nabla_x\\phi(t_f,x^{(k)}(t_f)).\n$$\n\n更新控制函数：利用 $x^{(k)}(t)$ 和 $p^{(k)}(t)$ 更新 $u^{(k+1)}(t)$，对于每个时间点 $t \\in [t_0, t_f]$，计算\n\n$$\nu^{(k+1)}(t)=\\arg\\min_{u\\in \\mathcal{U}}H(t,x^{(k)}(t),p^{(k)}(t),u)\n$$\n\n设置 $k = k+1$ 并且反复上述三步，直到达到迭代次数上限 $K$ 或者 $u^{(k)}(t)$ 的变化足够小：\n\n$$\n\\int_{t_0}^{t_f}||u^{(k+1)}(t)-u^{(k)}(t)||^2dt&lt;\\epsilon.\n$$\n\n‍\n","description":"","id":"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/","path":"/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/","title":"Method of Successive Approximations 通用格式"},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"body":"\nOriginal Paper: [1803.01299] An Optimal Control Approach to Deep Learning and Applications to Discrete-Weight Neural Networks\n\n\nThe Optimal Control Viewpoint\nNeural Networks as Dynamical System: Let $T \\in \\mathbb{Z}_+$ denote the number layers and $\\{x_{s,0} \\in \\mathbb{R}^{d_0}: s = 0, 1, \\cdots, S\\}$ represent $S + 1$ inputs (images, time-series). Consider the dynamical system\n$$\nx_{s,t+1}=f_t(x_{s,t},\\theta_t),\\quad t=0,1,\\ldots,T-1,\n$$\nwhere $f_{t}:\\mathbb{R}^{d_{t}}\\times\\Theta_{t}\\to\\mathbb{R}^{d_{t+1}}$ is a transformation on the state, $\\Theta_t$ is the trainable parameter set.\nObjective of Training: The goal of training is to adjust the weights $\\bm{\\theta} := \\{\\theta_t: t = 0, 1, \\cdots, T-1\\}$ to minimize some loss function between final output $x_{s, T}$ and true targets $y_s$ of $x_{s,0}$.\nStatement of Problem: Define $\\Phi_s: \\mathbb{R}^{d_T} \\to \\mathbb{R}$ that measures the loss, and the average loss function is\n$$\n\\frac{1}{S}\\sum_s \\Phi_s(x_{s,T})\n$$\nWe also consider some regularization terms $L_t: \\mathbb{R}^{d_t} \\times \\Theta_t \\to \\mathbb{R}$, thus the problem is\n$$\n\\min_{\\boldsymbol{\\theta}\\in\\boldsymbol{\\Theta}}J(\\boldsymbol{\\theta}):=\\frac{1}{S}\\sum_{s=1}^{S}\\Phi_{s}(x_{s,T})+\\frac{1}{S}\\sum_{s=1}^{S}\\sum_{t=0}^{T-1}L_{t}(x_{s,t},\\theta_{t}),\n$$\n$$\nx_{s,t+1}=f_t(x_{s,t},\\theta_t), \\quad t=0,\\cdots,T-1, \\quad s\\in \\{1,2,\\cdots,S\\}\n$$\nwhere $\\bm{\\Theta} := \\{\\Theta_0 \\times \\cdots \\times \\Theta_{T-1}\\}$.\n\nThe Pontryagin’s Maximum Principle\nHamiltonian Function: Let $\\bm{\\theta}^\\ast = \\{\\theta_0, \\cdots, \\theta_{T-1}\\} \\in \\bm{\\Theta}$ be a solution of the problem. For each $t$, define the Hamiltonian function $H_{t}:\\mathbb{R}^{d_{t}}\\times\\mathbb{R}^{d_{t+1}}\\times\\Theta_{t}\\to\\mathbb{R}$​\n$$\nH_t(x,p,\\theta):=p\\cdot f_t(x,\\theta)-\\frac{1}{S}L_t(x,\\theta).\n$$\nwhere $p \\in \\mathbb{R}^{d_{t+1}}$ is the co-state vector.\nDiscrete PMP, Informal Statement: Let $f_t$ and $\\Phi_s, s = 1,2,\\cdots, S$ be sufficiently smooth in $x$. Assume for each $t$ and $x \\in \\mathbb{R}^{d_t}$, the sets $\\{f_t(x,\\theta): \\theta \\in \\Theta_t\\}$ and $\\{L_t(x,\\theta): \\theta \\in \\Theta_t\\}$ are convex. Then there exists $\\boldsymbol{p}_{s}^{*}:=\\{p_{s,t}^{*}:t=0,\\ldots,{T}\\},$ such that\n$$\nx_{s,t+1}^* = \\nabla_p H_t(x_{s,t}^*, p_{s,t+1}^*, \\theta_t^*), \\quad x_{s,0}^* = x_{s,0}\n$$\n$$\np_{s,t}^* = \\nabla_x H_t(x_{s,t}^*, p_{s,t+1}^*, \\theta_t^*), \\quad p_{s,T}^* = -\\frac{1}{S} \\nabla \\Phi_s(x_{s,T}^*)\n$$\n$$\n\\sum_{s=1}^S H_t(x_{s,t}^*, p_{s,t+1}^*, \\theta_t^*) \\geq \\sum_{s=1}^S H_t(x_{s,t}^*, p_{s,t+1}^*, \\theta), \\forall \\theta \\in \\Theta_t\n$$\nfor $t = 0, 1, \\cdots, T-1$ and $s = 1,2,\\cdots, S$.\n\nThe Method of Successive Approximations (MSA)\nStatement of MSA Algorithm: Start from an initial guess $\\boldsymbol{\\theta}^{0}=\\{\\theta_{t}^{0}\\in\\Theta_{t}:t=0\\ldots,T-1\\}$,\n\nState Equation: $x_{s, t}$ means the state of the $s$-th sample at the $t$-th layer, $f_t$ is the transformation function at the $t$-th layer, $\\theta_t$ is the control at the $t$-th layer\n\n$$\nx_{s,t+1}^{\\boldsymbol{\\theta}^0}=f_t(x_{s,t}^{\\boldsymbol{\\theta}^0},\\theta_t^0),\\quad x_{s,0}^{\\boldsymbol{\\theta}^0}=x_{s,0},\n$$\n\nCo-State Equation: $p_{s,t}$ means the co-state of the $s$-th sample at the $t$-th layer, $\\Phi_s$ measures the loss of the $s$-th sample, $H_t$ is the Hamiltonian function\n\n$$\np_{s,t}^{\\boldsymbol{\\theta}^0}=\\nabla_xH_t(x_{s,t}^{\\boldsymbol{\\theta}^0},p_{s,t+1}^{\\boldsymbol{\\theta}^0},\\theta_t^0),\\quad p_{s,T}^{\\boldsymbol{\\theta}^0}=-\\frac{1}{S}\\nabla\\Phi_s(x_{s,T}^{\\boldsymbol{\\theta}^0}),\n$$\n\nMaximization of the Hamiltonian:\n\n$$\n\\theta_t^1=\\arg\\max_{\\theta\\in\\Theta_t}\\sum_{s=1}^SH_t(x_{s,t}^{\\boldsymbol{\\theta}^0},p_{s,t+1}^{\\boldsymbol{\\theta}^0},\\theta),\n\\quad t=0,\\ldots,T-1.\n$$\n\nMSA Algorithm:\n\n\nInitialize: $\\boldsymbol{\\theta}^{0}=\\{\\theta_{t}^{0}\\in\\Theta_{t}:t=0\\ldots,T-1\\};$\n\n\nFor $k = 0$ to $K$ do\n\n$x_{s,t+1}^{\\boldsymbol{\\theta}^k}=f_t(x_{s,t}^{\\boldsymbol{\\theta}^k},\\theta_t^k)$ and $x_{s,0}^{\\boldsymbol{\\theta}^k}=x_{s,0}$ for all $s$ and $t$;\n$p_{s,t}^{\\boldsymbol{\\theta}^k}=\\nabla_xH_t(x_{s,t}^{\\boldsymbol{\\theta}^k},p_{s,t+1}^{\\boldsymbol{\\theta}^k},\\theta_t^k),p_{s,T}^{\\boldsymbol{\\theta}^k}=-\\frac{1}{S}\\nabla\\Phi_s(x_{s,T})$ for all $s$ and $t$;\n$\\theta_t^{k+1}=\\arg\\max_{\\theta\\in\\Theta_t}\\sum_{s=1}^SH_t(x_{s,t}^{\\boldsymbol{\\theta}^k},p_{s,t+1}^{\\boldsymbol{\\theta}^k},\\theta)$ for $t = 0, \\cdots, T-1$;\n\n\n\nEnd for\n\n\n\n","description":"","id":"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/","path":"/blog/blog-method-of-successive-approximations/","title":"论文阅读：Method of Successive Approximations"},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"body":"\n近期想测试 Muon 优化器的效果，看了下 Muon 官方 Github 的实现，发现无法像 Adam 或者 AdamW 那样直接简单地调用。还是要学习一下 pytorch​ 中 model.parameters()​ 的结构，最终搞明白如何使用 Muon​ 优化器。\n背景\n众所周知，我们一般创建 Adam​ 等优化器时只需要把模型内部的参数 model.parameters()​ 传给优化器就可以很简单地创建一个优化器，例如以下代码：\n\n虽然大多数优化器都能以上面这样简单的方式进行创建，Muon​ 却不太一样。Muon​ 是针对二维以及更高维张量的优化器，而剩余的一维张量（例如偏置、Embedding层、输出层）则交给 Adam。按照其官方仓库的说明，要把 AdamW​ 替换为 Muon​ 得进行一定程度的修改：\n\n可以看出上面的代码涉及到了一些 Pytorch​ 中 Parameters​ 的结构，对于没咋写过优化器的炼金师（我）来说还是有点儿不熟悉的，而且可能要根据项目需求进行进一步修改。所以要正确使用 Muon​ 优化器，还是得充分理解 Pytorch​ 中 Parameters​ 的结构。\nModel.Parameters() 的本质\nParameter 对象：在 Pytorch​ 中，一个神经网络模型（对应 torch.nn.Module​ 类）由多个层组成，每个层又包含一些可以学习的参数（主要是权重 weights​ 和偏置 bias​），这些参数被封装为 torch.nn.Parameter​ 对象。torch.nn.Parameter​ 对象本质上是特殊的 Tensor​，其与普通 Tensor​ 的区别在于其被注册为模型的参数，在调用 loss.backward()​ 时 Pytorch​ 会自动计算其对应的梯度。\nmodel.parameters() ：model.parameters()​ 返回一个迭代器（Iterator），我们可以用它遍历模型中注册的 torch.nn.Parameter​ 对象。大多数情况下，我们只需要使用这个迭代器就可以创建一个优化器，例如：\n\nParameter Groups 参数组：除了使用上述的 parameter iterator 创建优化器外，Pytorch​ 还支持传入一组不同配置的参数（一个字典组成的列表），列表中每个字典定义了一个参数和对应的超参，包含 params​ （torch.nn.Parameter​ 对象的列表，而非迭代器）以及训练这些模型参数的超参（例如 lr​、weight_decay​ 等）。例如外面在前面例子的基础上希望对每层参数使用不同的学习率，则可以按下面的方式定义优化器\n\n注意：model.parameters()​ 返回的只能返回 iterator。parameter groups 必须要在外部定义。\nmodel.named_parameters() ：为了更方便地筛选和命名参数， Pytorch​ 还支持 named_parameters()​ 方法，类似于 parameters()​ 方法，其返回了一个迭代器，但是每步迭代得到的的元素是 (name, parameters)​ 的元组。那 name​ 是哪里来的呢？Pytorch 有一套自己的命名方式：\n\n直接赋值：例如 self.output_layer = nn.Linear(10,2)​，则对应的两个参数的名称为 output_layer.weight​ 和 output_layer.bias​。再比如说 self.my_param = nn.Parameter(torch.rand(5))​，则对应的名称为 my_param​\n​nn.Sequential​ 结构：例如 self.features = nn.Sequential(xxx, xxx)​，则获得的参数的名称为 features.0.weight​、features.0.bias​、features.1.weight​ … 其中中间的数字表示第 n​ 层。\n​nn.ModuleList​ 或者 Python 列表/字典：类似于 nn.Sequential​。\n\n我们可以使用 'pattern' in name​ 来确定参数的 name​ 中是否包含某个 pattern​。例如我们也可以用 name​ 的方式来构建 param groups​：\n\nMuon 优化器实战\n现在我们拥有了所有必要的知识，可以来解读和使用 MuonWithAuxAdam​ 了（见 Muon/muon.py at master · KellerJordan/Muon），从代码和文档我们可以看出：\n\n​Muon​ 是一个混合优化器：其内部同时实现了 Muon​ 和 Adam​ 的更新逻辑；\n​Muon​ 必须传入参数组（不能传入 model.parameters()​ 或者 model.named_parameters()​），参数组中使用键 'use_muon': True/False​ 来确定是否使用 Muon 算法。\n\n我们再次来理解 Muon​ 官方仓库给出的范例\n\n\n​model.body​、model.head​、model.embed​ 是模型中定义的属性，但这并非是所有模型都有这些属性，因此要根据自己的模型去修改。\n这里把 2​ 维及以上的参数设置为 hidden_weights​ 使用 Muon​ 进行优化，1​ 维偏置以及 head​、embed​ 的参数使用 Adam​ 优化。\n具体怎么控制是否使用 muon​：创建一个参数组，并使用 use_muon​ 键控制是否使用 muon​ 进行优化。\n\n例如比较常用的，筛选掉维度 &gt;=2​ 以及 embedding​ 层的用法可以是：\n\n‍\n‍\n","description":"","id":"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/","path":"/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/","title":"Pytorch Parameters 结构与 Muon 的调用"},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"body":"Hugging Face transformers​ 库支持对 CLM（Causal Language Modeling）和 MLM（Masked Language Modeling）的微调与预训练，本次对 CLM 的预训练/微调代码进行阅读。\n\n代码见 transformers/examples/pytorch/language-modeling/run_clm.py at main · huggingface/transformers\n\n参数定义 Argument Parsing\nrun_clm.py​ 定义了三个 dataclass​ 来管理所有可配置的参数。\nModelArguments 模型参数：定义了模型、配置、分词器相关的参数\n\nmodel_name_or_path​：指定要使用的预训练模型，例如 gpt2​，或者一个本地模型路径。如果为空，则表示要从头开始预训练模型；\nmodel_type​：如果从头训练，则需要指定模型类型，例如 gpt2​；\nconfig_name​、tokenizer_name​：配置和分词器的名词，一般不需要指定，脚本会自动从 model_name_or_path​ 中加载；\ncache_dir​：下载模型和数据集的缓存路径，默认为 ~/.cache/huggingface​；\ntorch_dtype​：加载模型时的数据类型，例如 float16​ 或 bfloat16​，用于混合精度模型；\n\nDataTrainingArguments 数据参数：定义了数据集加载和预处理相关的参数\n\ndataset_name​：要从 Hugging Face Hub 加载的数据集名称，例如 wikitext​；\ntrain_file​、validation_file​：如果使用本地数据，则指定训练和验证文件的路径（支持 .txt​、.csv​、.json​）；\nblock_size​：数据预处理后，所有文本会被拼接起来，然后切分成固定长度（block_size​）的块。这个值通常取决于模型的最大序列长度限制（如 GPT-2 是 1024）；\nstreaming: 在数据预处理阶段是否启用流式处理模式。如果不开启 streaming​，则会预先将数据预处理完毕然后写入磁盘缓存，训练过程中直接从缓存中读取。如果开启 streaming​，则训练过程中是边处理数据边送给模型训练。\noverwrite_cache​：是否覆盖预处理后的缓存数据。\n\nTrainingArguments 训练参数：包含了所有训练超参数\n\noutput_dir​：训练结果（模型权重、checkpoint 等）的输出目录；\ndo_train​, do_eval: 是否执行训练和评估；\nper_device_train_batch_size: 每个 GPU 的训练批次大小；\nlearning_rate: 学习率；\nnum_train_epochs: 训练的总轮数；\nfp16​, bf16: 是否启用16位浮点数（混合精度）训练；\npush_to_hub: 训练结束后是否将模型推送到 Hugging Face Hub。\n\nMain 函数逻辑\nStep 1. 解析参数：HfArgumentParser​ 会解析命令行传入的参数，填充到之前定义的三个 dataclass​ 对象中。\n\nStep 2. 日志、种子：设置好 logger​、seed​、output_dir​。检查 output_dir​ 中是否存在训练到一半的 checkpoint，若存在则接着训练。\nStep 3. 加载数据集：准备好数据集\n\n判断来源：判断通过 dataset_name​ （在线 Hub）还是 train_file​ （本地文件）提供数据；\n加载数据：使用 datasets.load_dataset​ 函数加载数据；\n验证集处理：如果用户只提供了训练集而没有验证集，脚本会自动从训练集中切分出一部分（默认为 5%）作为验证集。对于流式数据集（streaming），使用了 split_streaming_dataset​ 函数，通过取模运算（i % 100​）来动态切分数据流。\n\nStep 4. 加载模型和分词器：使用 Auto​ 系列的自动化类，用户只需要提供模型名称，其余都会自动处理\n\nStep 5. 模型预处理：使用 .map()​ 方法将原始文本数据转换为模型输入格式，.map​支持多进程加速和缓存，效率很高\n\n\nTokenization：定义 tokenize_function​函数，其输入一批文本，输出 token ID 列表；\n\n\nGrouping Texts：定义 group_texts​ 函数，其完成以下功能：\n\n将所有样本的 token ID 拼接为一个巨大的列表；\n将长列表切割为多个长度为 block_size​ 的小块；\n每个小块既是模型的 input_ids​，也是 labels​\n\n\n\nStep 6. 初始化 Trainer：\n\nStep 7. 执行训练与评估：\n\n","description":"","id":"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/","path":"/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/","title":"Transformers 库 CLM 预训练与微调代码阅读"},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"body":"近期想使用 Hugging Face​ 的 Trainer​ 测试一些微调和预训练任务，因此学习一下如何使用 Trainer​ 以及如何在其中自定义优化器。\nHugging Face Trainer 原理\nTrainer 的目的：虽然不用 Trainer​，Pytorch​ 的训练流程看起来也不麻烦，但是如果我们需要加入分布式训练、混合精度训练、梯度累积、日志记录、评估与断点续训时，代码量和复杂度会快速上升。而 Trainer​ 的目的就是让用户从这些复杂的细节中解放出来。\nTrainer 的创建：Trainer​ 的创建 API 主要如下\n\nTrainer 的主要方法：\n\ntrain(resume_from_checkpoint: str = None)​：启动训练，允许从某个 checkpoint​ 路径恢复训练。\nevaluate(eval_dataset: Dataset = None)​：在给定的数据集上执行一次评估。\npredict(test_dataset: Dataset)​：对一个没有标签的测试集进行预测，返回原始输出。\nsave_model(output_dir: str=None)​：将模型、配置、分词器（如果提供了）保存到指定目录\npush_to_hub()​：将训练好的模型、分词器等推送到 Hugging Face Hub。\n\nTrainer 的训练过程：对于一般用户只需要调用 trainer.train()​，其内部会执行一套高度优化、功能完备的训练循环。关键部分如下：\n\n环境与设置初始化：读取传入的 TrainingArguments​ 的配置，利用 Accelerate​ 库探测硬件环境；\n数据加载器的准备：读取传入的 Dataset​ 对象，创建 DataLoader​，使用 DistributedSampler​ 确保每个 GPU 进程拿到数据的不重复子集；\n核心训练循环 training_step​：每个训练步骤中取出一个 Batch 的数据传递给 training_step​。其中负责将数据移动到 device​，调用 model(**input)​ 执行前向传播，并取出 loss​；\n优化过程：使用 GradScaler​ 防止梯度下溢，控制 loss.backward()​、optimizer.step()​、optimizer.zero_grad()​ 累计梯度。\n生命周期钩子 Lifecycle Hooks：Trainer​ 提供了一系列回调函数，允许在特定节点（如 on_train_begin​、on_step_end​、on_epoch_end​、on_save​ 等）注入自定义逻辑，例如提前停止、打印自定义日志等。\n\nHugging Face Trainer 自定义优化器\n使用 Trainer 支持的优化器：​Trainer​ 默认支持 AdamW​、Adafactor​ 等优化器，可以通过 --optim​ 参数选择。\n使用 Trainer 不支持的优化器：最方便的方式是继承 Trainer​ 并重写 create_optimizer​ 方法。具体而言，Trainer​ 在初始化过程中会调用 self.create_optimizer_and_scheduler()​，其内部再调用 self.create_optimizer()​。\n\n创建自定义的 TrainingArguments​\n\n\n\n创建自定义 Trainer​ 并重写 create_optimizer​\n\n\n\n在训练脚本中使用 CustomTrainer​\n\n\n","description":"","id":"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/","path":"/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/","title":"Transformers 库 Trainer 使用与自定义优化器"},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"body":"近期想做一些图像大模型微调的测试，找到了 Hugging Face 的 transformers 仓库中有一些现成的脚本可以进行微调，因此在此详细阅读和解析下使用的代码。具体代码见 transformers/examples/pytorch/image-classification at main · huggingface/transformers。\n参数定义\n脚本使用 @dataclass​ 装饰器（用法可以问 AI）定义了三个类来管理所有的参数：\n\n​DataTrainingArguments​：控制数据相关参数，例如 dataset_name​、train_dir​、validation_dir​ 等；\n​ModelArguments​：模型参数，最重要的是 model_name_or_path​ 指定了要使用的预训练模型，例如 \"google/vit-base-patch16-224-in21k\"​\n​TrainingArguments​：训练过程相关参数，例如 output_dir​、learning rate​、num_train_epochs​、per_device_train_batch_size​ 等。\n\nMain 函数逻辑\nStep 1. 初始化与设置：解析参数、设置日志、检查断点、设置随机种子（此处略去详细代码）\nStep 2. 加载数据集：\n\n如果提供了 dataset_name​ 则从 Hugging Face 自动下载和加载数据集，生成一个 DatasetDict​ 对象\n\n\n\n如果没提供 dataset_name​，则需要提供本地数据集的 train_dir​ 和 validation_dir​。使用 imagefolder​ 这个特殊的加载器，自动将子文件夹的名称作为类别标签。\n\n\n\n准备 Label Mappings：数据集中的标签是类似于 cat、dog 等单词，但是模型只能理解数字。因此我们要准备 label2id​ 和 id2label​ 两个映射\n\n\nStep 3. 加载模型和处理器：加载模型配置文件、加载模型权重、加载模型的图像处理器\n\nStep 4. 图像变换与数据增强：将原始的 PIL.Image​ 对象转换为 torch.Tensor​\n\nStep 5. 设置训练前 Trainer\n\n​compute_metrics​ 函数\n\n\n\n​collate_fn​ 函数：输入一个批次的数据，将这些数据整理为 model.forward()​ 所需的数据格式\n\n\n‍\n‍\n‍\n","description":"","id":"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/","path":"/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/","title":"Transformers 库图像分类微调代码阅读"},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"body":"\n先验、后验的定义\n先验概率 Prior Probability：假设我们观测到数据 $D$，其由事物背后看不见的性质（参数 $\\theta$）控制。先验概率指的是在未观测任何数据前，我们对一个参数 $\\theta$ 的信念（表现为概率）\n$$\nP(\\theta).\n$$\n以抛硬币为例，我们让 $\\theta$ 表示该硬币朝上的概率（这个是硬币本身的性质，类似于神经网络参数）。我们在没抛任何一枚硬币前，若我们认为该硬币是均匀的概率是 $80\\%$​，则我们的先验表达为：\n$$\nP(\\theta = 0.5) = 0.8,\n$$\n即对于事件硬币朝上概率的概率为 ​$50\\%$（也就是均匀的）的信任度为 $80\\%$​。\n似然 Likelihood：似然表示我们假设某个参数 $\\theta$ 为真的情况下，能观测到数据 $D$ 的概率\n$$\nP(D | \\theta).\n$$\n例如我们假设硬币是均匀的，即 $\\theta = 0.5$，我们观察到抛 $10$ 次出现 $7$ 次正面的现象 $D$ 的概率为\n$$\nP(D | \\theta = 0.5).\n$$\n后验概率 Posterior Probability：后验概率表示观测到新数据 $D$ 后，我们对参数 $\\theta$ 更新后的信念（从先验的主观臆断到后验的数据观测）\n$$\nP(\\theta | D).\n$$\n证据 Evidence / 边缘似然 Marginal Likelihood：对于数据 $D$，我们定义其在所有可能的 $\\theta$ 下出现的总概率为 Evidence。在离散情况下\n$$\nP(D) = \\sum P(D|\\theta_i) P(\\theta_i)\n$$\n在连续情况下\n$$\nP(D) = \\int P(D|\\theta) P(\\theta) \\mathrm{d}\\theta.\n$$\n\n贝叶斯公式\n贝叶斯公式：贝叶斯公式将先验概率、似然、后验概率联系在了一起：\n$$\nP(\\theta|D)=\\frac{P(D|\\theta)\\cdot P(\\theta)}{P(D)}\n$$\n左侧 $P(\\theta | D)$ 是后验概率，$P(D|\\theta)$ 是似然，$P(\\theta)$ 是先验概率，$P(D)$ 是边缘似然。在实际计算中，$P(D)$ 非常难计算，因此我们一般认为\n$$\nP(\\theta|D)\\propto P(D|\\theta)\\cdot P(\\theta).\n$$\n投硬币例子：例如我们对硬币的公平性有所怀疑，提出了两个假设 $\\theta_1 = 0.5$ 和 $\\theta_2 = 0.8$（表示正面概率）。在没有证据前，我们认为它们都有可能，即\n$$\nP(\\theta = 0.5) = 0.5, \\quad P(\\theta = 0.8) = 0.5.\n$$\n然后我们观测到数据 $D$ 为10次抛掷，7次正面。如果 $\\theta = 0.5$，那么观测到 $D$ 的概率为\n$$\nP(D|\\theta_1=0.5)=C(10,7)\\cdot(0.5)^7(0.5)^3\\approx0.117\n$$\n如果 $\\theta = 0.8$，那么观测到 $D$ 的概率为\n$$\nP(D|\\theta_2=0.8)=C(10,7)\\cdot(0.8)^7(0.2)^3\\approx0.201\n$$\n因此我们可以得到后验概率\n$$\nP(\\theta_1=0.5|D)\\propto0.117\\times0.5=0.0585\n$$\n$$\nP(\\theta_2=0.8|D)\\propto0.201\\times0.5=0.1005\n$$\n由于只有这两种情况，我们不妨做个归一化：$P(D) = 0.0585 + 0.1005 = 0.159$，得到\n$$\nP(\\theta_1=0.5|D)=\\frac{0.0585}{0.159}\\approx0.368, \\quad\nP(\\theta_2=0.8|D)=\\frac{0.1005}{0.159}\\approx0.632.\n$$\n‍\n","description":"","id":"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/","path":"/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/","title":"先验、后验概率、贝叶斯公式"},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"body":"动力系统与平衡点\n动力系统：在动力学系统理论中，我们一般考虑一个连续时间的动力系统\n$$\n\\frac{\\mathrm{d} \\mathbf{x}}{\\mathrm{d} t} = {f}(\\mathbf{x},t).\n$$\n其中 $\\mathbf{x}(t)$ 是系统的状态 state，$t$ 是时间，${f}: D \\to \\mathbb{R}^n$ 是连续可微的向量场。\n自治动力系统：通常更常见的动力系统是自治 autonomous 的，表示其行为只受状态 $\\mathbf{x}(t)$ 的直接影响，而不受时间 $t$ 的直接影响，其形式为\n$$\n\\frac{\\mathrm{d} \\mathbf{x}}{\\mathrm{d} t} = {f}(\\mathbf{x}), \\quad f(\\mathbf{0}) = \\mathbf{0}.\n$$\n不失一般性，我们这里直接令系统的初值为 $\\mathbf{0}$。\n平衡点 Equilibrium Point：若系统一旦到达某点 $\\mathbf{x}_e \\in D$，它将永远保持在该点，则该点被称为平衡点 equilibrium point，满足\n$$\nf(\\mathbf{x}_e) = \\mathbf{0}\n$$\n稳定性的概念\n稳定性的思想：稳定性并不是一个单一的概念，而是有一个层次结构递进的。其核心思想是，当系统状态受到一个小的扰动 (perturbation) 偏离平衡点后，系统将如何响应。\n\nLyapunov 稳定性：最基本的稳定性，直观含义为如果系统初始状态足够接近平衡点，那么它未来的所有状态都将保持在平衡点附近的一个任意小的邻域内\nAsymptotic Stability 渐进稳定：比 Lyapunov 稳定性更强，如果系统初始状态足够接近平衡点，系统不仅保持在平衡点附近，而且随着时间推移，最终会收敛到平衡点。\nExponential Stability 指数稳定：比渐近稳定更强的稳定性，如果系统初始状态足够接近平衡点，系统不仅收敛到平衡点，而且其收敛速度至少像指数函数 $e^{-\\lambda t}$ 一样快，其中 $\\lambda &gt; 0$。\nGlobal Stability 全局稳定：前述稳定性都是局部的，全局稳定性将这一范围扩展至整个状态空间 $\\mathbb{R}^n$。\n\nLyapunov 稳定性：系统在平衡点 $\\mathbf{x} = \\mathbf{0}$ 是 Lyapunov 稳定的如果对于任意 $\\epsilon &gt; 0$，存在 $\\delta &gt; 0$，若 $\\|\\mathbf{x}(t_0)\\| &lt; \\delta$ 满足\n$$\n\\|\\mathbf{x}(t) \\| &lt; \\epsilon, \\quad t \\geq t_0.\n$$\nAsymptotic Stability：系统在平衡点 $\\mathbf{x} = \\mathbf{0}$ 是 Asymptotic 稳定的如果其是 Lyapunov 稳定的，且具有吸引性，即存在 $\\delta &gt; 0$，若 $\\| \\mathbf{x}(t_0) \\| &lt; \\delta$，有\n$$\n\\lim\\limits_{t \\to \\infty} \\mathbf{x}(t) = \\mathbf{0}.\n$$\nExponential Stability：系统在平衡点 $\\mathbf{x} = \\mathbf{0}$ 是指数稳定的如果存在 $\\alpha &gt; 0$，$\\lambda &gt; 0$，$\\delta &gt; 0$ 使得 $\\|\\mathbf{x}(t_0)\\| &lt; \\delta$ 时，\n$$\n\\|\\mathbf{x}(t)\\| \\leq \\alpha \\|\\mathbf{x}(t_0)\\|e^{-\\lambda (t - t_0)}.\n$$\n这里 $\\lambda$ 称为 rate of convergence，$\\alpha$ 反映系统的瞬态响应特性。\n\n对于线性时不变系统 $\\dot{\\mathbf{x}} = A \\mathbf{x}$​，渐近稳定等价于指数稳定，且当且仅当矩阵 A 的所有特征值都具有负实部。\n\nGlobal Stability：系统在平衡点 $\\mathbf{x} = \\mathbf{0}$ 是全局渐进稳定​的如果其是 Lyapunov 稳定的，且对任意初始状态  $\\mathbf{x}(t_0) \\in \\mathbb{R}^n$，有\n$$\n\\lim\\limits_{t \\to \\infty} \\mathbf{x}(t) = \\mathbf{0}\n$$\n类似的，也可以定义全局指数稳定。\nLyapunov’s Second Method\n李雅普诺夫第二方法（也称直接法）允许我们不求解微分方程本身来分析稳定性。该方法的核心是寻找一个标量函数，即李雅普诺夫函数。\n径向无界 Radially Unbounded：如果当 $\\|\\mathbf{x}\\| \\to \\infty$ 时，$V(\\mathbf{x}) \\to \\infty$，则称 $V(\\mathbf{x})$ 是 radially unbounded 的。\nLyapunov 稳定性定理：考虑自治系统\n$$\n\\frac{\\mathrm{d} \\mathbf{x}}{\\mathrm{d} t} = {f}(\\mathbf{x}), \\quad f(\\mathbf{0}) = \\mathbf{0}.\n$$\n设 $V(\\mathbf{x})$ 是在包含原点的区域 $D \\subseteq \\mathbb{R}^n$ 上连续可微的标量函数。定义 $V(\\mathbf{x})$ 沿系统轨迹的导数为\n$$\n\\dot{V} = \\frac{\\mathrm{d}}{\\mathrm{d} t}V(\\mathbf{x}(t)) = \\nabla V(\\mathbf{x}) \\cdot f(\\mathbf{x}) = \\frac{\\partial V}{\\partial \\mathbf{x}} \\dot{\\mathbf{x}}.\n$$\n\n如果 $D$ 内 $V(\\mathbf{x})$ 是正定，$\\dot{V}(\\mathbf{x})$ 是半负定的，则 $\\mathbf{x} = \\mathbf{0}$ 是 Lyapunov 稳定的；\n如果 $D$ 内 $V(\\mathbf{x})$ 是正定，$\\dot{V}(\\mathbf{x})$ 是负定的，则 $\\mathbf{x} = \\mathbf{0}$ 是渐进稳定的；\n如果 $\\mathbb{R}^n$ 内 $V(\\mathbf{x})$ 是正定且径向无界，$\\dot{V}(\\mathbf{x})$ 是负定的，则 $\\mathbf{x} = \\mathbf{0}$ 是全局渐进稳定的；\n\n‍\n","description":"","id":"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/","path":"/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/","title":"动力系统稳定性概览"},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"body":"‍\n\n预备知识：似然函数\n似然函数：似然函数 $L(\\theta | D)$ 表示在参数为 $\\theta$ 的模型下，观测到数据 $D$ 的概率，即\n$$\nL(\\theta|D)=p(D|\\theta)=\\prod_{i=1}^Np(x_i|\\theta).\n$$\n对数似然：由于似然函数的计算是乘法，有各种各样的问题。我们希望将其转换为加法或者减法，而取对数是一种很自然的想法\n$$\n\\mathcal{L}(\\theta|D)=\\log L(\\theta|D)=\\sum_{i=1}^N\\log p(x_i|\\theta).\n$$\n最大化似然估计 Maximum Likelihood Estimation, MLE：如果我们能够调整 $\\theta$，那么我们肯定希望在 $\\theta$ 下观测到 $D$ 的概率越高越好，也就是最大化似然函数\n$$\n\\theta_{MLE}=\\arg\\max_\\theta\\mathcal{L}(\\theta|D).\n$$\n\n预备知识：Score 函数\nScore 函数的定义：定义 Score 函数为对数似然函数关于 $\\theta$ 的梯度，其表示着在当前 ​$\\theta$​ 位置如何调整参数能最快地提高模型对数据的解释能力。\n$$\ns(\\theta) := \\nabla_\\theta \\mathcal{L}(\\theta|D)\n$$\nScore 函数的期望：假设数据 $D$ 是由一个真实的参数 $\\theta^\\ast$ 生成的，那么 Score 函数在该点的期望为零：\n$$\n\\mathbb{E}_{D\\sim p(D|\\theta^*)}[s(\\theta^*)]=0,\n$$\n需要注意的是，这个期望为 $0$ 是一个关于所有可能数据集的理论平均性质。对于我们手中任何一个具体的数据集 $D$，由于采样的随机性，计算出的 $s(\\theta^*)$ 的值几乎总是不为 $0$ 的。\n\nFisher 矩阵\nFisher 信息矩阵：Fisher 信息矩阵量化了数据 ​$D$​ 中包含了多少模型参数 ​$\\theta$​ 的信息，其有两种等价的定义。\n定义 1. Score 函数的方差：定义 Fisher 信息矩阵为 Score 函数的协方差矩阵\n$$\nF(\\theta)=\\mathbb{E}_{x\\sim p(x|\\theta)}[s(\\theta)s(\\theta)^\\top]\n$$\n在实际问题中，对于每个样本的梯度向量 $s_k(\\theta)$，我们通过以下公式计算 Fisher 信息矩阵\n$$\n\\hat{F}(\\theta)=\\frac{1}{N}\\sum_{k=1}^Ns_k(\\theta)s_k(\\theta)^\\top\n$$\n定义 2. 对数似然函数 Hessian 矩阵的负期望：我们也可以用对数似然函数的 Hessian 矩阵的负期望来定义 Fisher 矩阵\n$$\nF(\\theta)=-\\mathbb{E}_{x\\sim p(x|\\theta)}[\\nabla_{\\theta}^{2}\\mathcal{L}(\\theta|D)]\n$$\n在实际计算中，对数据集中每个样本 $x_k$ 计算对数似然的 Hessian 矩阵 $\\nabla_\\theta^2\\mathcal{L}(\\theta|x_k)=\\nabla_\\theta^2\\log p(x_k|\\theta)$，取负号后求和：\n$$\n\\hat{F}(\\theta)=-\\frac{1}{N}\\sum_{k=1}^{N}\\nabla_{\\theta}^{2}\\log p(x_{k}|\\theta)\n$$\nFisher 矩阵元素含义：Fisher 矩阵的对角元素 $F_{ii}$ 衡量了数据中关于某个参数 $\\theta_i$ 的信息量，$F_{ii}$ 越大说明 $\\theta_i$ 对模型越重要。非对角元素 $F_{ij}$ 表示了不同参数 $\\theta_i$ 和 $\\theta_j$ 估计值之间的相关性/耦合度。\n\n弹性权重巩固 Elastic Weight Consolidation, EWC\nEWC 是一种持续学习算法，其目标是在学习新任务（任务B）时，减缓对旧任务（任务A）知识的遗忘。这里介绍其数学基础与基本想法。\nEWC 核心思想：对于旧任务（任务A）中越重要的参数，在学习新任务（任务B）时就越要限制它的改动。\nEWC 损失函数：假设已经完成了任务 A 的训练得到了最优参数 $\\theta_A^\\ast$。现在要学习任务 B，则 EWC 的损失函数表示为\n$$\nL(\\theta)=L_B(\\theta)+\\frac{\\lambda}{2}\\sum_iF_i(\\theta_i-\\theta_{A,i}^*)^2,\n$$\n其中 $L_B(\\theta)$ 是任务 B 的标准损失函数，$\\frac{\\lambda}{2}\\sum_iF_i(\\theta_i-\\theta_{A,i}^*)^2$ 是 EWC 增加的正则化惩罚项，$\\lambda$ 是正则化参数，$(\\theta_i-\\theta_{A,i}^*)^2$ 是当前参数 $\\theta_i$ 与任务 A 最优参数 $\\theta_{A,i}^\\ast$ 的二次距离，$F_i$ 是在 ​$\\theta_{A}^\\ast$​ 处的 Fisher 矩阵的对角元素，充当了重要性权重。\n\n如果参数 $\\theta_i$ 对任务 A 很重要（$F_i$ 很大），那么对它的任何改动 $(\\theta_i - \\theta_{A,i})^2$ 都会被放大，从而产生巨大的惩罚，迫使模型不要轻易改动它。\n如果参数 $\\theta_i$ 对任务 A 不重要（$F_i$ 很小），惩罚就小，模型可以自由调整它来适应任务 $B$。\n\n一些疑问和注意点：\n\n\n为什么只用对角元素：由于完整的 Fisher 矩阵过于庞大，EWC 中只使用了 Fisher 矩阵的对角元素以表示重要性，忽略了参数之间的相关性。\n\n\nFisher 矩阵是固定的吗：注意 EWC 使用的 Fisher 矩阵是 $\\theta_A^\\ast$ 处的，而非每次参数更新时更新的，这样能准确捕捉对 A 任务重要的参数。\n\n\n为什么用 Fisher 矩阵对角而非 Score 函数分量：理想情况下 $\\theta_A^\\ast$ 处的 Score 函数为 $0$（极值点），而 Fisher 矩阵衡量了不同样本对某个参数的需求，如果 $F_i$ 很大，则稍微一改动，便会影响多个样本的拟合结果。\n\n\n\n‍\n","description":"","id":"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/","path":"/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/","title":"Fisher 矩阵与弹性权重巩固 Elastic Weight Consolidation, EWC"},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"body":"依稀记得 Heavy-Ball 动量格式和 Momentum 动量格式是完全等价的，但是总是记不清楚，因此重新写一遍。\nHeavy-Ball 动量格式：Heavy-Ball 动量格式为\n$$\n\\theta_{t+1} - \\theta_t = \\gamma (\\theta_{t} - \\theta_{t-1}) - \\eta \\nabla f(\\theta_t)\n$$\n现代 Momentum 格式：现代 Momentum 动量格式为\n$$\nv_{t+1} = \\beta v_t + \\nabla f(\\theta_t), \\quad \\theta_{t+1} = \\theta_t - \\eta v_{t+1}.\n$$\nHeavy-Ball 与 Momentum 格式的等价性：Heavy-Ball 和 Momentum 在数学上是完全等价的，且 $\\gamma = \\beta$。\n\n证明：这里只从 Momentum 出发推导 Heavy-Ball，将 Momentum 第一个式子两侧同时乘上学习率 $\\eta$ 得到\n$$\n\\eta v_{t+1} = \\beta \\eta v_t + \\eta \\nabla f(\\theta_t),\n$$\n而根据第二个式子得到 $-\\eta v_{t+1} = \\theta_{t+1} - \\theta_t$，因此带入上面的等式得到结论。\n\n‍\n","description":"","id":"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/","path":"/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/","title":"Heavy-ball 与 Momentum 算法等价性"},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"body":"SFT 代码阅读\n\n代码见 trl/trl/scripts/sft.py at main · huggingface/trl\n\nStep 1. 模型和分词器初始化：\n\nStep 2. 数据集加载：可以用 --dataset_name​ 加载一个标准数据集，也可以用 --datasets​ 提供更复杂的配置（例如混合多个不同的数据集）\n\nStep 3. SFT 训练器初始化：\n\nStep 4. 训练与保存：\n\n‍\n","description":"","id":"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/","path":"/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/","title":"Hugging Face trl 微调库 SFT 代码阅读"},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"body":"\n问题描述\n拉格朗日乘子法（Method of Lagrange multiplier）用于解决等式约束的优化问题（Equality-Constrained Optimization）。\n等式约束的优化算法：给定目标函数 $f: \\mathbb{R}^m \\to \\mathbb{R}$ 和等式约束条件 $\\mathbf{g}(\\mathbf{x}) = \\mathbf{c}$，其中 $\\mathbf{x} \\in \\mathbb{R}^n$，$\\mathbf{c} \\in \\mathbb{R}^m$​。问题是找到 $\\mathbf{x}^\\ast$ 满足\n$$\n\\mathbf{x}^\\ast = \\arg\\min_\\mathbf{x} f(\\mathbf{x}), \\quad \\operatorname{subject~to} \\quad\n\\mathbf{g}(\\mathbf{x}) = \\mathbf{c}.\n$$\n其中 $\\mathbf{g}(\\mathbf{x}^\\ast) = \\mathbf{c}$ 为多个等式约束条件 $g_1(\\mathbf{x}^\\ast) = c_1$，$g_2(\\mathbf{x}^\\ast) = c_2$ 等。\n注：为了简单起见，我们先考虑一个限制条件 $g(\\mathbf{x}) = c$。\n\n核心思想\n等高线 Level Sets：对于 $d \\in \\mathbb{R}$，集合 $\\{\\mathbf{x}: f(\\mathbf{x}) = d\\}$ 构成了 $f$ 的一条等高线。\n\n梯度与等高线正交：函数在某一点的梯度 $\\nabla f(\\mathbf{x})$ 指向函数值增长最快的方向，且与该点的等高线正交。\n约束曲面是等高线：约束 $g(\\mathbf{x}) = c$ 本身也定义了一个曲面。由于其是一个等式，其可以被视作等高线，因此 $\\nabla g(\\mathbf{x})$ 与该曲面正交。\n\n拉格朗日乘子法的直观理解：假设我们沿着约束曲面 $g(\\mathbf{x}) = c$ 行走，寻找 $f(\\mathbf{x})$ 的最高点。\n\n如果我们能沿着约束曲面 $g(\\mathbf{x}) = c$ 移动优化 $f(\\mathbf{x})$，那我们肯定还没到最优点。\n当我们达到 $\\mathbf{x}^\\ast$ 时，我们无法再沿着 $g(\\mathbf{x}) = c$ 优化 $f(\\mathbf{x})$，因此 $\\mathbf{x}^\\ast$ 处约束曲线的方向与 $f(\\mathbf{x})$ 的等高线方向是相切的。\n\n核心思想：拉格朗日乘子法的核心思想为在最优点 ​$\\mathbf{x}^\\ast$​处，目标函数 ​$f(\\mathbf{x})$​ 的等高线/面与约束条件 ​$g(\\mathbf{x}) = c$​ 的曲线/面相切。用数学语言来说即两个曲面 $f(\\mathbf{x}) = f(\\mathbf{x}^\\ast)$ 和 $g(\\mathbf{x}) = c$ 相切，那么它们的法向量必然是平行的，也就是\n$$\n\\nabla f(\\mathbf{x}^*)=-\\lambda\\nabla g(\\mathbf{x}^*)\n\\quad \\Rightarrow \\quad\n\\nabla f(\\mathbf{x}^*)+\\lambda\\nabla g(\\mathbf{x}^*)=\\mathbf{0}\n$$\n其中 $\\lambda$ 是一个待定系数，表示两个向量的模长比。\n\n拉格朗日乘子法\n拉格朗日乘子法叙述：上述思想引出了一个巧妙的解决方案，我们引入一个辅助函数，称为拉格朗日函数（Lagrangian Function） ：\n$$\nL(\\mathbf{x},\\lambda)=f(\\mathbf{x})+\\lambda(g(\\mathbf{x})-c)\n$$\n这样我们就把前面的有约束问题转换为了对拉格朗日函数 ​$L(\\mathbf{x}, \\lambda)$​ 的无约束优化问题：\n$$\n\\begin{cases}\n\\nabla_\\mathbf{x}L(\\mathbf{x},\\lambda)=\\nabla f(\\mathbf{x})+\\lambda\\nabla g(\\mathbf{x})=\\mathbf{0} \\\\\n\\frac{\\partial L}{\\partial\\lambda}=g(\\mathbf{x})-c=0\n\\end{cases}\n$$\n其中第一个式子是前一节中导出的条件，第二个式子施加了原始的约束条件 $g(\\mathbf{x}) = c$。\n多等式约束拉格朗日乘子法：对于多个等式约束的优化问题，我们定义拉格朗日函数为\n$$\nL(\\mathbf{x},\\boldsymbol{\\lambda})=f(\\mathbf{x})+\\sum_{i=1}^m\\lambda_i(g_i(\\mathbf{x})-c_i).\n$$\n对应的无约束优化问题为：\n$$\n\\begin{cases}\n\\nabla_\\mathbf{x}L(\\mathbf{x},\\boldsymbol{\\lambda})=\\nabla f(\\mathbf{x})+\\sum_{i=1}^m\\lambda_i\\nabla g_i(\\mathbf{x})=\\mathbf{0} \\\\\n\\frac{\\partial L}{\\partial\\lambda_i}=g_i(\\mathbf{x})-c_i=0, \\quad i = 1,2,\\cdots, m\n\\end{cases}\n$$\n‍\n","description":"","id":"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/","path":"/blog/la-ge-lang-ri-cheng-zi-fa/","title":"拉格朗日乘子法"},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"body":"\nOriginal Paper: [2509.01440] Benchmarking Optimizers for Large Language Model Pretraining\n\n\nIntroduction\nChinchilla Scaling Law: The optimal amount of training data for a given model size that yields the best performance under a fixed computational budget. To be more specific, we need around 20 text tokens per parameter (see 2203.15556)\nOverview: We discuss the algorithms according to their logical grouping:\n\nAdam-like methods: AdamW​, ADOPT​, AdEMAMix​\nSign-based methods: Lion​, Signum​\nApproximate second-order optimizers: Muon​, SOAP​, Sophia​\nLearning rate/ scheduler-free learning algorithms: Schedule-Free AdamW​, Prodigy​\nMARS methods: MARS​\n\nADOPT: Remove the current gradient $g_t$ from the second moment estimate $v_t$ and alter the order of the momentum update $m_t$ and normalization.\n​\nAdEMAMix (Dual EMA) : This work argues that using a single EMA to accumulate past gradients in the first moment estimate $m$ can be suboptimal, as it cannot simultaneously prioritize both immediate past and older gradients.\n​\nLion: Lion is a sign-based method, which determines the update direction by taking the sign of an interpolation between the previous momentum and the current gradient.\n​\nSignum: This method differs from Lion in the interpolation term between the EMA of momentum and the current gradient.\n​\nMuon and D-Muon: In Muon’s original code, weight decay does not apply to the matrix parameters in MuonNon1D​. This weight decay issue is addressd in [2502.16982] Muon is Scalable for LLM Training, in which the authors present a scheme for sharing the learning rate and weight decay between the matrix and non-matrix parameters of the model.\n​\n​\nSOAP: SOAP improves Shampoo and reduces the computational overhead by optimizing only two-dimensional layers while running AdamW for 1D layers.\n​\nSophia:\n​\nSchedule-Free AdamW: The idea of Shcedule-Free AdamW​ is to eliminate learning rate schedulers by replacing them with iterate averaging.\n​\nProdigy: Prodigy removes the need for hand-tuned learning rates through an intrinsic, adaptive step-size scheme.\n​\nMARS: MARS incorporates modern adaptive and approximate second-order methods with a variance reduction update style.\n​\n\nResults at Small Scale: 124M Models\nNotation: Hereafter, “$A \\times B$ tokens” indicates the batch size is $A$, and each batch contains $B$ tokens.\nResults with Small and Large Batches and Stability across Training Horizons\n\n  \n  Comparing optimizers for training a 124M parameter LLM: (a) &amp;quot;small&amp;quot; batch size (b) &amp;quot;large&amp;quot; batch size.\n​\n\n  \n  Ranking of optimizers for 124M models with &amp;quot;small&amp;quot; and &amp;quot;large&amp;quot; batch sizes.\n​\n\nTakeaway (Batch Size)\n\nAdEMAMix​ consistently achieves state-of-the-art performance and robust scaling with training duration.\nSign-based methods (Signum​, Lion​) and MARS​ greatly benefit from the increased batch size.\nSophia​ diverges in small-batch setting, when trained beyond the Chinchilla optimal horizon, even with sufficiently small learning rate;\nSOAP​ show a consistent performance in both settings.\n\nTakeaway (Stability) : Once optimizers are properly re-tuned for the maximal length of training considered, doubling of number of iterations does not affect the ranking of methods.\n\n\nIncreasing the Batch Size Further:\n\n  \n  Scaling batch size\n​\n\nTakeaway: Many methods, especially MARS​, Prodigy​, and sign-based​ ones, can outperform AdamW​ while trained on a sufficiently large batches.\n\n\nWeight Decay Ablation:\nHere the baseline AdamW​ uses a weight decay of $\\lambda = 0.1$.\n\n  \n  Larger weight decay achieves significantly better results when training on fewer tokens: (a) AdamW, Signum, Lion with large weight decay outperform baseline AdamW with weight decay of 0.1 for short training duration. (b) the setting without weight decay is suboptimal. (c) Smaller weight decay leads to larger L2 norm of the model parameter.\n​\n\n  \n  Importance of weight decay for Muon. (1) D-Muon uses a weight decay for all parameters, (2) Muon uses weight decay only on embeddings, scalar parameters, and the final layer. We can see that D-Muon greatly outperforms the basic Muon.\n​\n\nTakeaway:\n\nThe use of weight decay (particularly a large weight decay term 0.5 and above), can significantly impact the final loss and optimizer behavior.\nThe setting of weight decay to be $0$ is suboptimal.\nFor extended training horizons, non-zero weight of $0.1$ proves to be a robust option.\n\n\n\nLearning Rate Sensitivity:\n\n  \n  Optimal learning rate stability across optimizers. The optimal learning rate determined during tuning on 2.1B tokens remains consistent after a learning rate sweep on 16.8B tokens for most optimizers.\n​\n\nTakeaway:\n\nFor most optimizer, the learning rate $\\gamma_{\\max}$ selected near the Chinchilla optimal horizon transfers smoothly to $8 \\times$longer run.\nSign-based methods and Sophia​ diverge with $\\gamma_{\\max} = 2e^{-3}$.\nMARS​ demonstrates a very consistent performance across $\\gamma$ sweep.\n\n\n\nWarmup Ablation:\n\n  \n  Warmup ablation: sign-based optimizers, Sophia and SF-AdamW benefit from the increased warmup.\n​\n\nTakeaway: We reveal that the warmup duration is optimizer-dependent and should be tuned: for SF-AdamW​, Sophia​, and Signum​, longer warmup results in improved final performance.\n\n\nWarmup Types of WSD(Warmup-Stable-Decay), cosine, and linear **$\\gamma$**​ -scheduler:\n\n  \n  Comparisons between cosine, WSD, and the linear schedulers.\n​\n\n  \n  Gradient norm patterns for different schedulers: (b) the gradient evolution for majority of optimizers resembles the SF-AdamW pattern (a,c) Exceptions are sign-based methods: Signum and Lion.\n​\n\nTakeaway: A choice of the learning rate scheduler is also optimizer-related\n\nFor most methods, the cosine scheduler dominates.\nLinear scheduler outperforms or matches cosine and WSD for sign-based methods, SOAP​ and MARS​.\nWSD appears to be the best option for Muon​\n\n\n\nResults at Medium Scale: 210M Models\nResults​\n\n  \n  Ranking of optimizers for 210M models with the batch size of 256*512 tokens.\n​\n\n  \n  Comparing optimizers for training a 219M parameter LLM.\n​\n\nTakeaway:\n\nWe do not observe a much of a change in ranking of optimizers for 210M model, compared to benchmarking on 124M.\nWe replicated almost identical hyperparameters for all optimizers, except for the learning rate for sign-based methods (which is more sensitive to the learning rate while scaling the model size)\n\n\n\nDecay the learning rate sufficiently\n\n  \n  Decaying the learning rate down to 0.01 and beyond, instead of only to 0.1\n​\n\nTakeaway: Decaying the learning rate further than $10\\%$ of the maximal significantly improves the results. However, for different schedulers, the best final learning rate is different.\n\n\nResults at Large Scale: 583M and 720M Parameters\nResults\n\n  \n  Ranking of optimizers for 720M Llama-based models.\n​\n\n  \n  Comparing optimizers for training a 720M parameter LLM.\n​\n\nTakeaway:\n\nAt larger scale of model and batch size, AdEMAMix​ and MARS​ dominate.\nDespite training with large batches, Signum​ and Lion​ scale poorly.\nD-Muon​ is consistent across all our benchmarking setups.\n\n\n\nWall-clock time comparison​\n\n  \n  Wall-clock time comparison.\n​\n\nTakeaway: Most optimizers exhibit similar wall-time performance, with sign-based methods being slightly faster. SOAP​ is the main exception.\n\n\nExtension to MoEs\nMoE:\n​\nResults:\n\n  \n  Ranking optimizers for 520M MoE models with 256*512 batch size.\n​\n\n  \n  Comparing optimizers for training a 520M parameter MoE.\n​\n\nTakeaway: Benchmarking results obtained for dense models transfer to corresponding MoEs.\n\n‍\n","description":"","id":"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/","path":"/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/","title":"论文阅读-Benchmarking Optimizers for Large Language Model Pretraining"},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"body":"\nOriginal Paper: [2404.11013] Control Theoretic Approach to Fine-Tuning and Transfer Learning\n\n\nPreliminaries\nHausdorff Space: A topological space $(X, \\mathcal{T})$ is said to be a Hausdorff space if\n$$\n\\forall x,y\\in X,x\\neq y\\Longrightarrow\\exists U,V\\in\\mathcal{T}\\mathrm{~s.t.~}x\\in U,y\\in V,\\mathrm{~and~}U\\cap V=\\emptyset\n$$\nwhere $\\mathcal{T}$ is the set of all the open sets in the space.\n\nHausdorff 空间保证了点的可分离性。\n\nBasis of Topological Spaces: The basis of a topological space $\\mathcal{B}$ is a set of open sets satisfying\n$$\n\\exists\\mathcal{B}=\\{B_1,B_2,B_3,\\ldots\\}\\subseteq\\mathcal{T}\\mathrm{~s.t.~}\\forall U\\in\\mathcal{T},U=\\bigcup_{i\\in I}B_i\\text{ for some }I\n$$\nSecond-Countable: A topological space $(X, \\mathcal{T})$ is said to be second countable if $\\mathcal{T}$ has a countable basis.\nHomeomorphism: A mapping $\\phi: U \\to V$ is homeomorphism if both $\\phi$ and $\\phi^{-1}$ are continuous mapping.\nLocally Euclidean and Chart: A topological space $X$ is said to be locally Euclidean if for any $p \\in X$, there exists an open neighbor $U$ of $p$, a open set $V \\subseteq \\mathbb{R}^n$, and a homeomorphism $\\phi$ such that\n$$\n\\phi: U \\to V.\n$$\nHere $\\phi$ is called the chart.\n\n流形上每个局部都可以被坐标卡 chart 映射到一块 $\\mathbb{R}^n$ 的区域\n\nTopological Manifold: An $n$-dimensional topological manifold is a topological space that is Hausdorff, second-countable, and locally Euclidean of dimension $n$.\nSmooth Curve: A smooth curve at a point $p$ on an manifold $M$ is a smooth map $\\gamma: I \\to M$, where $I \\subseteq \\mathbb{R}$ is an open interval containing $0$, such that $\\gamma(0) = p$.\nEquivalence Relation on Curves: Let $(U, \\phi)$ be a local chart containing the point $p$, where $\\phi: U \\to \\mathbb{R}^n$. Two smooth curves $\\gamma_1$ and $\\gamma_2$ at $p$ are said to be equivalent iff their velocity vectors in the chart coordinates are identical, that is\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}t}(\\phi\\circ\\gamma_1)(t)\\bigg|_{t=0}=\\frac{\\mathrm{d}}{\\mathrm{d}t}(\\phi\\circ\\gamma_2)(t)\\bigg|_{t=0}.\n$$\n\n可以理解为切平面上一个方向的曲线是等价的\n\nTangent Vector: A tangent vector $v$ at a point $p$ is an equivalence class of all smooth curves passing through $p$. We denote this as $v = [\\gamma]$.\nTangent Space: The tangent space at a point $p$ on $M$, denoted by $T_pM$, is the set of all tangent vectors at $p$:\n$$\nT_pM:=\\{[\\gamma]\\mid\\gamma:I\\to M\\text{ is a smooth curve with }\\gamma(0)=p\\}\n$$\n\nProblem Statement\nDataset and System: Consider the paired sets $(\\mathcal{X},\\mathcal{Y})=\\{(x^{i},y^{i})\\}_{i=1}^{q}$ in a connected Riemannian manifold $\\mathcal{M}$​, where elements of $\\mathcal{X}$ are pairwise distinct. We take the system\n$$\n\\dot{x}(t)=f(u(t), x(t)),\n\\quad u\\in L_\\infty([0,T],\\mathbb{R}^{\\bar{n}\\times\\bar{n}})\n$$\n$$\nx^i\\in\\mathbb{R}^n\n\\overset{E}{\\operatorname*{\\longrightarrow}}\n\\bar{x}^i\\in\\mathbb{R}^{\\bar{n}}\n\\overset{\\varphi_T(u,\\cdot)}{\\operatorname*{\\longrightarrow}}\n\\bar{y}^i\\in\\mathbb{R}^{\\bar{n}}\n\\overset{R}{\\operatorname*{\\longrightarrow}}\ny^i\\in\\mathbb{R}^{n_o}\n$$\nwhere $E: \\mathbb{R}^n \\to \\mathbb{R}^{\\bar{n}}$ is an embedding function, $R: \\mathbb{R}^{\\bar{n}} \\to \\mathbb{R}^n$ is a readout function, $\\bar{n}$ is the embedding dimension, $n_o$ is the output dimension, and $\\varphi_t(u,\\cdot)$ is the map generated by the control function $u$. For simplicity, we assume that $n = \\bar{n}$, and let $R$ be the orthogonal projection, that is\n$$\nR:x\\in\\mathbb{R}^n\\mapsto Cx\\in\\mathbb{R}^{n_o},\n\\quad\n\\text{where} \\quad C=[O_{n_{o}\\times n-n_{o}}I_{n_{o}\\times n_{o}}]\\in\\mathbb{R}^{n_{o}\\times n}.\n$$\n\nIf $n = n_o$ and $R$ is the identity map, then we call the problem the control with fixed end-points（固定终值条件）. Otherwise, control with partially constrained end-points（终值约束条件）.\n\nObjective (Memorization Property) : The control $u$ is said to have memorized the ensemble $(\\mathcal{X}, \\mathcal{Y})$ if the following holds for a finite $T \\geq 0$:\n$$\nR(\\varphi_T(u,E(x^i)))=y^i, \\quad \\forall x^i\\in\\mathcal{X}.\n$$\n\n我们的总目标就是找到一个控制信号 $u$，对任意数据都能满足 memorization property。\n\nCost Functional: We define per-sample cost functional for a given point $x^i$ as\n$$\n\\mathcal{J}^i(u)=\\frac{1}{2}\\|C\\varphi(u,x^i)-y^i\\|^2.\n$$\nThen, the cost-functional for the entire ensemble is\n$$\n\\mathcal{J}(u,\\mathcal{X}):=\\sum_{i=1}^{q}\\|C\\varphi(u,x^{i})-y^{i}\\|^{2}+\\lambda\\int_{0}^{T}\\|u(\\tau)\\|^{2}d\\tau.\n$$\nwhere $\\lambda$ is some regularization coefficient.\nq-Folded Method: Suppose $\\mathcal{X}$ contains $q$ data points. Stack all the points in $\\mathcal{X}$ into a vector of dimension $nq$ denoted by $X_0$, and the stacked outputs by $Y$. The minimization problem is\n$$\n\\mathcal{J}(u,X_0):=\\|\\Lambda(C)\\vec{\\varphi}_T(u,X_0)-Y\\|^2+\\int_0^T\\|u(\\tau)\\|^2d\\tau.\n$$\n$$\n\\text{subject to} \\quad \\dot{X}(t)=F(u(t),X(t)), \\quad X(0)=X_0.\n$$\nwhere $\\Lambda(C):=\\mathrm{diag}(C,\\cdots,C)\\in\\mathbb{R}^{n_{0}q\\times nq}$, and $F$ is the dynamics created by copying $f$ $q$-times.\n\n使用 q-folded method 求解非常困难。\n\n\nExistence of a Control Function\nLie Bracket: Let $g_1$ and $g_2$ be differentiable vector fields in $\\mathcal{M} \\subset \\mathbb{R}^n$, we call the Lie bracket of $g_1$ and $g_2$ the vector field:\n$$\ng_1,g_2:=\\frac{\\partial g_2(x)}{\\partial x}g_1(x)-\\frac{\\partial g_1(x)}{\\partial x}g_2(x), \\quad \\mathrm{for} \\quad x\\in\\mathcal{M}\n$$\n\nLie bracket 的核心含义：测量路径的不闭合程度，沿着以下两种路径：(1) 先 $g_1$ 走 $\\epsilon$，再 $g_2$ 走 $\\epsilon$；(2) $g_2$ 走 $\\epsilon$，再 $g_1$ 走 $\\epsilon$。两种路线到达的终点距离为：\n$$\n\\epsilon^2\\left(\\frac{\\partial g_2(x)}{\\partial x}g_1(x)-\\frac{\\partial g_1(x)}{\\partial x}g_2(x)\\right).\n$$\n\nManeuver Set: Let $\\mathcal{F}^0=\\{f(x,u)|u\\in L_\\infty([0,T],\\mathbb{R}^{n\\times n})\\}$ be the maneuver set with all the feasible control functions, and recursively define\n$$\n\\mathcal{F}^k=\\mathcal{F}^{k-1}\\cup\\left\\{g_i,g_j\\mid g_i,g_j\\in\\mathcal{F}^{k-1}\\right\\}.\n$$\n\n$\\mathcal{F}$ 是中的元素是关于 $x$ 的函数\n\n$\\mathcal{F}^0$：$u$ 可以是任意矩阵，此时每个 $u$ 对应一种运动模式 $g_i(x)$，因此 $\\mathcal{F}^0$ 包含了所有的直接运动方式（但是不能组合不同运动模式）。\n$\\mathcal{F}^k$：在 $\\mathcal{F}^{k-1}$ 的运动模式基础上进一步进行组合（例如快速交替执行它们），如果这种组合产生了一种新的运动模式，则加入动作库。\n\n这种方式一般适用于 $f$ 是非线性的情况，否则直接组合 $u$ 即可。\n\nControl Distribution: The corresponding distributions at point $x \\in \\mathbb{R}^n$ are\n$$\n\\mathcal{D}_{x}^{k}(\\mathcal{F})=\\mathrm{span}\\left\\{g(x)\\mid g\\in\\mathcal{F}^{k}\\right\\}.\n$$\nWe can see that $\\mathcal{D}_{x}^{k}(\\mathcal{F})$ satisfies $\\mathcal{D}_{x}^{k}(\\mathcal{F})\\subseteq\\mathcal{D}_{x}^{k+1}(\\mathcal{F})$.\n\n$\\mathcal{D}_{x}^{k}(\\mathcal{F})$ 表示从 $x$ 出发，从 $\\mathcal{F}^k$ 动作库中取一个动作，能达到的集合。\n\nBracket-Generating: We call $\\mathcal{F}$ bracket-generating if $\\mathcal{D}_x^\\infty (\\mathcal{F})$ spans $T_xE(\\mathcal{M})$ for all $x \\in E(\\mathcal{M})$. Here $E$ is the embedding function and $T_x$ represents the tangent space.\n\n$T_xE(\\mathcal{M})$ 表示了所有可能的运动方向，因此 bracket-generating 表示了我们的控制可以控制往任何方向。\n\nq-Folded Statement: Assume $\\mathcal{X}$ contains finite pairwise distinct points, $n &gt; n_o$, $R(x) = Cx$. If $\\tilde{\\mathcal{F}}$ is bracket-generating in $E(\\mathcal{M})^{(q)}$, then there exists $u$ and a finite time $T \\geq 0$ such that the system memorizes $(\\mathcal{X}, \\mathcal{Y})$ by the control function $u$.\n\nEmbedding space $E(\\mathcal{M})^{q}:=E(\\mathcal{M})\\times\\cdots\\times E(\\mathcal{M})$\nEnsemble $X=\\left[E(x^1)^\\top,\\cdots,E(x^q)^\\top\\right]^\\top\\in E(\\mathcal{M})^q \\subseteq \\mathbb{R}^{nq}$\n$\\Delta^{q}:=\\{[E(x^{1})^{\\top},\\cdots,E(x^{q})^{\\top}]^{\\top}\\in E(\\mathcal{M})^{q} | E(x^i)=E(x^j)\\mathrm{~for~}i\\neq j\\}$\nComplement $E(\\mathcal{M})^{(q)}:=E(\\mathcal{M})^{q}\\setminus\\Delta^{q}$\n$\\tilde{\\mathcal{F}}^0=\\{[f(u,x^1)^\\top,f(u,x^2)^\\top,\\cdots,f(u,x^q)^\\top]^\\top\\in\\mathbb{R}^{nq}|u\\in L_\\infty([0,T],\\mathbb{R}^{n\\times n})\\}.$\n\n\nTuning without Forgetting\nObjective: Let $\\mathcal{X}^{j}=\\{x^{i}\\in\\mathcal{X}|i=1,2,\\cdots,j\\}$, and $\\mathcal{Y}^j$ the corresponding batch of labels. Denote $u^k$ the control function at the $k$th iteration. Assume that $u^k$ has memorized the ensemble $(\\mathcal{X}^{j},\\mathcal{Y}^{j})$. We propose an iterative method to find a control $u^\\ast$ such that\n$$\nC\\varphi(u^*,x^i)=y^i\n\\quad \\text{for all} \\quad\nx^i\\in\\mathcal{X}^{j+1}(=\\mathcal{X}^j\\cup\\{x^{j+1}\\})\n$$\nTuning without Forgetting: Assume that $u^k$ has memorized the ensemble $(\\mathcal{X}^{j},\\mathcal{Y}^{j})$. If the update $\\delta u^k$ satisfies\n$$\n\\mathcal{J}^{j+1}(u^k+\\delta u^k)\\leq\\mathcal{J}^{j+1}(u^k)\n$$\n$$\nR\\left(\\varphi(u^k+\\delta u^k,x^i)\\right)=y^i+o(\\delta u^k),\\quad \\forall x^i\\in\\mathcal{X}^j\n$$\nThen the control function $u^{k+1} := u^k + \\delta u^k$ has been tuned for $\\mathcal{X}^{j+1}$ without forgetting $\\mathcal{X}^j$.\n\n条件1：要求更新控制后，对新数据点的 cost 下降\n条件2：要求更新控制后，对老数据点的影响不明显\n\n\nA Projected Gradient Descent Method\nLinearized Controllability Property: We say the system $\\dot{x}(t)=f(x(t),u(t))$ has the Linearized Controllability Property (LPC)  at $x^i$ for all $u\\in L_{\\infty}([0,T],\\mathbb{R}^{n\\times n})$ if the linear time varying system\n$$\n\\dot{z}(t)=\\left(\\frac{\\partial f(x,u)}{\\partial x}\\bigg|_{(x=\\varphi_t(u,x^i),u)}\\right)z(t)+\\left(\\frac{\\partial f(x,u)}{\\partial u}\\bigg|_{(x=\\varphi_t(u,x^i),u)}\\right)v(t),\n$$\nwhere $v(t)\\in L_\\infty([0,T],\\mathbb{R}^{n\\times n})$ is controllable.\n\nLPC 是算法能正常运作的前提，其保证了非线性系统 $\\dot{x} = f(x,u)$ 在局部线性化后，扰动可以被任意控制。\n\nImpact of Updated Control: Suppose that a given control function $u$ has memorized the pair of points $(x^i, y^i)$, then\n$$\n\\delta\\varphi_t(u,x^i)=\\int_0^t\\Phi_{(u,x^i)}(t,\\tau)\\frac{\\partial f(x,u)}{\\partial u}\\bigg|_{(x=\\varphi_\\tau(u,x^i),u)}\\delta u(\\tau)d\\tau\n$$\nup to first order in $\\delta u(t)$. Here $\\Phi_{(u,x^i)}(t, \\tau)$ is the state transfer matrix defined by\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}t}\\Phi(t,\\tau)=A(t)\\Phi(t,\\tau), \\quad\n\\Phi(\\tau,\\tau)=I\n$$\n$$\nA(t) = \\frac{\\partial f(x,u)}{\\partial x}\\bigg|_{(x=\\varphi_t(u,x^i),u)}\n$$\n\n上面的公式给出了如果我在各个 $\\tau$ 时刻更新了控制为 $\\delta u(\\tau)$，那么最终的输出会变多少。\n\nL Operator: Let $R$ be the readout function,\n$$\n\\mathcal{L}_{(u,x^i)}(\\delta u):=R\\left(\\int_0^T\\Phi_{(u,x^i)}(T,\\tau)\\frac{\\partial f(x(\\tau),u(\\tau))}{\\partial u}\\delta u(\\tau)d\\tau\\right)\n$$\n\n$\\mathcal{L}$ 算子代表了 $\\delta u$ 对最终输出的影响，如果希望不遗忘，则尽可能要让 $\\mathcal{L}$ 算子为 $0$。\n\nNull Space of L Operator:\n$$\n\\mathcal{K}(u,x^i):=\\operatorname{span}\\{\\delta u\\in L_\\infty([0,T],\\mathbb{R}^{n\\times n})\\mid\\mathcal{L}_{(u,x^i)}(\\delta u)=0\\}\n$$\n$$\n\\mathcal{K}(u,\\mathcal{X}^j):=\\mathrm{span}\\{\\delta u\\in L_\\infty([0,T],\\mathbb{R}^{n\\times n})\\mid\\delta u\\in\\bigcap_{x^i\\in\\mathcal{X}^j}\\mathcal{K}(u,x^i)\\}\n$$\n\n$\\mathcal{K}$ 的价值在于只要我们选出了一个安全的子空间用于更新/投影\n\nProjection Operator:\n$$\n\\operatorname{proj}_{\\mathcal{K}(u,\\mathcal{X}^j)}\\nabla_{u(t)}\\mathcal{J}^{j+1}(u):=\\arg\\min_{d(t)\\in\\mathcal{K}(u,\\mathcal{X}^j)}\\int_{0}^{T}\\|d(\\tau)-\\nabla_{u(\\tau)}\\mathcal{J}^{j+1}(u)\\|^2d\\tau\n$$\n\n将理想学习方向 $\\nabla_{u(t)}\\mathcal{J}^{j+1}$ 投影到 $\\mathcal{K}(u,\\mathcal{X}^j)$ 中，从而构成更新方向，即 $\\delta u=\\mathrm{proj}_{\\mathcal{K}}(\\nabla_uJ^{j+1})$。这里的投影操作就是找了 $\\mathcal{K}(u,\\mathcal{X}^j)$ 中离 $\\nabla_{u(t)}\\mathcal{J}^{j+1}$ 距离最近的。\n\n\nMain Results\nCondition for Tuning without Forgetting:\n​\nMore Detailed Condition:\n​\n\nNumerical Methods\nApproximation of $\\mathcal{L}_{(u,x^i)}(\\cdot)$: We provide a method to compute a numerical approximation of $\\mathcal{L}_{(u,x^i)}(\\cdot)$ for all $x^i \\in \\mathcal{X}^j$,\n​\nPhase 1 (Implement Theorem 1) :\n​\nPhase 2 (Minimize the Norm of **$u$**​ )  : In this phase, we project the gradient of the $L^2$ norm of the control function onto the subspace of functions $\\mathcal{K}(u^k, \\mathcal{X})$ at each iteration.\n​\nPhase 3 (Refinement) : In this phase, we aim to refine the control $u$ to steer all the points closer to their associated end-points. Let $\\mathcal{P}$ be the number of iterations per sample.\n​\n‍\n","description":"","id":"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/","path":"/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/","title":"论文阅读：Control Theoretic Approach to Fine-Tuning and Transfer Learning"},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"body":"\nOriginal Paper​\n\n\nIntroduction\nViT:\n​\nLoRA: LoRA (Low-Rank Adaptation) freezes the original model weights and injects trainable, low-rank matrices into its layers.\n​\nAdaptFormer: AdaptFormer adapts Vision Transformers to new tasks by inserting small, lightweight modules in parallel to the existing feed-forward networks.\n\n  \n  Comparison of previous full and AdaptFormer fine-tuning.\n​\n\nA Control Formulation of PEFT Algorithms\nNotation: Given an image $x_0 \\in \\mathbb{R}^{C \\times H \\times W}$(Channel, Height, Width), the ViT model splits and embeds it into visual tokens $x_0^\\prime \\in \\mathbb{R}^{m \\times d}$, where $m$ denotes the number of tokens and $d$ refers to the length of each token. By adding an additional class-token, ViT forms $x_1 \\in \\mathbb{R}^{(m+1) \\times d}$. The $t$-th block of ViT is defined as:\n$$\nx_{t+\\frac12}=\\text{MHSA}(\\text{LN}(x_t))+x_t, \\quad x_{t+1}=\\text{FFN}(\\text{LN}(x_{t+\\frac12}))+x_{t+\\frac12}\n$$\nfor $t = 1,2, \\cdots, T-1$. Here MHSA, FFN and LN denote the multi-head self-attention, feed-forward network and layer normalization, respectively.\nDynamics of LoRA: LoRA finds functions $\\{g_t\\}$ to\n$$\nx_{t+1}=f_{t}\\left(x_{t},\\theta_{t},g_{t}(x_{t},u_{t})\\right).\n$$\nwhere $x_t \\in \\mathbb{R}^{(m+1) \\times d}$ is the token at the $t$-th layer, $\\theta_t$ is the parameter at the $t$-th layer, and $g_t(x_t, u_t) = x_tu_t$ satisfies\n$$\nu_t=A_tB_t,\\quad A_t\\in\\mathbb{R}^{d\\times r},B_t\\in\\mathbb{R}^{r\\times d}, \\quad r\\ll d.\n$$\nDynamics of AdaptFormer: The dynamics can be expressed as\n$$\nx_{t+1}=f_t(x_t,\\theta_t)+g_t(x_t,u_t).\n$$\nOverall Goal: The objective is to find the control such that the terminal loss on downstream tasks could be minimized:\n$$\n\\min_{\\{u_t,\\theta_T\\}}\\frac1N\\sum_{i=1}^N\\mathcal{L}(x_{\\mathrm{Pred},i},y_i)\n$$\nsuch that\n$$\nx_{t+1,i}={f}_t(x_{t,i},\\theta_t)+g_t(x_{t,i},u_t), \\quad t\\in[1,\\cdots,T-1],\n$$\n$$\nx_{\\mathrm{Pred},i}=f_T(x_{T,i}^\\mathrm{cls},\\theta_T).\n$$\nHere $N$ indicates the number of samples.\n\nControllability Analysis\nA Sufficient Condition for Controllability:\n​\nBenefits of Nonlinear Controller: Let $N$ denote the number of samples and $D$ denotes the dimension of state/parameter.\n​\n‍\n\nNonlinear Controller Design\nCPA (Cross-Patch Attention) : Add additional cross-patch mechanism\n$$\nx^{p(j’)}=\\text{CPA}(x)=\\sum_j\\frac{\\exp\\langle x^{p(i)},x^{p(j)}\\rangle}{\\sum_m\\exp\\langle x^{p(i)},x^{p(m)}\\rangle}x^{p(j)}\n$$\nwhere $x^{p(j)}$ denotes the $j$-th patch of $x$.\nNonlinear Controller Design:\n‍\n​\n$$\n\\operatorname{Control}(x)=\\operatorname{LoRA}(x)+\\operatorname{CPA}\\left(\\operatorname{LoRA}(x)\\right)\n$$\n\nExperiments\nCompeting Algorithms: We compare our method with the following algorithms:\n\nFull-Tuning\nLinear Probing: Appending an additional trainable linear layer on top of the pre-trained model while keeping the rest parameters fixed.\nVisual Prompt Tuning (VPT): Concatenating a set of trainable tokens with existing image tokens.\nLoRA: Injecting trainable low-rank matrices to $W_Q$ and $W_V$.\nAdaptFormer: A vision-specific LoRA algorithm by perturbing the FFN layer with (almost) linear controls.\n\nExperiments on Vision Benchmarks:\n​\n​\nMulti-Head Controller Experiment:\n​\n‍\n","description":"","id":"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/","path":"/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/","title":"论文阅读：Parameter-Efficient Fine-Tuning with Controls"},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"body":"\nOriginal Paper: [2509.04259] RL's Razor: Why Online Reinforcement Learning Forgets Less\nPosts: RL's Razor: Why On-Policy Reinforcement Learning Forgets Less\n\n\nIntroduction\nOn-Policy RL: The agent learns only from experience generated by its currect policy. It follows its current strategy, collects data, updates its strategy, and then discards the old data.\nOff-Policy RL: The agent can learn from experience generated by a different policy. This could be data from an older version of itself, from a human demonstrator, or from another AI.\n\nOn-Policy RL 只学习由【当前最新版本】的策略所产生的经验，Off-Policy 允许学习由【任何策略】（包括过去的自己、人类专家等）所产生的经验。\n\nOnline RL: The agent learns by actively interacting with a live environment. It takes an action, gets a result, and learns from it in real-time.\nOffline RL: The agent learns from a fixed, pre-collected dataset of past interactions. It has no ability to explore or gather new data.\n\nOnline 和 On-Policy 的辨析\n\nOnline 决定了经验是如何产生的：是通过与环境的实时互动，而非提前准备好\nOn-Policy 决定了采集到的经验是如何被使用的，是“用完即弃”（On-Policy），还是“存起来反复用”（Off-Policy）\n\nOffline 和 Off-Policy 的辨析：Offiline 一定是 Off-Policy 的，反之不一定\n\nPrevious Approaches to Catastrophic Forgetting: Previous approaches such as constraining weight updates, preserving learned features, or regularizing shift in output distribution focus on its effects rather than its underlying cause. Some prior work claimed that forgetting can be determined by how much the model’s distribution shifts on past tasks, but in practice this is infeasible because the set of prior tasks is vast or even unbounded.\nEWC: Elastic weight consolidation can be seen as approximations to KL minimization.\nSFT Versus RL: Prior comparisons between SFT and RL have focused on new task performance rather than the extent of forgetting. It is found that on-policy learning can achieve stronger performance when the expert providing supervision is the same.\nParityMNIST: ParityMNIST is derived from MNIST, but reframes the task as predicting parity (even vs. odd).\n\nContribution of This Work\nRL Forgets Less than SFT: Even when SFT and RL achieve the same performance on the new task, we observe that SFT often achieves new-task gains by erasing prior knowledge, while RL better preserves old skills.\n\n  \n  Bias toward KL-minimal solutions reduces forgetting: (1) Left: RL converges to those closest in KL to the base model. (2) Right: RL preserves better prior-task performance compared to SFT.\n​\nEmpirical Forgetting Law: When fine-tuning a model $\\pi$ on a new task $\\tau$, the degree of forgetting is accurately predicted by $\\mathbb{E}_{x \\sim \\tau}[\\operatorname{KL}(\\pi_0 ||\\pi)]$, where $\\pi_0$ is the base policy. KL divergence is a reliable predictor of forgetting across settings.\nDifference between SFT and RL: On-policy methods such as RL are inherently biased toward solutions that remain closer to the original policy in KL divergence.\nKL Hypothesis Validation: We construct a “oracle SFT” that minimizes KL divergence while achieving perfect accuracy, which achieves even less forget than RL. This demonstrate that RL’s advantage does not stem from being inherently different, but from its implicit KL minimization.\n\n并不是 RL 好，而是 RL 中内含的 KL Minimizer 减少了遗忘，如果 SFT 能降低 KL Divergence，其也能减少遗忘。\n\n\nResults\nExperimental Setup: We fine-tuned models using the same set of prompts. One group of models was trained with SFT, and another with RL using GRPO. In RL training, we used only a binary success indicator as the reward, without explicit KL regularization.\n\nLLM, Math Reasoning: Qwen 2.5 3B-Instruct on Open-Reasoner-Zero dataset.\nLLM, Science Q&amp;A: Qwen 2.5 3B-Instruct on Chemistry L-3 subset of SciKnowEval.\nLLM, Tool use: Qwen 2.5 3B-Instruct on ToolAlpaca dataset.\nRobotics, Pick and Place: OpenVLA 7B on SimplerEnv environment.\n\nRL Forgets Less than SFT: RL is able to learn new tasks while incurring minimal forgetting, whereas SFT reaches similar new-task performance only by sacrificing prior knowledge.\n\n  \n  Pareto frontiers of RL and SFT: Comparing the performance of a fine-tuned model on the new task (x-axis) and prior task (y-axis). Each point corresponds to a model trained with a different set of hyperparameters.\n​\nSmaller KL Divergences Lead to Less Forgetting: We pretrained a MLP jointly on a subset of ParityMNIST and FashionMNIST, then fine-tuned only on ParityMNIST while measuring forgetting on FashionMNIST. We constructed an oracle SFT distribution (use the KL minimization answer as label instead of the true label).\n\n  \n  KL divergence predicts catastrophic forgetting: (1) SFT outperforms RL only when an oracle distribution is used. (2) Forgetting aligns a single curve when plotted against KL divergence. (3) RL improves new-task accuracy with much smaller KL shifts than SFT.\n​\n\n​SFT on dist 1​: All even digits mapped to label 0, all odd digits to label 1.\n​SFT on dist 2​: Even digits randomly mapped to $\\{0, 4\\}$, odd digits to $\\{1,5\\}$.\n​SFT on optimal dist​: Annotations drawn from the minimum-KL distribution consistent with task correctness. Concretely, for an input image $x$ we compute $\\pi_0(\\cdot | x) \\in \\mathbb{R}^{10}$ and the binary indicator vector $R \\in \\{0,1\\}^{10}$ encoding which labels are correct given the digit’s parity. The oracle distribution $q^\\ast$ is the solution to\n\n$$\nq^*=\\arg\\min_qD_{\\text{KL}}(\\pi_0\\|q)\\quad\\text{s.t.}\\quad q^\\top R=1.\n$$\n\n例如给定图片 $2$，因为其是偶数，$R$ 在所有偶数位置为 $1$​，那么上面的向量 R = [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]​\n\nOn-Policy Methods Lead to Smaller KL Divergence: Here we consider the loss function of SFT and RL:\n\nSFT minimizes cross-entropy against a supervision distribution $\\pi_\\beta$ over a distribution of inputs $\\mathcal{D}$​\n\n$$\n{\\mathcal{L}}_{\\mathrm{SFT}}(\\pi)=-\\mathbb{E}_{x\\sim\\mathcal{D},y\\sim\\pi_{\\beta}}[\\log\\pi(y|x)]\n$$\n\nLet $A(x,y)$ be an advantage function. RL with policy gradient optimizes\n\n$$\n\\mathcal{L}_{\\mathrm{RL}}(\\pi)=-\\mathbb{E}_{x\\sim\\mathcal{D},y\\sim\\pi}\\left[A(x,y)\\log\\pi(y|x)\\right]\n$$\n. There are two features that distinguish RL from SFT:\n\nSampling Distribution: While in RL the training was done on outputs drawn from the model’s own distribution, in SFT they come from fixed external annotations.\nNegative Examples: While sampling from $\\pi$, some of the responses will be incorrect. These are usually assigned a negative coefficient $A(x,y)$. This pushes probability mass away from poor outputs.\n\nOur hypothesis is that one of these two differences is what causes RL’s resistance to forgetting. So we perform experiments with four different objectives: “GRPO”, “1-0 Reinforce”, “SFT”, and “SimPO”. The results show that the critical factor is the use of on-policy data.\n\n  \n  Comparison of algorithm classes: &amp;quot;Pos Examples&amp;quot; indicates that the dataset only contains positive examples while &amp;quot;Pos + Neg Examples&amp;quot; indicates that the dataset contains both positive and negative examples.\n​\nTheoretical Perspective: Sampling from the model’s own distribution keeps it close to the base model, while SFT pushes it toward arbitrary external distributions.\n\n  \n  KL-minimal path to optimality.\n​\n\nRL 的 policy 更新可以被视作来回的投影，源于 Information Geometry 的领域。假设空间中有我们的策略 $\\pi_k$，可行空间 $\\Pi$，最优空间 $P^\\ast$。\n\nSFT 就像给定一个 $P^\\ast$ 的一个坐标，让我们传送到那里，不管距离有多远\nRL 则先用 Information Projection 选择 $P^\\ast$ 中最近的位置进行投影，再用 Momentum Projection 投影到 $\\Pi$ 中。最终 RL 可以视作一次在 $\\Pi$ 中的更新。\n\n\n\nAlternative Hypothesis\nWe systematically evaluated alternative variables as potential predictors of catastrophic forgetting, grouped into four categories.\nWeight-Level Changes: Many prior work tried to mitigate forgetting by constraining the change in parameter space. We measured parameter changes under L1, Fisher-weighted L2, and spectral norm metrics. These metrics correlated only weakly with forgetting: large parameter shifts could occur without forgetting, and conversely, forgetting sometimes occurred despite small parameter movement.\nRepresentation/Activation-Level Changes: Some other papers focused on maintaining the previous features. We examined hidden activation shifts (L1 and L2 distances) as proxies for changes in internal representations. Although we found that there is representation drift during training, the curves were distinct between training objectives (不同训练方法的【Activation Change-Forgetting】曲线不同), meaning that it is not a good predictor.\n\n  \n  CKA similarity to the base model during training.\n​\n\nCKA (Centered Kernel Alignment) 是一种数学工具，用于衡量两个分布的相似度。CKA 越接近 $1$ 说明与原始分布越接近。上图说明了 SFT 中模型的内部知识结构（表征）遭到了破坏。\n\nSparsity and Rank of Updates: Some argue that RL updates are sparse while SFT weight updates are dense. We found that the reason for the observed sparse updates was the use of bfloat16​, which may ignoring some small updates. Performing the same training with float32​ leads to identical performance without any sparsity. So we found that all algorithms lead to full rank weight updates.\nDistributional Distances: We considered multiple measures of output distribution change: (1) Forward KL $\\mathbb{E}_{x \\sim \\tau}[\\operatorname{KL}(\\pi_0 || \\pi)]$, (2) Reverse KL $\\mathbb{E}_{x \\sim \\tau}[\\operatorname{KL}(\\pi || \\pi_0)]$, (3) Total Variation, (4) $L_2$ distance between distributions.\n\n  \n  Predictive power of alternative variables compared to forward KL.\n​\n\nDistribution 在这里指最终模型输出的差别，因为衡量遗忘最直接的办法是衡量其对老问题的回答有没有变。这里 $R^2$ 是一种统计指标，$R^2 = 1$ 表示完美预测。\n\n\nAdditional Results\nGradient Similarity versus KL Change:\n​\n‍\n","description":"","id":"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/","path":"/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/","title":"论文阅读：RL's Razor Why Online Reinforcement Learning Forgets Less"},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"body":"\nOriginal Paper: [2411.07191] The Super Weight in Large Language Models\n\n\nIntroduction\nLarge Outliers in Large Models: Once LLMs reach a certain scale, a small set of hidden state features contains outliers of exceptionally large magnitude. These outliers account for a small percentage of all activations but are crucial for preserving the compressed model’s quality.\nSuper Weights: Not all large outliers are equally important. In this paper, we study a tiny yet important set of outliers in LLMs, termed super weights. In Llama-7B, pruning the super weight, a single scalar, completely destroys the model’s ability to generate text.\n\n  \n  Super Weight Phenomenon: Pruning a single super weight can completely destroy a LLM's ability to generate text. On the left, the original Llama-7B produces a reasonable completion. On the right, after pruning the super weight, Llama-7B generates complete gibberish.\n​\nSuper Activations: Super activations are exceptionally massive activations. They persist across many layers, feature constant magnitude, and always exist at the same position regardless of input.\n\n  \n  Super activations: Exceptionally massive activations\n​\nSuper Weights behave similarly across model families and sizes:\n\nThey are always found in the mlp.down_proj​ weight.\nThey produce exceptionally large magnitude activation–the super activation.\nThey suppress stopword likelihood.\nPruning the super weight destroys quality by dampening the super activation（super activation 几乎消失了） and shifting almost all logit probability mass to stopwords（几乎只输出 stopwords）.\n\n\n  \n  How Super Weights behave: (1) Super weights are often found in an early layer's down projection (2) Super activations are propagated through skip connections. (3) This has a effect of suppressing stopword likelihoods in the final logits.\n​\n\nmlp.down_proj​：在 Transformer 架构中，Feed Forward 层（也就是 MLP 层）一般是两层神经网络，表示为 $\\operatorname{FFN}(x) = W_2(\\operatorname{ReLU}(W_1x + b_1)) + b_2)$，即先经过一个 up_proj​ 进行升维，一个 activation​ 进行非线性变换，再经过一个 down_proj​ 进行降维。\n​\nStopword 指的是那些非常常见，但是信息量很低的词，例如 the​、a​、is​、of​ 等。\n\nSuper Outliers: We refer to both super weights and super activations as super outliers, which are critical to model quality. Fortunately, there are no more than a handful of scalar super outliers per tensor.\n\nContribution of This Work\nSuper Weights: We discover a tiny subset of outliers in LLMs, at most six scalars, that are disproportionately important; pruning these super weights destroys model quality.\nIdentifying Super Weights: We present a data-free way to identify super weights using only a single forward pass and provide an index of super weights for existing, open LLMs.\nSuper Activations: We analyze how super weights influence inference and relate them to the activation outliers observed in prior work.\nCompression: By preserving super outliers, we show that round-to-nearest quantization increases effectiveness noticeably; preserving super outliers improves compression quality.\n\nIdentification of Super Weights\nSuper Weights Create Super Activations: The super activations’ channel (the position in vector) aligns with the super weights’, and the activation first appears right after the super weights.\n\n  \n  Pruning the super weight decreases the super activation's magnitude by 75%.\n​\nThe Mechanism behind Super Activations: The Hadamard product of the gate​ and up​ projection creates a relatively large activation. The super weights further amplify it and create super activations.\n\nGate 指的是对输入信息进行过滤和放缩的操作，假设 A​ 是输入向量；g​ 是与 A​ 等长的门向量，其元素在 0~1​ 之间。那么 gate 操作后的输出为 B = A ⊙ g​，其中 ⊙​ 是逐元素（Hadamard）乘法。\n虽然经典 Transformer 架构中的 FFN 层没有 gate 层，但是现代 Transformer，如 Llama、Mistral 等模型中有。\n\nIdentifying Super Weight by Activation Spikes: Super weights can be located by detecting the spikes in the down_proj​ inputs and outputs distributions across the layers. This dectection only requires a single input prompt, rather than a set of validation data or use-case examples.\nIdentifying Steps: Let $W \\in \\mathbb{R}^{D \\times H}$ be the down_proj​ weight matrix, where $D$ is the dimension of the activation feature and $H$ is the intermediate hidden dimension. Let $X \\in \\mathbb{R}^{L \\times H}$ be the input matrix, where $L$ is the sequence length. Then the output of down_proj​ is\n$$\nY = XW^\\top, \\quad\n\\text{where} \\quad Y_{ij} = \\sum_{k=1}^d X_{ik}W_{jk}.\n$$\nSuppose $Y_{ij}$ is a super activation, $X_{ik}$ and $W_{jk}$ are outliers, then $Y_{ij} \\approx X_{ik}W_{jk}$.\n\nPlot extreme outliers in the input and output activations of mlp.down_proj​.\nDetermine the layer and coordinates of the super weights.\nRemove detected super weights and repeat the above process, until the magnitudes of large maximum activations are greatly suppressed.\n\n\n  \n  How to identify the super weights: The input has a large activation on layer 2. The value's channel index tells the row of super weight. The output has a large activation at layer 2. This value's channel index gives us the column of the super weight.\n​\n\nMechanisms of Super Weights\nSuper Weights (partially) Operate via Super Activations: We want to assess the super weight’s impact on model quality is solely mediated by super activations or other factors. We conduct experiments under three conditions:\n\nOriginal model\nRemove super weights (Prune SW): Set the weight scalar as zero.\nRemove super weights and restore super activation (Prune SW, +SA): Set the weight scalar as zero, and restore super activation at the layer where it first appears.\n\nThe results show that super activations contribute substantially to the model’s performance, they do not fully account for the super weight’s overall influence on quality.\n\n  \n  Super Weight Importance: &amp;quot;Prune SW&amp;quot; indicates pruning single super weight, &amp;quot;Prune Non-SW&amp;quot; indicates pruning other 7,000 largest-magnitude weights, &amp;quot;Prune SW,+SA&amp;quot; indicates pruning super weight but restoring super activation. The experiment is conducted to assess the model's accuracy on seven zero-shot datasets and perplexity on C4 and Wiki-2.\n​\nSuper Weights Affect Output Token Probability Distributions:\n\n  \n  Super Weights Suppress Stopwords: Removing super weights results in 2 to 5 times larger stopword probabilities, while non-stopwords decrease by 2 to 3 times.\n​\nSensitivity of Super Weights: We investigate how does increasing the magnitude of super weights affect model quality.\n\n  \n  Amplifying Super Weight Improves Quality: There exists some scaling where quality is improved.\n​\n\nSuper-Outlier Aware Quantization\nQuantization: The presence of outliers significantly degrade quantization quality. However, super outliers carry significant importance for model quality, making their preservation during\nquantization critical.\nRound-to-Nearest Quantization: Here we consider the asymmetric round-to-nearest quantization\n$$\nQ(\\mathbf{X})=\\mathrm{Round}\\left(\\frac{\\mathbf{X}-\\mathrm{MIN}(\\mathbf{X})}{\\Delta}\\right),Q^{-1}(\\mathbf{\\hat{X}})=\\Delta\\cdot\\mathbf{\\hat{X}}+\\mathrm{MIN}(\\mathbf{X})\n$$\nwhere $\\mathbf{X}$ is the tensor to be quantized, $\\mathrm{MIN}(\\mathbf{X})$ is the smallest element in $\\mathbf{X}$, and $\\Delta=\\frac{\\mathrm{MAX}(\\mathbf{X})-\\mathrm{MIN}(\\mathbf{X})}{2^{N-1}-1}$ is the quantization step with $N$ being the number of bits. So super outliers in $\\mathbf{X}$ drastically increase the step size, increasing the quantization error.\n\n量化步长 $\\Delta$ 衡量了量化后两个相邻离散值之间的距离，可以类比于图像的分辨率。假设 $\\mathbf{X}$ 中大部分值都在 $[-1.0, 1.0]$ 区间内，突然出现了一个超大的离群值（outlier），这会导致量化步长 $\\Delta$ 激增，从而导致精度下降严重。\n\nSolution to Outlier Quantization:\n\nHold out the super outlier to prevent adverse effects on inlier quantization.\nRestore the super outlier’s value after dequantization.\n\nActivation Quantization: We replace the super activation with the median, then quantize, dequantize and restore it.\n$$\n\\hat{A}=\\mathrm{RESTORE}(Q^{-1}(Q(\\mathrm{REPLACE}(A)))\n$$\nWeight Quantization: First, we identify super weights. Second, we clip the outlier weights, quantize, and dequantize the clipped weights. Third, restore the half-precision super weights after dequantization.\n$$\n\\hat{W}=\\mathrm{RESTORE}(Q^{-1}(Q(\\mathrm{CLIP}_z(W)))\n$$\nWe parameterize clipping using a z-score.\n\nz-score 方法来自于统计学，给定一个阈值 z​，其衡量每个元素偏离平均值的程度。一旦某个元素的偏离值超过阈值 z​，则会被视作离群值。上面的 CLIP​ 操作即将离群值裁剪掉。\n\n\n  \n  Round-to-nearest with super-activation handling is competitive. Here, &amp;quot;Naive W8A8&amp;quot; indicates the naive round-to-nearest quantification, &amp;quot;SmoothQuant&amp;quot; is an advanced quantification method.\n​\n\nExperiments\nWe first evaluate the perplexity (PPL) of different quantization method for Wiki-2 and C4.\n\n  \n  Handling the super activation improves activation quantization: FP16 indicates the un-quantized model.\n​\nWe also evaluate the accuracy on zero-shot benchmarks.\n\n  \n  Restoring super weight improves block scaling: Here &amp;quot;RTN&amp;quot; refers to &amp;quot;round-to-nearest&amp;quot;.\n​\n\nBlock size 是量化中的一个概念，指的是为了更好地适应 weight tensor 的局部变化，将大的 weight tensor 切割为多个小块独立进行量化\n\n大 Block Size：量化粗超，但是高效\n小 Block Size：量化精细，但是计算和存储开销大\n\n\n","description":"","id":"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/","path":"/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/","title":"论文阅读：The Super Weight in Large Language Models"},"https://reichtumqian.pages.dev/blog/mutagen/":{"body":"Mutagen 是好用的命令行 SSH 转发与 SCP 目录同步软件，见 mutagen-io/mutagen: Fast file synchronization and network forwarding for remote development，主要支持以下功能：\n\n文件同步：本地与远程、远程与远程（通过本地中转）、本地与 Docker 等\n长期端口转发：只要创建后一直保持端口转发\n\n安装\n从 Releases · mutagen-io/mutagen 中下载二进制文件并放到 PATH 中。\n快速上手：端口转发\n端口转发的功能由 mutagen forward 控制，具体而言：\n\nmutagen forward create --name=web-app tcp:localhost:8080 docker://devcontainer:tcp:localhost:1313 将 Docker 的 1313 端口映射到本地的 8080 （支持 SSH 配置）\nmutagen forward list ：列出端口转发列表\nmutagen forward monitor &lt;name&gt; ：监控端口转发\nmutagen forward terminate &lt;name&gt; ：取消端口转发\nmutagen forward pause/resume &lt;name&gt; ：暂停与恢复端口转发\n\n\n快速上手：文件同步\n文件同步相关功能由 mutagen sync 命令控制，具体包括：\n\nmutagen sync create --name=web-app-code ~/project user@example.org:~/project ：创建同步（支持 SSH 配置）\nmutagen sync list ：列出同步会话\nmutagen sync monitor &lt;name&gt; ：监控文件同步\nmutagen sync terminate &lt;name&gt; ：取消同步\nmutagen sync pause/resume &lt;name&gt; ：暂停与恢复同步\n\n\n","description":"","id":"https://reichtumqian.pages.dev/blog/mutagen/","path":"/blog/mutagen/","title":"Mutagen：好用的端口转发与远程文件同步工具"},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"body":"今天在 peft​ 库上折腾了一天，发现 peft​ 库的 get_base_model()​不能返回原始模型，还是返回了微调后的模型，因此记录一下。\n\n参考 GitHub Issue：get_base_model() is returning the base model with the LoRA still applied. · Issue #430 · huggingface/peft\n\nget_base_model()​ 的错误使用：当前不要用 get_base_model()​ 去获取原始模型。例如我们可能如下使用：\n\n我们以为 reference_model​ 是未经过微调的模型，实际上 peft​ 返回了经过微调的模型，也就是 reference_model​ 和 model​ 没有差别！\n如何正确获取未经微调的模型：建议使用 with model.disable_adapter()​，例如\n\n","description":"","id":"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/","path":"/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/","title":"Peft 获取原模型 get_base_model 的 Bug"},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"body":"Pytest 是 Python 中好用的自动化测试框架，本文同时讲解了如何在 VSCode 中调用。\n\nPytest 快速入门\n安装 Pytest：\n\nPytest 中的测试：Pytest 中测试文件必须命名为 test_*.py​ 或 *_test.py​，测试函数必须以 test_​ 开头。例如\n\n从命令行运行：最简单的运行方式是使用命令行，cd​ 到项目测试根目录，然后运行\n\nPytest 会自动扫描当前目录及子目录下所有符合规则的测试文件和函数，并执行它们。你会看到一份清晰的报告。\n\n\n在 VSCode 中使用 Pytest\n配置 VS Code：首先安装 Python 扩展，然后点击 VS Code 左侧活动栏的“烧杯”图标，进入测试面板。点击“配置 Python 测试”，在弹出的菜单中选择 ​**​pytest​**​，然后选择你的测试所在的根目录。在 settings.json​ 中可以修改配置文件\n\n测试工作流：在测试面板中，我们可以看到所有测试的树状结构。每个测试用例、每个文件、每个类旁边都有【Run】、【Debug】按钮，可以随时单独运行。\n​\n‍\n","description":"","id":"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/","path":"/blog/pytest-vscode-kuai-su-shang-shou/","title":"Pytest + VSCode 快速上手"},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"body":"Pytest 是 Python 中的一个单元测试框架，而 Fixture 是为 Pytest 测试提供其运行所需的数据、对象、环境和状态的函数。它负责“准备工作”（Setup）和“清理工作”（Teardown）。\n\nPytest Fixture 的基础用法\n什么是 Fixture：在 Pytest 中，一个 Fixture 就是一个被 @pytest.fixture​ 装饰器标记的 Python 函数。这个函数的名字可以被其他测试函数当作参数来使用。当 Pytest 发现一个测试函数请求了一个 Fixture，它会：\n\n在运行该测试函数之前，先去执行对应的 Fixture 函数。\n将 Fixture 函数的返回值（如果有的话）传递给测试函数。\n在测试函数执行完毕后，执行 Fixture 中定义的清理操作。\n\n@pytest.fixture 的用法：假设我们有好几个测试用例，都需要用到一个相同的数据字典。\n\n没有 Fixture 的写法（不推荐）：user_data​ 这个字典在每个测试中都重复定义了，非常冗余。\n\n\n\n使用 Fixture 的写法（推荐）：Pytest 在执行 test_user_info_display​ 和 test_user_permission​ 时，会自动找到并执行 user_data​ Fixture，然后将它的返回值 data​ 注入到测试函数的 user_data​ 参数中。\n\n\n使用 yield 实现 Setup 和 Teardown：如果我们需要清理工作（Teardown），我们可以使用 yield​ 关键字，其之前的代码是 Setup 部分，其之后的代码是 Teardown 部分。\n\n\nFixture 进阶用法\nFixture 的 Scope：默认情况下，Fixture 的作用域是 function​，意味着它会对每一个使用它的测试函数都执行一次，有时候这会造成不必要的开销。我们可以通过 scope​ 参数来控制 Fixture 的生命周期：\n\nscope=\"function\"​ (默认): 每个测试函数执行一次。\nscope=\"class\": 每个测试类（Test Class）只执行一次。\nscope=\"module\": 每个模块（.py​ 文件）只执行一次。\nscope=\"session\": 整个测试会话（运行 pytest​ 命令一次）只执行一次。\n\n例如连接数据库是一个耗时操作，我们希望整个测试文件（模块）只连接一次：\n\nFixture 之间相互依赖：一个 Fixture 可以像测试函数一样，请求另一个 Fixture\n\n","description":"","id":"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/","path":"/blog/pytest-zhong-de-fixture/","title":"Pytest 中的 Fixture"},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"body":"‍\n\nLoRA 思想回顾\nLoRA 假设在微调过程中，权重的变化是一个 low-rank 的矩阵，因此其冻结模型原始权重 $W_0$，并在旁边注入两个小的、可训练的 low-rank 矩阵 $A$ 和 $B$ 来模拟权重的更新 $\\Delta W$：\n$$\nW_{tuned}=W_0+\\Delta W=W_0+B A\n$$\n其中 $A \\in \\mathbb{R}^{r \\times k}$，$B \\in \\mathbb{R}^{d \\times r}$，其中 $r$ 为指定的权重矩阵的秩。\n\nPytorch-Lightning + Peft 实现 LoRA\npeft​ （Parameter-Efficient Fine-Tuning）是 Hugging Face 公司实现的用于高效微调的库。其核心工具是 get_peft_model​ 函数（95% 情况下够用）。下面以一个最简单的例子说明如何使用 peft​ 库实现 LoRA。\nStep 1. 准备一个 Pytorch 模型：peft​ 的 get_peft_model​ 函数是作用于一个现有的模型，因此我们需要先实现一个最简化的模型\n\nStep 2. 定义 LoRA 配置并应用：我们需要定义一个 LoraConfig​ 对象，并且包含 LoRA​ 的配置信息。其中 target_modules​ 是一个字符串的列表，该 LoRA​ 配置会作用于任何 name​ 中包含这些字符串的层。\n\nStep 3. 像平常一样训练模型：peft​ 库最强大的地方是其只对模型进行了修改，训练流程完全不变\n\n","description":"","id":"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/","path":"/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/","title":"Pytorch-Lightning + Peft 实现 LoRA 微调示例"},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"body":"自动求导（Autograd）是 Pytorch 框架的基石，下面我们对其思想、方法进行总结。\n\n计算图 Computational Graph\n计算图的概念：当我们对一个 Tensor 执行任何操作时，Pytorch 后台会默默构建一个有向无环图 Graph 来记录这些操作。图的节点为 Tensors；边为函数 Operations，它们接收输入的 Tensors 并计算输出的 Tensors。一个典型的计算图如下所示：\n\n自动求导：Pytorch 的自动求导引擎 autograd​ 通过上面的计算图，从最终的输出 z​ 开始，使用链式法则（z.backward()​），反向追溯到每个输入参数 x​、y​、w​。从而计算 z​ 关于这些输入值的梯度。\nrequires_grad 属性：requires_grad​ 是 torch.Tensor​ 的一个 bool​ 类型属性，默认值为 False​。如果为 True​，则会追踪对这个 Tensor​ 的所有操作。任何需要学习的参数（如 weight​ 和 bias​），它们本质上也是 torch.Tensor​，必须把它们的 requires_grad​ 设置为 True​。\n\ngrad 属性：对于 requires_grad​ 的 Tensor，最终计算的梯度会被保存在 .grad​ 属性中\n\n例如上图中我们希望计算 z​ 关于 x​ 的导数，则必须把 x.requires_grad​ 设置为 True​。\n\n\n\n梯度的计算：Backward 与 Autograd\nBackward 函数：.backward()​ 函数会从当前的 Tensor​ 出发（通常是最终的 loss​），沿着计算图反向传播，计算所有 requires_grad = True​ 的叶子节点 Tensor 的梯度。对于中间节点，其会计算关于它们的梯度，但是用完后会被直接释放不被保存，除非显式调用 .retain_grad()​。\n\n梯度的累积：Pytorch 中默认梯度会累积，即每次调用 .backward()​ 后，Pytorch 会把新计算的梯度加到原来的 .grad​ 上\n\ntorch.autograd.grad() ：autograd.grad()​ 是比 backward()​ 更加底层的函数，其直接调用 autograd​ 引擎返回所需的梯度，而不是像 .backward()​ 一样将梯度填充到 .grad​ 属性中。\n\n高阶求导示例：autograd.grad()​ 还可以将求导作为一个操作放入计算图中。例如用 z​ 关于 x​ 求导得到 grad_x​，这会创建一个新的计算图，包含了 x​ 到 grad_x​ 的计算关系。\n\n清空梯度\n由于 Pytorch 的默认行为是累积梯度，因此在神经网络每个 batch​ 开始前，我们必须手动清空上一轮积累的梯度，常见的方法有两种：\n手动清零：对 Tensor 的 grad​ 属性调用 .zero_()​方法，这会遍历模型的所有参数并逐个清零\n\n使用优化器清零：这是标准做法，Pytorch 的优化器会接收模型的所有参数，调用 optimizer.zero_grad()​ 即可自动清零模型的参数\n\n\n‍\n","description":"","id":"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/","path":"/blog/pytorch-qiu-dao-cao-zuo-zong-jie/","title":"Pytorch 求导操作总结"},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"body":"\n逐元素运算（Element-Wise Operations）\n逐元素运算指的是对两个形状相同的 Tensor 的对应元素进行操作。\n\n\n广播运算（Broadcasting）\n广播允许 PyTorch 中不同形状的 Tensor 、标量与 Tensor 进行计算。\n不同形状 Tensor 计算：广播规则为\n\n从两个 Tensor 的末尾维度开始，向前比较它们的维度。\n如果两个维度相等，或者其中一个维度为 1​，那么它们是兼容的。\n如果某个 Tensor 的维度比另一个少，它会被自动添加维度，并在前面补上 1​。\n\n\n标量与 Tensor 计算：\n\n\n矩阵与向量运算\nPyTorch 提供了专用的函数和运算符来支持矩阵乘法运算。\n二维矩阵计算：两个二维张量（不支持矩阵和向量）\n\n批量矩阵计算：对于三维 Tensor 可以将第一个维度视作批次大小（Batch Size），然后做批次乘法\n\n万能矩阵乘法：torch.matmul(a, b)​ 或者 a @ b​ 能根据 Tensor 的维度采用最合适的操作：\n\n向量 x 向量 (1D) : 返回点积 (dot product)。\n矩阵 x 向量 (2D @ 1D) : 返回矩阵-向量乘积。\n矩阵 x 矩阵 (2D @ 2D) : 等同于 torch.mm​。\n批量 x 批量 (3D+ @ 3D+) : 支持广播机制的批量矩阵乘法。例如，一个 (J, 1, N, M) 的 Tensor 可以和 (K, M, P) 的 Tensor 相乘。\n\n\n原地操作\nPyTorch 中许多操作都有一个带下划线 _​ 的版本，这表示它们是原地（in-place）操作。它们会直接修改 Tensor 的内容，而不是创建一个新的 Tensor。\n\n注意事项：原地操作会节省内存，但可能会在计算梯度时（例如在 backward()​ 调用中）带来问题，因为它会修改用于计算梯度的前向传播的数值。除非你确定不会影响梯度计算或者内存非常紧张，否则建议使用非原地操作 (x = x + y​)，这样代码的可读性和安全性更高。一般原地操作常用于编写优化器。\n","description":"","id":"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/","path":"/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/","title":"Pytorch Tensor 数学操作总结"},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"body":"方法返回类型描述示例：(3, 4, 5)​\n​x.shape​​torch.Size​以元组形式返回 Tensor 形状​torch.Size([3, 4, 5])​\n​x.shape[n]​​int​返回第 n​ 个维度的大小​x.shape[0] = 3​\n​x.size()​​torch.Size​和 x.shape​ 相同​torch.Size([3, 4, 5])​\n​x.size(n)​​int​返回第 n​ 个维度的大小​x.size(1) = 4​\n​len(x)​​int​返回第 0​ 个维度的大小​len(x) = 3​\n​x.dim()​​int​返回维度数量​x.dim() = 3​\n​x.numel()​​int​返回 Tensor 元素总数​x.numel() = 60​\n\n‍\n","description":"","id":"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/","path":"/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/","title":"Pytorch Tensor 形状操作总结"},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"body":"在 PyTorch 中，无论是整个网络、一个卷积层，还是一个包含多个层的复杂模块，它们都继承自同一个基类：torch.nn.Module​。nn.Module​ 可以包含其他的 nn.Module​，这使得网络架构可以像套娃一样层层嵌套，形成一个树状结构。\n\nPyTorch 网络结构基础\n网络层 Layers：网络层是神经网络中最基本的计算单元，负责执行具体的数学运算。常见的网络层类型包括：\n\nConv2d: 二维卷积层，用于提取图像特征，是 CNN 的核心。例如 Conv2d(3, 64, kernel_size=(3, 3), ...)​ 表示输入通道为 3 (RGB图像)，输出通道为 64，卷积核大小为 3x3。\nBatchNorm2d: 二维批量归一化层，用于加速模型训练，提高稳定性。\nReLU: 激活函数层，引入非线性，使网络能够学习更复杂的模式。\nLinear: 全连接层，通常用于网络的末端，进行分类或回归。\nIdentity: 占位层，它什么也不做，原样输出输入。在 ResNet 中有时用于保持结构一致性。\n\n网络层名 Layer Names：网络层名是你在代码中给每个网络层或容器赋予的变量名。在 PyTorch 中的模型摘要中，括号内的为网络层名。网络层名是在模型初始化时被赋予的\n\n网络层容器 Containers：网络层容器本身也是一种 nn.Module​，它的主要作用是像一个 “盒子” 或 “工具箱”，用来组织和管理其他的 nn.Module​（包括其他容器和计算层）。我们这里介绍两种容器：\n\nSequential: 顺序容器。这是最常见的容器，它会按照你添加模块的顺序，依次执行内部的模块。\n自定义容器 ( 例如 ResNet​, BasicBlock​): 除了 Sequential​ 这种现成的容器，我们还可以通过自己定义一个类并继承 nn.Module​ 来创建更复杂的自定义容器。\n\nSequential 容器中的层名：默认情况下 Sequential​ 容器从 0​ 开始给每层容器起名。例如\n\n输出应该如下：\n\n‍\nResNet-18 网络结构解析\n我们以 torchvision​ 中的 resnet-18​ 为例，看看其网络结构。\n\n直接成员变量：self.conv1​、self.bn1​、self.relu​、self.maxpool​、self.layer1/2/3/4​、self.avgpool​、self.fc​\n容器结构：4 个 self.layer​ 都使用了 nn.Sequential​，并且内部使用了自定义的 BasicBlock​，每个 BasicBlock​ 还各有不同。\n\n\n","description":"","id":"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/","path":"/blog/pytorch-wang-luo-jie-gou-ji-chu/","title":"PyTorch 网络结构基础"},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"body":"Pytorch​ 中的数据管理由 Dataset​ 和 DataLoader​ 两个类实现。\n\nPytorch 中的数据处理\nPytorch 数据处理的步骤：Pytorch​ 中处理和加载数据一般需要经历以下步骤\n\n加载原始数据：从硬盘读取数据（例如图片、文本、CSV 文件）\n预处理数据：将原始数据转换成 Tensor，进行必要的变换（如尺寸调整、归一化）\n分批（Batching）：将整个数据集分成一个个小批次（mini-batch）\n迭代：将这些批次数据送入模型进行训练或评估\n\nDataset 与 DataLoader 的分工：Pytorch​ 中主要用 Dataset​ 和 DataLoader​ 两个类实现了上述操作\n\nDataset​：负责加载和预处理单个数据样本，使用 __getitem__​ 读取每一个数据点。\nDataLoader​：负责从 Dataset​ 中取出数据，并将其打包成批次以供训练\n\n\ntorch.utils.data.Dataset 类\nDataset 类基本使用：Dataset​ 是一个抽象类，我们需要创建自己的类来继承它，并实现两个方法：\n\n__len__(self)​：返回数据集样本的总数。DataLoader​ 会用它来确定迭代的次数。\n_getitem__(self, idx)​：接收一个索引 idx​，返回数据集中对应的一个样本。数据加载和预处理（transform​）一般在这里完成。\n\n示例：从文件夹读取图片：假设我们的图片存储在如下目录中：\n\n我们可以创建一个 CustomImageDataset​\n\n数据变换与增强 transform：原始数据很少能直接送入模型。图片需要被统一尺寸、转换为 Tensor、并进行归一化；文本需要被分词、转换为 ID。transform​ 就是用来完成这些预处理工作的。例如 torchvision.transforms​ 模块为图像处理提供了大量现成的工具\n\n\ntorch.utils.data.DataLoader 类\nDataLoader 的基本使用：DataLoader​ 是一个迭代器，它从 Dataset​ 中自动抓取数据，打包成批次。其包含如下核心参数：\n\ndataset: 我们刚刚创建的 Dataset​ 实例。\nbatch_size​ (int): 每个批次包含的样本数。默认为 1。\nshuffle​ (bool): 是否在每个 epoch 开始时打乱数据顺序。训练时通常设为 True​，验证/测试时设为 False​。\nnum_workers​ (int): 用于数据加载的子进程数。0​ 表示在主进程中加载。大于 0​ 的值可以显著加速数据加载，避免 GPU 等待。\ncollate_fn​ (callable, optional): 用于将多个样本合并成一个批次的函数。下面会重点讲解。\npin_memory​ (bool): 如果为 True​，数据加载器会将张量复制到 CUDA 固定内存中，这可以加快数据到 GPU 的传输速度。\n\n示例：创建和使用 DataLoader\n\ncollate_fn 自定义批次合并逻辑：DataLoader​ 的默认合并函数 default_collate​ 简单地使用 torch.stack()​ 将样本列表堆叠成一个批次，其使用场景是 Dataset​ 返回的每个样本都有相同的形状。但是，如果样本形状不一，​​default_collate​​ 就会报错。最典型的例子是自然语言处理（NLP），每个句子的长度（词元数量）都不同。此时就需要自定义 collate_fn​，其工作逻辑为：\n\nDataLoader​ 从 Dataset​ 中取出 batch_size​ 个样本，形成一个列表，例如 [sample1, sample2, ..., sample_batch_size]​。\nDataLoader​ 将这个列表传递给 collate_fn​ 函数。\ncollate_fn​ 函数负责处理这个列表，并返回一个或多个已经正确打包好的批次 Tensor。\n\n示例：处理不同长度的序列：假设我们有一个 Dataset​ 返回的是 (序列, 标签)​，其中序列是不同长度的 Tensor。\n\n","description":"","id":"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/","path":"/blog/pytorch-zhong-de-dataset-dataloader/","title":"Pytorch 中的 Dataset、DataLoader"},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"body":"\nOriginal Paper: Optimal Protocols for Continual Learning via Statistical Physics and Control Theory\n\n\n概述：本篇文章介绍了如何使用最优控制理论调整连续学习中的 Replay 任务、学习率使得最终的 generalization error 最低。\n\nIntroduction\nMulti-Task Learning: Training a neural network on a series of tasks.\nCatastrophic Forgetting: Multi-task learning can lead to catastrophic forgetting, where learning new tasks degrades performance on older ones.\nReplay: Present the network with examples from the old tasks while training on the new one to minimize forgetting.\n\nA Teacher-Student Framework\nTeacher-Student Framework: Here we consider a teacher-student framework\n\n\nStudent: The student network is trained on synthetic inputs $\\boldsymbol{x} \\in \\mathbb{R}^N$, drawn i.i.d. from a standard Gaussian distribution $x_i \\sim \\mathcal{N}(0, 1)$. It is a two-layer neural network with $K$ hidden units, first-layer weight $\\boldsymbol{W} = (\\boldsymbol{w}_1,\\cdots,\\boldsymbol{w}_K)^{\\top} \\in \\mathbb{R}^{K \\times N}$, activation function $g$, and second-layer weights $\\boldsymbol{v} \\in \\mathbb{R}^K$. It outputs the prediction\n$$\n\\hat{y}(\\boldsymbol{x}; \\boldsymbol{W}, \\boldsymbol{v}) = \\sum\\limits_{k = 1}^K g \\left( \\frac{\\boldsymbol{x} \\cdot \\boldsymbol{w}_k}{\\sqrt{N}} \\right).\n$$\n\n\nTeacher: The labels for each task $t = 1,2,\\cdots, T$ are generated by the teacher networks, $y^{(t)} = g_{\\ast}(\\boldsymbol{x} \\cdot \\boldsymbol{w}_{\\ast}^{(t)}/\\sqrt{N})$, where $\\boldsymbol{W}_{\\ast} = (\\boldsymbol{w}_{\\ast}^{(1)},\\cdots,\\boldsymbol{w}_{\\ast}^{(T)})^{\\top} \\in \\mathbb{R}^{T \\times N}$ denote the corresponding teacher vectors, and $g_{\\ast}$ the activation function.\n\n\nTask-Dependent Weights: We allow for task-dependent readout weights $\\boldsymbol{V} = (\\boldsymbol{v}^{(1)},\\cdots,\\boldsymbol{v}^{(T)})^{\\top} \\in \\mathbb{R}^{T \\times K}$. Specifically, when the task $t$ is presented, the readout is switched to the corresponding task, the first-layer weights are shared across tasks.\n\n\n\n  \n  Representation of the continual learning task in the teacher-student setting: (a) A student network is trained on i.i.d. inputs from two teacher networks, defining two different tasks; (b) Sequential training results in catastrophic forgetting.\n\nGeneralization Error: The generalization error of the student on task $t$ is given by\n$$\n\\varepsilon_t(\\boldsymbol{W}, \\boldsymbol{V}, \\boldsymbol{W}_*) := \\frac{1}{2} \\left\\langle \\left( y^{(t)} - \\hat{y}^{(t)} \\right)^2 \\right\\rangle = \\frac{1}{2} \\mathbb{E}_{\\boldsymbol{x}} \\left[ \\left( g_* \\left( \\frac{\\boldsymbol{w}_*^{(t)} \\cdot \\boldsymbol{x}}{\\sqrt{N}} \\right) - \\hat{y}(\\boldsymbol{x}; \\boldsymbol{W}, \\boldsymbol{v}^{(t)}) \\right)^2 \\right].\n$$\nwhere $(\\boldsymbol{x}, y^{(t)})$ is a sample, $\\hat{y}^{(t)}$ is the prediction, the angular brackets $\\langle \\cdot \\rangle$ denote the expectation over the input distribution.\nOverlaps Variables: The above generalization error depends only through the preactivations\n$$\n\\lambda_k := \\frac{\\boldsymbol{x} \\cdot \\boldsymbol{w}_k}{\\sqrt{N}}, \\quad k = 1, \\ldots, K, \\qquad \\text{and} \\qquad \\lambda_*^{(t)} := \\frac{\\boldsymbol{x} \\cdot \\boldsymbol{w}_*^{(t)}}{\\sqrt{N}}, \\quad t = 1, \\ldots, T.\n$$\nThey define jointly Gaussian variables with zero mean and second moments given by\n$$\n\\begin{aligned}\n&amp;M_{kt} := \\mathbb{E}_{\\boldsymbol{x}} \\left[ \\lambda_k \\lambda_*^{(t)} \\right] = \\frac{\\boldsymbol{w}_k \\cdot \\boldsymbol{w}_*^{(t)}}{N} , \\\\\n&amp;Q_{kh} := \\mathbb{E}_{\\boldsymbol{x}} \\left[ \\lambda_k \\lambda_h \\right] = \\frac{\\boldsymbol{w}_k \\cdot \\boldsymbol{w}_h}{N} , \\\\\n&amp;S_{tt’} := \\mathbb{E}_{\\boldsymbol{x}} \\left[ \\lambda_*^{(t)} \\lambda_*^{(t’)} \\right] = \\frac{\\boldsymbol{w}_*^{(t)} \\cdot \\boldsymbol{w}_*^{(t’)}}{N} ,\n\\end{aligned}\n$$\ncalled overlaps in the statistical physics literature. Therefore, the dynamics of the generalization error is entirely captured by the evolution of the readouts $\\boldsymbol{V}$ and the overlaps.\nForward Training Dynamics: We use the shorthand notation $\\mathbb{Q} = (\\operatorname{vec}(\\boldsymbol{Q}), \\operatorname{vec}(\\boldsymbol{M}), \\operatorname{vec}(\\boldsymbol{V})) \\in \\mathbb{R}^{K^2 + 2KT}$. The training dynamics is described by a set of ODEs\n$$\n\\frac{\\mathrm{d}\\mathbb{Q}(\\alpha)}{\\mathrm{d}\\alpha} = f_{\\mathbb{Q}}(\\mathbb{Q}(\\alpha), \\boldsymbol{u}(\\alpha)), \\quad \\alpha \\in (0, \\alpha_F].\n$$\nThe parameter $\\alpha$ denotes the effective training time, and $\\boldsymbol{u}$ is the control variable.\n\nThe Optimal Control Framework\nOptimal Control Framework: Our goal is to derive training strategies that are optimal with respect to the generalization performance at the end of the training and on all tasks. In practice, we minimize a linear combination of the generalization errors on different tasks\n$$\nh(\\mathbb{Q}(\\alpha_F)) := \\sum\\limits_{t = 1}^T c_t \\epsilon_t(\\mathbb{Q}(\\alpha_F)), \\quad \\text{with} \\quad c_t \\geq 0, \\sum\\limits_{t = 1}^T c_t = 1.\n$$\nwhere $\\alpha_F$ is the final training time, the coefficients $c_t$ identify the relative importance of different tasks and $\\epsilon_t$ denotes the infinite-dimensional limit of the average generalization error on task $t$. We define the cost functional\n$$\n\\mathcal{F}[\\mathbb{Q}, \\hat{\\mathbb{Q}}, \\bm{u}] = h\\left(\\mathbb{Q}(\\alpha_F)\\right) + \\int_0^{\\alpha_F} \\mathrm{d}\\alpha , \\hat{\\mathbb{Q}}(\\alpha)^\\top \\left[ -\\frac{\\mathrm{d}\\mathbb{Q}(\\alpha)}{\\mathrm{d}\\alpha} + f_{\\mathbb{Q}}\\left(\\mathbb{Q}(\\alpha), \\bm{u}(\\alpha)\\right) \\right],\n$$\nHere $\\hat{\\mathbb{Q}} = (\\operatorname{vec}(\\hat{\\boldsymbol{Q}}), \\operatorname{vec}(\\hat{\\boldsymbol{M}}), \\hat{\\operatorname{vec}(\\boldsymbol{V}}))$ is the conjugate order parameters (We can consider it as a Lagrange multiplier that incorperates the dynamics of $\\mathbb{Q}$).\nBackward Conjugate Dynamics:\n\n‍\n‍\n","description":"","id":"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/","path":"/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/","title":"论文阅读：连续学习的最优控制方式"},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"body":"\nOriginal Paper: [2004.12651] Recall and Learn: Fine-tuning Deep Pretrained Language Models with Less Forgetting\n\n\nIntroduction\nSequential Transfer Learning: Pretrain a language model on large-scale unlabeled data and then adapt it to downstream tasks. The adaptation step is usually conducted in two manners: fine-tuning or freezing pretrained weights (e.g., train an additional classification head).\nCatastrophic Forgetting: Such a sequential transfer learning paradigm often confronts the catastrophic forgetting problem, where a model forgets previously learned knowledge and overfits to target domains.\nMulti-task Learning: Learns multiple tasks simultaneously to avoid catastrophic forgetting.\n\nElastic Weight Consolidation (EWC): EWC evaluates the importance of each weight by Fisher information matrix, and punish the change on these important weights when adapting on subsequent tasks.\n\nChallenge in LLM Fine-Tuning: Multi-task learning methods cannot be directly applied to the sequential transferring regime of deep pretrained LMs.\n\nMulti-task learning methods require to use data of pretraining tasks during adaptation.\nWe only care about the performance of the downstream task, while multi-task learning also aims to promote performance on pretraining tasks.\n\n\nContribution of This Work\nRecall and Learn Mechanism: We propose a recall and learn mechanism, which adopts the idea of multi-task learning and jointly learns pretraining tasks and downstream tasks.\n\nPretraining Simulation: recall the knowledge from pretraining tasks without data.\nObjective Shifting: focus the learning on downstream tasks gradually.\n\nRecall Adam (RECADAM) : We provide RECADAM to integrate the recall and learn mechanism into Adam optimizer.\n\nMethodology\nPretraining Simulation: We introduce Pretraining Simulation to approximate the optimization objective of source tasks as a quadratic penalty. The learning objective on the source tasks $\\text{Loss}_S$ is approximately\n$$\n\\text{Loss}_S \\approx \\frac{1}{2}\\gamma \\sum_i (\\theta_i - \\theta_i^\\ast)^2,\n$$\nwhere $\\theta^\\ast$ is the pretrained parameter, and $\\gamma$ is a constant.\nObjective Shifting: We introduce Objective Shifting to allow the objective function to gradually shift to $\\text{Loss}_T$ with the annealing coefficient. The loss function with annealing coefficient is\n$$\n\\text{Loss} = \\lambda(t) \\text{Loss}_T + (1 - \\lambda(t)) \\text{Loss}_S.\n$$\nSpecifically, $\\lambda(t)$ is calculated as the sigmoid annealing function:\n$$\n\\lambda(t)=\\frac{1}{1+\\exp(-k\\cdot(t-t_0))}.\n$$\n\n  \n  At the beginning of the training process, the model mainly focuses on pretraining tasks. As training proceeds, the model gradually focuses on target tasks.\n​\nRecAdam Optimizer: We introduce RecAdam to integrate the quadratic penalty (Pretraining Simulation) and annealing coefficient (Objective Shifting). The difference between Adam and RecAdam lies in decoupling the quadratic penalty and annealing coefficient in Adam optimizer. In vanilla Adam, both the quadratic penalty and annealing coefficient would be adapted by the gradient update rules.\n\n  \n  The comparison between Adam and RecAdam, where SetScheduleMultiplier(t) refers to the preceduer (e.g., warm-up technique) to get the scaling factor of the step size.\n\n\nExperiments\nSet up​\n\nModel: BERT and ALBERT;\nData: General Language Understanding Evaluation (GLUE), it includes 9 tasks.\nImplementation: Our methods use random initialization (do not load the pretrained paramters) while vanilla fine-tuning initializes the fine-tuning model with pretrained parameters.\nHyper-Parameters: We set $\\gamma$ to $5000$, select the best $t_0$ and $k$ in $\\{100, 250, 500, 1000\\}$ and $\\{0.05, 0.1, 0.2, 0.5, 1\\}$ respectively for the annealing coefficient $\\lambda(t)$.\n\nResults on BERT-Base: We outperform the vanilla fine-tuning method on $7$ out of $8$ tasks, especially on the tasks with smaller training data (&lt;10k). It is interesting to find that compared to the median results with BERT-large model, we can also achieve better results on more than half of the tasks.\nResults on ALBERT-xxlarge: We outperform the vanilla fine-tuning method on 5 out of 8 tasks of the GLUE benchmark.\n\nInitialization Analysis: RECADAM, with both initialization strategies, can outperform the vanilla fine-tuning method on all the four tasks. Random initialization would be our choice because the model would benefit from a larger parameter search space.\n\n  \n  Comparison of different model initialization strategies: pre-trained initialization (PI) and Random Initialization (RI). We report median over 5 runs.\n\nForgetting Analysis: The hyper-parameter $k$ controls the rate of the objective shifting\n\nTarget Loss: With larger k, the model converges quickly on the target task.\nSource Loss: We measure the pre-trained knowledge forgetting by the Euclidean distance between $\\theta_0$ and $\\theta$. At the very early stage, the distance drops sharply because of the random initialization and pre-trained knowledge recalling. As the objective rate $k$ decreases, we find that the model can achieve less forgetting at the end of the fine-tuning.\n\n\n  \n  Learning curves with different k values: \n\n\n‍\n","description":"","id":"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/","path":"/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/","title":"论文阅读-Recall and Learn Fine Tuning with Less Forgetting"},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"body":"在文章 [2407.10490] Learning Dynamics of LLM Finetuning 中我们接触到了神经正切核的概念，其刻画了不同数据对参数、Logits 的影响。\n\n问题回顾\n分类问题：我们考虑多分类问题，将输入 $\\mathbf{x}$ 映射至 $\\mathbf{y} \\in \\mathcal{V}$，其中 $\\mathcal{V}$ 是大小为 $V$ 的字典。模型会先输出 logits $\\mathbf{z} = h_\\theta(\\mathbf{x}) \\in \\mathbb{R}^V$，然后取 Softmax：\n$$\n\\mathbf{x}\n\\xrightarrow{\\text{Hidden Layers}}\n\\underbrace{\n\\mathbf{z} = h_{\\theta}(\\mathbf{x}) =\n\\begin{bmatrix}\nz_1\\\\ z_2 \\\\ \\vdots \\\\ z_V\n\\end{bmatrix}}_{\\text{logits}}\n\\xrightarrow{\\text{Softmax}}\n\\underbrace{\n\\begin{bmatrix}\n\\pi_{\\theta}(y_1\\mid \\mathbf{x})\\\\\n\\pi_{\\theta}(y_2\\mid \\mathbf{x})\\\\\n\\vdots\\\\\n\\pi_{\\theta}(y_V\\mid \\mathbf{x})\n\\end{bmatrix}}_{\\text{confidence}}.\n$$\n学习样本的 Dynamics：考虑学习新样本 $(\\mathbf{x}_u, \\mathbf{y}_u)$，学习率为 $\\eta$，通过在 $\\mathbf{x}_u$ 上进行一次梯度下降，模型在 $\\mathbf{x}_o$ 上预测的变化值：\n$$\n\\Delta \\log \\pi^t(\\mathbf{y} \\mid \\mathbf{x}_o) := \\log \\pi_{\\theta^{t+1}}(\\mathbf{y} \\mid \\mathbf{x}_o) - \\log \\pi _{\\theta^t}(\\mathbf{y} \\mid \\mathbf{x}_o).\n$$\nLearning Dynamics：单步的 Learning Dynamics 为\n$$\n\\underbrace{\\Delta \\log \\pi^t(\\mathbf{y} \\mid \\mathbf{x}_o)}_{V \\times 1} = -\\eta \\underbrace{\\mathcal{A}^t(\\mathbf{x}_o)}_{V \\times V} \\underbrace{\\mathcal{K}^t(\\mathbf{x}_o, \\mathbf{x}_u)}_{V \\times V} \\underbrace{\\mathcal{G}^t(\\mathbf{x}_u, \\mathbf{y}_u)}_{V \\times 1} + \\mathcal{O}\\bigl(\\eta^2 \\|\\nabla_\\theta \\mathbf{z}(\\mathbf{x}_u)\\|_{\\text{op}}^2\\bigr),\n$$\n\n$\\mathcal{A}^t = \\nabla_{\\mathbf{z}} \\log \\pi_{\\theta^t}(\\mathbf{x}_o) = I - \\mathbf{1} \\pi^{\\top}_{\\theta^t}(\\mathbf{x}_o)$ 将 logits 中的变化 $\\Delta \\mathbf{z}$ 映射到输出分布 $\\log \\pi (\\mathbf{y} \\mid \\mathbf{x}_o)$，即对应着 Softmax 的矩阵表达；\n$\\mathcal{K}^t(\\mathbf{x}_o, \\mathbf{x}_u) = (\\nabla_{\\theta}\\mathbf{z}(\\mathbf{x}_o)\\mid_{\\theta^t})(\\nabla_{\\theta}\\mathbf{z}(\\mathbf{x}_u)\\mid_{\\theta^t})^{\\top}$ 衡量了 $\\mathbf{x}_o$ 和 $\\mathbf{x}_u$ 的相互影响程度；\n$\\mathcal{G}^t(\\mathbf{x}_u, \\mathbf{y}_u) = \\nabla_{\\mathbf{z}}\\mathcal{L}(\\mathbf{x}_u, \\mathbf{y}_u)\\mid_{\\mathbf{z}^t}$ 从当前分布指向期望的分布，即误差信号。\n\n​\n\n神经正切核的理解\n$\\nabla_\\theta \\mathbf{z}(\\mathbf{x})$ 的理解：$\\mathbf{z}(\\mathbf{x}) \\in \\mathbb{R}^V$ 是模型对输入 $\\mathbf{x}$ 输出的 logits 向量，$\\theta \\in \\mathbb{R}^P$ 是模型所有参数构成的向量，因此 $\\nabla_\\theta \\mathbf{z}(\\mathbf{x})$ 是 $\\mathbf{z}(\\mathbf{x})$ 关于 $\\theta$ 的 Jacobian Matrix：\n$$\n\\nabla_\\theta\\mathbf{z}(\\mathbf{x})=\n\\begin{bmatrix}\n\\frac{\\partial z_1}{\\partial\\theta_1} &amp; \\frac{\\partial z_1}{\\partial\\theta_2} &amp; \\ldots &amp; \\frac{\\partial z_1}{\\partial\\theta_P} \\\\\n\\frac{\\partial z_2}{\\partial\\theta_1} &amp; \\frac{\\partial z_2}{\\partial\\theta_2} &amp; \\ldots &amp; \\frac{\\partial z_2}{\\partial\\theta_P} \\\\\n\\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\\n\\frac{\\partial z_V}{\\partial\\theta_1} &amp; \\frac{\\partial z_V}{\\partial\\theta_2} &amp; \\ldots &amp; \\frac{\\partial z_V}{\\partial\\theta_P}\n\\end{bmatrix}.\n$$\n$\\nabla_\\theta \\mathbf{z}(\\mathbf{x})$ 的第 $i$ 行 $\\nabla_\\theta {z}_i(\\mathbf{x})$ 表示了为了使第 ​$i$​ 个 logit ​$z_i$​ 增长得最快，模型 ​$\\theta$​ 应该更新的方向。换而言之，模型 ​$\\theta$​ 对第 ​$i$​ 个 logit 的敏感度。\n矩阵乘积的含义：我们来分析 $\\mathcal{K}$ 的第 $(i,j)$ 个元素，其是 $\\nabla_\\theta z_i(\\mathbf{x}_o)$ 与 $\\nabla_\\theta z_j(\\mathbf{x}_u)$ 的内积\n$$\n\\mathcal{K}_{ij}=(\\nabla_\\theta z_i(\\mathbf{x}_o))\\cdot(\\nabla_\\theta z_j(\\mathbf{x}_u))^\\top=\\sum_{p=1}^P\\frac{\\partial z_i(\\mathbf{x}_o)}{\\partial\\theta_p}\\frac{\\partial z_j(\\mathbf{x}_u)}{\\partial\\theta_p}\n$$\n\n向量 $\\nabla_\\theta z_i(\\mathbf{x}_o)$ 是在参数空间 $\\mathbb{R}^P$ 中，能够最有效提升【输入为 $\\mathbf{x}_o$ 时第 $i$ 个类别的 logit 值】的方向；\n向量 $\\nabla_\\theta z_j(\\mathbf{x}_u)$ 是在参数空间 $\\mathbb{R}^P$ 中，能够最有效提升【输入为 $\\mathbf{x}_u$ 时第 $j$ 个类别的 logit 值】的方向。\n\n参数空间中的相似性：$\\mathcal{K}_{ij}$ 作为一个度量矩阵，其度量了两个方向在参数空间中的对齐程度或一致性\n\n若 $\\mathcal{K}_{ij}$ 为很大的正数：意味着那些能够有效提升 $z_i(\\mathbf{x}_o)$ 的参数更新，同样也有效于提升 $z_j(\\mathbf{x}_u)$；\n若 $\\mathcal{K}_{ij}$ 接近于 $0$：两个方向在参数空间正交，改变参数来影响 $z_i(\\mathbf{x}_o)$ 对 $z_j(\\mathbf{x}_u)$ 几乎没有影响，反之亦然；\n若 $\\mathcal{K}_{ij}$ 为很大的负数：两个方向是相反的，提升 $z_i(\\mathbf{x}_o)$ 的参数更新会导致 $z_j(\\mathbf{x}_u)$ 的下降。\n\n在 Learning Dynamics 中的作用：$\\mathcal{K}^t(\\mathbf{x}_o, \\mathbf{x}_u)$ 接收来自于 $\\mathbf{x}_u$ 的误差信号 $\\mathcal{G}^t$，并将其翻译为对 $\\mathbf{x}_o$ 的 logits $\\mathbf{z}(\\mathbf{x}_o)$ 的影响\n","description":"","id":"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/","path":"/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/","title":"神经正切核 Neural Tangent Kernel, NTK"},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"body":"TylerYep/torchinfo 库提供了便捷、美观的网络架构输出方案\n\n安装 torchinfo\n\n\n快速上手\n为了方便检查每一层的 output shape​，torchinfo​ 要求输入 input size​，一般情况下不在乎 batch_size​ 的话可以设置为 1​。\n\n输出如下\n\n","description":"","id":"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/","path":"/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/","title":"torchinfo 库可视化网络架构"},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"body":"LPC（Linearized Controllability Property，线性化可控性）  是一个用来判断我们能否在局部有效控制一个复杂非线性系统的工具。\n它问的是这样一个问题：如果系统沿着一条预定轨迹（路径）运动时，受到一点点微小的干扰偏离了轨迹，我们有没有能力通过微调控制输入，让它回到我们想要的任何一个附近的微小位置上？如果答案是“有”，那么系统就具备LPC。\n\n数学语言描述\n系统与轨迹：考虑一个非线性系统\n$$\n\\dot{x}(t)=f(x(t),u(t)) \\tag{1}\n$$\n其中 $t \\in [0, T]$，$x(t) \\in \\mathbb{R}^n$，$u(t) \\in \\mathbb{R}^m$，以及 $f \\in C^1(\\mathbb{R}^m, \\mathbb{R}^n)$。给定初始状态 $x_0$ 和控制输入函数 $u: [0, T] \\to \\mathbb{R}^m$，记真实轨迹 $x^\\ast(t) = \\varphi_t(u, x_0)$ 满足：\n$$\n\\dot{x}^*(t)=f(x^*(t),u(t)),\\quad x^*(0)=x_0.\n$$\n沿轨迹的线性化：考虑状态 $x$ 和控制 $u$ 的微小扰动\n$$\nx(t)=x^*(t)+\\delta x(t),\n\\quad u_{new}(t)=u(t)+\\delta u(t)\n$$\n代入原系统方程 (1) 并对 $f$ 泰勒展开，我们可以得到 $\\delta x(t)$ 的变分方程\n$$\n\\dot{\\delta}x(t)=A(t)\\delta x(t)+B(t)\\delta u(t).\n$$\n$$\nA(t):=\\left.\\frac{\\partial f}{\\partial x}\\right|_{(x=x^*(t),u=u(t))}, \\quad B(t):=\\frac{\\partial f}{\\partial u}\\bigg|_{(x=x^*(t),u=u(t))}\n$$\n此为一个线性时变（Linear Time-Varying, LTV）系统。\n线性化可控性 LPC：给定非线性系统 $\\dot{x}(t)=f(x(t),u(t))$，初始状态 $x_0$，控制输入 $u(t)$，以及真实轨迹 $x^\\ast(t)$。该系统在 $t \\in [0, T]$ 上是线性化可控的若对应的线性时变系统\n$$\n\\dot{z}(t)=A(t)z(t)+B(t)v(t) \\tag{2}\n$$\n$$\nA(t):=\\left.\\frac{\\partial f}{\\partial x}\\right|_{(x=x^*(t),u=u(t))}, \\quad B(t):=\\frac{\\partial f}{\\partial u}\\bigg|_{(x=x^*(t),u=u(t))}\n$$\n在 $[0, T]$ 上是可控的。\n\n(2) 的可控性保证了 $\\delta x$ 是可控的，也就是说可以施加微小控制 $\\delta u(t) = v(t)$，将偏差 $\\delta x(t) = z(t)$ 拉到期望值。\n\n等价条件：LTV 系统 (2) 是可控的等价于其在 $[0, T]$ 上的可控性格拉姆矩阵（Controllability Gramian）$W_C(0, T)$ 是非奇异的：\n$$\nW_C(0,T)=\\int_0^T\\Phi(T,\\tau)B(\\tau)B^T(\\tau)\\Phi^T(T,\\tau)d\\tau\n$$\n其中 $\\Phi(t, \\tau)$ 满足\n$$\n\\dot{\\Phi}(t,\\tau)=A(t)\\Phi(t,\\tau), \\quad \\Phi(\\tau,\\tau)=I.\n$$\n‍\n","description":"","id":"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/","path":"/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/","title":"线性可控性 Linearized Controllability Property LPC"},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"body":"‍\n\n问题陈述\n线性时不变系统 LTI：我们将系统视作数学算子 $H$，其接收一个输入信号 $x(t)$，产生一个输出信号 $y(t)$，即\n$$\ny(t) = H[x(t)].\n$$\n若其满足以下两个条件，则其是线性时不变（LTI）系统：\n\n线性性：给定任意两个信号 $x_1(t)$ 和 $x_2(t)$，和常数 $a_1$ 和 $a_2$，满足\n\n$$\nH[a_1x_1(t)+a_2x_2(t)]=a_1H[x_1(t)]+a_2H[x_2(t)]\n$$\n\n时不变性(Time-Invariance)：给定信号 $x(t)$ 和任意时间延迟 $\\tau$，满足\n\n$$\ny(t-\\tau)=H[x(t-\\tau)]\n$$\n系统模型：我们考虑一个 LTI 系统，其动态由以下状态空间方程描述：\n$$\n\\dot{\\mathbf{x}}(t)=A\\mathbf{x}(t)+B\\mathbf{u}(t),\n$$\n其中 $\\mathbf{x}(t) \\in \\mathbb{R}^n$ 是状态向量，$\\mathbf{u}(t) \\in \\mathbb{R}^m$ 是输入/控制向量，$A \\in \\mathbb{R}^{n \\times n}$ 是系统矩阵，$B \\in \\mathbb{R}^{n \\times m}$ 是输入矩阵。\n\n在能控性理论中我们不需要考虑输出 $y(t)$，因此此处不写出 $y(t)$ 的方程。\n\n系统模型的解：该系统方程的解为\n$$\n\\mathbf{x}(t)=e^{At}\\mathbf{x}(0)+\\int_0^te^{A(t-\\tau)}B\\mathbf{u}(\\tau)d\\tau.\n$$\n其中 $\\mathbf{x}(0)$ 是初始状态，$e^{At}$ 是矩阵指数，定义为 $e^{At}=\\sum_{k=0}^\\infty\\frac{(At)^k}{k!}$。\n能控性问题：能控性的问题是能否通过选择一个合适的控制输入 $\\mathbf{u}(t)$，在有限的时间 $t_f &gt; 0$ 内，将系统从任意初始状态 $\\mathbf{x}(0)$ 驱动到任意期望的最终状态 $\\mathbf{x}(t_f)$。\n\n能控性的数学定义\n状态能控性：上述系统对矩阵 $(A, B)$ 是状态完全可控的（completely state controllable） ，如果对任意初始状态 $\\mathbf{x}(0) \\in \\mathbb{R}^n$ 和任意最终状态 $\\mathbf{x}_f \\in \\mathbb{R}^n$，存在有限时间 $t_f &gt; 0$ 和分段连续 $\\mathbf{u}(t)$，使得\n$$\n\\mathbf{x}(t_f) = \\mathbf{x}_{f}.\n$$\n等价问题：代入系统模型的解，可知状态可控性等价于：对于任意 $\\mathbf{x}(0)$ 和 $\\mathbf{x}_f$，以下方程关于 $\\mathbf{u}(\\tau)$ 是否有解？\n$$\n\\mathbf{x}_f-e^{At_f}\\mathbf{x}(0)=\\int_0^{t_f}e^{A(t_f-\\tau)}B\\mathbf{u}(\\tau)d\\tau.\n$$\n可达集 Reachable Set：令左侧项 $\\tilde{\\mathbf{x}}=\\mathbf{x}_{f}-e^{At_{f}}\\mathbf{x}(0)$，则问题转化为 $\\tilde{\\mathbf{x}}$ 是否总能被积分项表示。也就是是否在可达集中：\n$$\n\\mathcal{R}_t = \\left\\{ \\mathbf{x} \\in \\mathbb{R}^n | \\mathbf{x} = \\int_0^t e^{A(t-\\tau)}B\\mathbf{u}(\\tau) \\mathrm{d} \\tau, \\quad \\mathbf{u}(t) \\in \\mathcal{U} \\right\\},\n$$\n其中 $\\mathcal{U}$ 表示分段连续函数 $u: [0,t] \\to \\mathbb{R}^m$ 组成的集合。\n\n能控性判据\n我们有两个主要的等价判据来判断系统的能控性：能控性格拉姆矩阵 (Controllability Grammian)、卡尔曼能控性判据 (Kalman’s Rank Condition)\n能控性格拉姆矩阵 (Controllability Grammian) ：上述系统是完全可控的，当且仅当对于任意 $t &gt; 0$，下面的能控性格拉姆矩阵 $W_c(t)$ 是非奇异的：\n$$\nW_c(t)=\\int_0^te^{A\\tau}BB^\\top e^{A^\\top \\tau}d\\tau,\n$$\n即 $\\operatorname{det}(W_c(t)) \\neq 0$。\n卡尔曼能控性判据（Kalman’s Rank Condition） ：上述系统是完全可控的，若下面的能控性矩阵 $\\mathcal{C} \\in \\mathbb{R}^{n \\times nm}$ 是满秩的：\n$$\n\\mathcal{C}=\n\\begin{bmatrix}\nB &amp; AB &amp; A^2B &amp; \\cdots &amp; A^{n-1}B\n\\end{bmatrix}\n$$\n即 $\\operatorname{rank}(\\mathcal{C}) = n$。\n‍\n","description":"","id":"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/","path":"/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/","title":"线性时不变系统的能控性 Controllable"},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"body":"‍\n\n约束优化问题与拉格朗日函数\n约束优化问题：我们考虑如下的约束优化问题，$x$ 是我们的优化变量（Primal Variable），$f(x)$ 是目标函数（Objective function），$g_i$ 和 $h_j$ 是约束条件（Constraints）\n$$\n\\begin{aligned}\n\\min_{x\\in\\mathbb{R}^{n}} \\quad &amp;f(x) \\\\\n\\mathrm{s.t.} \\quad &amp;g_i(x)\\leq0,\\quad i=1,\\ldots,m \\\\\n&amp; h_j(x)=0,\\quad j=1,\\ldots,p\n\\end{aligned}\n$$\n我们将上述问题称为原始问题（Primal Problem）。\n拉格朗日函数：我们引入拉格朗日乘子（Lagrange Multiplier）$\\lambda_i \\geq 0$ 和 $\\nu_j$，也称为对偶变量（Dual Variables），并定义拉格朗日函数\n$$\n\\mathcal{L}(x,\\lambda,\\nu)=f(x)+\\sum_{i=1}^m\\lambda_ig_i(x)+\\sum_{j=1}^p\\nu_jh_j(x)\n$$\n其中 $\\lambda=[\\lambda_1,\\ldots,\\lambda_m]^T$ 且 $\\lambda_i\\geq0$，$\\nu_j \\in \\mathbb{R}$ 。\n拉格朗日函数的性质分析：若我们固定 $x$，尝试最大化 $\\mathcal{L}(x, \\lambda, \\nu)$\n$$\n\\max_{\\lambda\\geq0,\\nu}\\mathcal{L}(x,\\lambda,\\nu)\n$$\n\n如果 $x$ 违反了约束：比如 $g_k(x) &gt; 0$，那么我们可以让 $\\lambda_k \\to \\infty$，从而 $\\mathcal{L} \\to \\infty$。比如 $h_j(x) \\neq 0$，我们可以让 $\\nu_j \\to \\pm \\infty$，这也导致 $\\mathcal{L} \\to \\infty$。\n如果 $x$ 满足所有条件：$g_i(x) \\leq 0$ 且 $h_j(x) = 0$，为了最大化 $\\mathcal{L}$，我们会让所有 $\\lambda_i = 0$，即 $\\max_{\\lambda\\geq0,\\nu}\\sum\\lambda_ig_i(x)+\\sum\\nu_jh_j(x)=0$。\n\n$$\n\\max_{\\lambda\\geq0,\\nu}\\mathcal{L}(x,\\lambda,\\nu)=\n\\begin{cases}\nf(x) &amp; \\mathrm{if~}x\\text{ is feasible }(\\text{满足所有约束}) \\\\\n\\infty &amp; \\mathrm{if~}x\\text{ is infeasible }(\\text{违反任何约束}) &amp;\n\\end{cases}\n$$\n原优化问题的拉格朗日函数表达（对偶问题） ：我们最初的约束优化问题 $\\min f(x)$ 等价于下面的无约束问题：\n$$\n\\min_x\\left(\\max_{\\lambda\\geq0,\\nu}\\mathcal{L}(x,\\lambda,\\nu)\\right)\n$$\n或者我们可以将最大、最小的顺序对调一下，获得对偶问题（Dual Problem）：\n$$\n\\max_{\\lambda\\geq0,\\nu}\\left(\\min_x\\mathcal{L}(x,\\lambda,\\nu)\\right).\n$$\n\n大多数情况下，原始问题和对偶问题的解是相同的。最优解 $(x^*,\\lambda^*,\\nu^*)$ 位于拉格朗日函数的一个鞍点（Saddle Point）上。\n\n\nPrimal-Dual 算法\nPrimal-Dual 算法核心思想：我们不去直接解 minimax 或 maximin 问题，而是通过迭代的方式同时寻找原始变量 $x$ 和对偶变量 $(\\lambda, \\nu)$，直到它们收敛到鞍点。\nPrimal-Dual 算法：Primal-Dual 算法分为 Primal 和 Dual 两步，以梯度下降和梯度上升为例\n\nPrimal Variable：梯度下降\n\n$$\nx^{(k+1)}\\leftarrow x^{(k)}-\\eta_x\\nabla_x\\mathcal{L}(x^{(k)},\\lambda^{(k)},\\nu^{(k)}).\n$$\n\nDual Variable：梯度上升。同时由于 $\\lambda \\geq 0$，因此需要将其投影到非负数\n\n$$\n\\lambda^{(k+1)} \\leftarrow \\max \\left(0,  \\lambda^{(k)} + \\eta_\\lambda \\nabla_\\lambda \\mathcal{L}(x^{(k)}, \\lambda^{(k)}, \\nu^{(k)}) \\right)\n$$\n$$\n\\nu^{(k+1)} \\leftarrow \\nu^{(k)} + \\eta_\\nu \\nabla_\\nu \\mathcal{L}(x^{(k)}, \\lambda^{(k)}, \\nu^{(k)})\n$$\n‍\n","description":"","id":"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/","path":"/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/","title":"约束问题的 Primal-Dual 算法"},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"body":"近期在学习一些最优控制 Optimal Control 相关的理论，想先学习一下大致的问题，因此整理此笔记。\n\n问题描述 Problem Formulation\n状态方程 State Equation：Optimal Control 中考虑描述系统动态的常微分方程\n$$\n\\dot{x}(t) = f(t, x(t), u(t)),\n$$\n其中 $t \\in [t_0, t_f]$ 是时间，$x(t) \\in \\mathbb{R}^n$ 是状态向量 state vector，$u(t) \\in \\mathcal{U} \\subset \\mathbb{R}^m$ 是控制向量，$\\mathcal{U}$ 是 set of admissible controls。\n\n我们希望通过调整 $u$ 的控制信号来控制 $x(t)$ 的行为。\n\n边界条件 Boundary Conditions：往往我们考虑的问题会有一些限制条件，例如\n\nInitial Condition：初始状态往往是固定的 $x(t_0) = x_0$；\nTerminal Condition：一般是一种约束条件 $\\Psi(t_f, x(t_f)) = \\mathbf{0}$，其中 $\\Psi$ 是一个向量函数\n\nCost Functional：通过控制动力系统，我们希望最小化目标函数 $J$，其一般由两个部分组成：\n$$\nJ[u(\\cdot)] = \\phi(t_f, x(t_f)) + \\int_{t_0}^{t_f} L(t, x(t), u(t))\\mathrm{d}t.\n$$\n\n$\\phi(t_f, x(t_f))$ 是 terminal cost，与系统在终点的状态有关；\n$L(t, x(t), u(t))$ 是 running cost，表示整个过程中的积累成本。\n\n我们的目标 Objective：找到一个控制函数 $u^\\ast(\\cdot): [t_0, t_f] \\to \\mathcal{U}$，是的对应的状态轨迹 trajectory 能够最小化指标 $J$。\n\nPontryagin’s Minimum Principle - PMP\nPMP 提供了一组最优控制所必须满足的必要条件，其是经典变分法 Calculus of Variations 的推广。但我们这里暂时不管什么是经典变分法，先把 PMP 的定理叙述搞明白。\n哈密顿量 The Hamiltonian：我们引入一个辅助函数，称为哈密顿量 Hamiltonian：\n$$\nH(t,x,u,\\lambda) = L(t, x, u) + \\lambda(t)^\\top f(t, x, u),\n$$\n其中 $\\lambda(t) \\in \\mathbb{R}^n$ 是一个向量函数，称为 co-state vector 或 adjoint vector。哈密顿量将用于描述 PMP 定理。\nPMP 定理：设 $u^\\ast(\\cdot)$ 是最优控制，$x^\\ast(\\cdot)$ 是对应的最优轨迹，那么必然存在一个非零的 co-state vector $\\lambda^\\ast(\\cdot)$，对于所有 $t \\in [t_0, t_f]$ 满足\n\n状态方程 State Equation：系统原始动态的重新表述\n\n$$\n\\dot{x}^\\ast(t) = \\frac{\\partial H}{\\partial \\lambda}(t, x^\\ast, u^\\ast, \\lambda^\\ast) = f(t, x^\\ast, u^\\ast).\n$$\n\n协态方程 Co-state Equation/Adjoint Equation：$\\lambda^\\ast(t)$ 需要满足的方程\n\n$$\n\\dot{\\lambda}^\\ast(t) = - \\frac{\\partial H}{\\partial x}(t, x^\\ast, u^\\ast, \\lambda^\\ast).\n$$\n\n哈密顿量最小化条件 Minimization of the Hamiltonian：对于所有容许的控制 $v \\in \\mathcal{U}$，最优控制 $u^\\ast(t)$ 必须使哈密顿量在任意时刻 $t$ 取最小值\n\n$$\nH(t, x^\\ast(t), u^\\ast(t), \\lambda^\\ast(t)) \\leq H(t, x^\\ast(t), v, \\lambda^\\ast(t)).\n$$\n\n如果控制 $u$ 没有约束（即 $\\mathcal{U} = \\mathbb{R}^m$）且 $H$ 对 $u$ 可微，则该条件可以简化为\n$$\n\\frac{\\partial H}{\\partial u} (t, x^\\ast, u^\\ast, \\lambda^\\ast) = 0\n$$\n\n\n横截条件 Transversality Condition：如果 $x(t_f)$ 固定，则 $\\lambda(t_f)$ 没有约束；如果 $x(t_f)$ 自由，则\n\n$$\n\\lambda^\\ast(t_f) = \\frac{\\partial \\phi}{\\partial x} (t_f, x^\\ast(t_f)).\n$$\n总结：PMP 将复杂的泛函最小化问题转化为两点边值问题 Two-Point Boundary Value Problem\n\n动态规划与 Hamilton-Jacobi-Bellman (HJB) 方程\n动态规划是解决最优控制问题的另一种方法，其提供了最优性的充分条件，并且能得到闭环 closed-loop 或者反馈 feedback 控制策略。\n最优值函数 Optimal Value Function：定义 Optimal Value Function $V(t, x)$ 为从时间 $t$、状态 $x$ 出发，能得到的最小成本\n$$\nV(t, x) = \\min_{u(\\cdot) \\in \\mathcal{U}} \\left[\\phi(t_f, x(t_f)) + \\int_t^{t_f} L(\\tau, x(\\tau), u(\\tau) \\mathrm{d} \\tau\\right],\n$$\n其中轨迹 $x(\\tau)$ 满足 $\\dot{x} = f(\\tau, x, u)$ 和 $x(t) = x$。根据其定义，我们有 terminal condition\n$$\nV(t_f, x) = \\phi(t_f, x).\n$$\nBellman’s Principle of Optimality：无论过去的状态和决策如何，余下的决策对于由过去决策所形成的状态而言，也必须构成一个最优策略。\nHJB 方程：根据 Bellman’s Priciple of Optimality，考虑一个极小的时间段 $[t, t+\\delta t]$，\n$$\nV(t, x) = \\min_{u(t)} [L(t,x,u) \\delta t + V(t + \\delta t, x(t + \\delta t)) + o(\\delta t)]\n$$\n对 $V(t + \\delta t, x(t+\\delta t))$ 进行泰勒展开\n$$\nV(t + \\delta t, x+ \\delta x) \\approx V(t,x) + \\frac{\\partial V}{\\partial t} \\delta t + \\left( \\frac{\\partial V}{\\partial x}\\right) \\dot{x} \\delta t.\n$$\n将展开式代入，并用 $\\dot{x} = f(t, x, u)$ 替换，整理后两侧同时除以 $\\delta t$，并令 $\\delta t \\to 0$，得到 HJB 方程\n$$- \\frac{\\partial V}{\\partial t} (t, x) = \\min_{u \\in \\mathcal{U}} \\left[ L(t, x, u) + \\left( \\frac{\\partial V}{\\partial x}(t, x) \\right)^{\\top} f(t,x,u) \\right].\n$$\n与哈密顿量的关系：如果我们将 $\\frac{\\partial V}{\\partial x}$ 视作一个整体，则 HJB 方程可以更紧凑地写为：\n$$- \\frac{\\partial V}{\\partial t} = \\min_{u \\in \\mathcal{U}} H \\left(t, x, u, \\frac{\\partial V}{\\partial x}\\right),\n$$\n变为一个 PDE，边界条件为 $V(t_f, x)  = \\phi(t_f, x)$。\n求解与应用：如果能求解上面的 PDE 得到 $V(t,x)$，则最优控制可以通过最小化哈密顿量在每个时刻 $(t,x)$ 得到\n$$\nu^\\ast(t, x) = \\arg\\min_{u \\in \\mathcal{U}} H \\left( t, x, u, \\frac{\\partial V}{\\partial x}(t,x) \\right).\n$$\n但是在高位 state space 中，HJB 方程的求解非常困难，这也被称为维数灾难 curse of dimensionality。\n","description":"","id":"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/","path":"/blog/zui-you-kong-zhi-optimal-control-gai-lan/","title":"最优控制 Optimal Control 概览"},"https://reichtumqian.pages.dev/projects/":{"body":"","description":"","id":"https://reichtumqian.pages.dev/projects/","path":"/projects/","title":"Projects"}},"docInfo":{"https://reichtumqian.pages.dev/":{"body":4,"description":0,"path":0,"title":2},"https://reichtumqian.pages.dev/archive/":{"body":0,"description":0,"path":1,"title":1},"https://reichtumqian.pages.dev/blog/":{"body":0,"description":0,"path":1,"title":1},"https://reichtumqian.pages.dev/blog/anaconda-quan-jia-tong/":{"body":394,"description":0,"path":5,"title":4},"https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/":{"body":967,"description":0,"path":8,"title":7},"https://reichtumqian.pages.dev/blog/blog-adam/":{"body":0,"description":0,"path":3,"title":4},"https://reichtumqian.pages.dev/blog/blog-adamw/":{"body":422,"description":0,"path":3,"title":6},"https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/":{"body":816,"description":0,"path":13,"title":9},"https://reichtumqian.pages.dev/blog/blog-lasalle-s-invariance-principle/":{"body":614,"description":0,"path":6,"title":4},"https://reichtumqian.pages.dev/blog/blog-lora-low-rank-adaptation/":{"body":354,"description":0,"path":6,"title":4},"https://reichtumqian.pages.dev/blog/blog-mae-ce-shi-huan-jing-da-jian/":{"body":318,"description":0,"path":9,"title":5},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations-tong-yong-ge-shi/":{"body":474,"description":0,"path":10,"title":6},"https://reichtumqian.pages.dev/blog/blog-method-of-successive-approximations/":{"body":788,"description":0,"path":6,"title":6},"https://reichtumqian.pages.dev/blog/blog-pytorch-parameters-jie-gou-yu-muon-de-diao-yong/":{"body":720,"description":0,"path":11,"title":6},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-clm-yu-xun-lian-yu-wei-diao-dai-ma-yue-du/":{"body":611,"description":0,"path":15,"title":9},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-trainer-shi-yong-yu-zi-ding-yi-you-hua-qi/":{"body":418,"description":0,"path":14,"title":10},"https://reichtumqian.pages.dev/blog/blog-transformers-ku-tu-xiang-fen-lei-wei-diao-dai-ma-yue-du/":{"body":282,"description":0,"path":14,"title":7},"https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/":{"body":444,"description":0,"path":13,"title":7},"https://reichtumqian.pages.dev/blog/dong-li-xi-tong-wen-ding-xing-gai-lan/":{"body":784,"description":0,"path":10,"title":8},"https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/":{"body":824,"description":0,"path":15,"title":10},"https://reichtumqian.pages.dev/blog/heavy-ball-yu-momentum-suan-fa-deng-jia-xing/":{"body":145,"description":0,"path":10,"title":7},"https://reichtumqian.pages.dev/blog/hugging-face-trl-wei-diao-ku-dai-ma-yue-du/":{"body":58,"description":0,"path":11,"title":8},"https://reichtumqian.pages.dev/blog/la-ge-lang-ri-cheng-zi-fa/":{"body":616,"description":0,"path":8,"title":6},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-benchmarking-optimizers-for-large-language-model-pretraining-md/":{"body":1116,"description":0,"path":13,"title":9},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-control-theoretic-approach-to-fine-tuning-and-transfer-learning/":{"body":2279,"description":0,"path":14,"title":11},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-parameter-efficient-fine-tuning-with-controls/":{"body":551,"description":0,"path":11,"title":8},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-rl-s-razor-why-online-reinforcement-learning-forgets-less/":{"body":1589,"description":0,"path":14,"title":11},"https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/":{"body":1517,"description":0,"path":12,"title":9},"https://reichtumqian.pages.dev/blog/mutagen/":{"body":211,"description":0,"path":2,"title":10},"https://reichtumqian.pages.dev/blog/peft-huo-qu-yuan-mo-xing-get-base-model-de-bug/":{"body":101,"description":0,"path":12,"title":8},"https://reichtumqian.pages.dev/blog/pytest-vscode-kuai-su-shang-shou/":{"body":178,"description":0,"path":7,"title":5},"https://reichtumqian.pages.dev/blog/pytest-zhong-de-fixture/":{"body":352,"description":0,"path":5,"title":3},"https://reichtumqian.pages.dev/blog/pytorch-lightning-peft-shi-xian-lora-wei-diao-shi-li/":{"body":202,"description":0,"path":11,"title":7},"https://reichtumqian.pages.dev/blog/pytorch-qiu-dao-cao-zuo-zong-jie/":{"body":421,"description":0,"path":8,"title":4},"https://reichtumqian.pages.dev/blog/pytorch-tensor-shu-xue-cao-zuo-zong-jie/":{"body":311,"description":0,"path":9,"title":5},"https://reichtumqian.pages.dev/blog/pytorch-tensor-xing-zhuang-cao-zuo-zong-jie/":{"body":78,"description":0,"path":9,"title":5},"https://reichtumqian.pages.dev/blog/pytorch-wang-luo-jie-gou-ji-chu/":{"body":380,"description":0,"path":8,"title":5},"https://reichtumqian.pages.dev/blog/pytorch-zhong-de-dataset-dataloader/":{"body":558,"description":0,"path":6,"title":4},"https://reichtumqian.pages.dev/blog/reading-lian-xu-xue-xi-de-zui-you-kong-zhi-fang-shi/":{"body":873,"description":0,"path":13,"title":8},"https://reichtumqian.pages.dev/blog/reading-recall-and-learn-fine-tuning-with-less-forgetting/":{"body":741,"description":0,"path":10,"title":10},"https://reichtumqian.pages.dev/blog/shen-jing-zheng-qie-he-neural-tangent-kernel-ntk/":{"body":854,"description":0,"path":10,"title":7},"https://reichtumqian.pages.dev/blog/torchinfo-ku-ke-shi-hua-wang-luo-jia-gou/":{"body":41,"description":0,"path":10,"title":6},"https://reichtumqian.pages.dev/blog/xian-xing-ke-kong-xing-linearized-controllability-property-lpc/":{"body":445,"description":0,"path":10,"title":7},"https://reichtumqian.pages.dev/blog/xian-xing-shi-bu-bian-xi-tong-de-neng-kong-xing-controllable/":{"body":632,"description":0,"path":13,"title":8},"https://reichtumqian.pages.dev/blog/yue-shu-wen-ti-de-primal-dual-suan-fa/":{"body":526,"description":0,"path":10,"title":5},"https://reichtumqian.pages.dev/blog/zui-you-kong-zhi-optimal-control-gai-lan/":{"body":1017,"description":0,"path":9,"title":6},"https://reichtumqian.pages.dev/projects/":{"body":0,"description":0,"path":1,"title":1}},"length":47},"lang":"Chinese"}