<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet href="https://reichtumqian.pages.dev/feed_style.xsl" type="text/xsl"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="zh">
    <tabi:metadata xmlns:tabi="https://github.com/welpo/tabi">
        <tabi:base_url>https:&#x2F;&#x2F;reichtumqian.pages.dev</tabi:base_url>
        <tabi:separator>
            •
        </tabi:separator>
        <tabi:about_feeds>This is a web feed, also known as an Atom feed. Subscribe by copying the URL from the address bar into your newsreader</tabi:about_feeds>
        <tabi:visit_the_site>Visit website</tabi:visit_the_site>
        <tabi:recent_posts>Recent posts</tabi:recent_posts>
        <tabi:last_updated_on>Updated on $DATE</tabi:last_updated_on>
        <tabi:default_theme></tabi:default_theme>
        <tabi:post_listing_date>date</tabi:post_listing_date>
        <tabi:current_section>LLM</tabi:current_section>
    </tabi:metadata><title>Reichtum's Blog - LLM</title>
        <subtitle>Reichtum&#x27;s Blog</subtitle>
    <link href="https://reichtumqian.pages.dev/tags/llm/atom.xml" rel="self" type="application/atom+xml"/>
    <link href="https://reichtumqian.pages.dev/tags/llm/" rel="alternate" type="text/html"/>
    <generator uri="https://www.getzola.org/">Zola</generator><updated>2025-09-06T00:00:00+00:00</updated><id>https://reichtumqian.pages.dev/tags/llm/atom.xml</id><entry xml:lang="zh">
        <title>论文阅读：The Super Weight in Large Language Models</title>
        <published>2025-09-06T00:00:00+00:00</published>
        <updated>2025-09-06T00:00:00+00:00</updated>
        <author>
            <name>Reichtum</name>
        </author>
        <link rel="alternate" href="https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/" type="text/html"/>
        <id>https://reichtumqian.pages.dev/blog/lun-wen-yue-du-the-super-weight-in-large-language-models/</id>
        
            <content type="html">&lt;blockquote&gt;
&lt;p&gt;Original Paper: &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2411.07191&quot;&gt;[2411.07191] The Super Weight in Large Language Models&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;strong&gt;Large Outliers in Large Models&lt;&#x2F;strong&gt;: Once LLMs reach a certain scale, a small set of hidden state features contains outliers of exceptionally large magnitude. These outliers account for a small percentage of all activations but are crucial for preserving the compressed model’s quality.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Super Weights&lt;&#x2F;strong&gt;: Not all large outliers are equally important. In this paper, we study a tiny yet important set of outliers in LLMs, termed &lt;em&gt;super weights&lt;&#x2F;em&gt;. In Llama-7B, pruning the super weight, a single scalar, completely destroys the model’s ability to generate text.&lt;&#x2F;p&gt;
&lt;figure&gt;
  &lt;img src=&quot;assets&#x2F;image-20250906104045-xl09xfx.png&quot; alt=&quot;image&quot;&gt;
  &lt;figcaption&gt;Super Weight Phenomenon: Pruning a single super weight can completely destroy a LLM&amp;#x27;s ability to generate text. On the left, the original Llama-7B produces a reasonable completion. On the right, after pruning the super weight, Llama-7B generates complete gibberish.&lt;&#x2F;figcaption&gt;
&lt;&#x2F;figure&gt;​
&lt;p&gt;&lt;strong&gt;Super Activations&lt;&#x2F;strong&gt;: &lt;em&gt;Super activations&lt;&#x2F;em&gt; are exceptionally massive activations. They persist across many layers, feature constant magnitude, and always exist at the same position regardless of input.&lt;&#x2F;p&gt;
&lt;figure&gt;
  &lt;img src=&quot;assets&#x2F;image-20250906111713-x3jh79f.png&quot; alt=&quot;image&quot;&gt;
  &lt;figcaption&gt;Super activations: Exceptionally massive activations&lt;&#x2F;figcaption&gt;
&lt;&#x2F;figure&gt;​
&lt;p&gt;&lt;strong&gt;Super Weights behave similarly across model families and sizes&lt;&#x2F;strong&gt;:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;They are always found in the &lt;code&gt;mlp.down_proj&lt;&#x2F;code&gt;​ weight.&lt;&#x2F;li&gt;
&lt;li&gt;They produce exceptionally large magnitude activation–the &lt;em&gt;super activation&lt;&#x2F;em&gt;.&lt;&#x2F;li&gt;
&lt;li&gt;They suppress stopword likelihood.&lt;&#x2F;li&gt;
&lt;li&gt;Pruning the super weight destroys quality by &lt;u&gt;dampening the super activation&lt;&#x2F;u&gt;（super activation 几乎消失了） and &lt;u&gt;shifting almost all logit probability mass to stopwords&lt;&#x2F;u&gt;（几乎只输出 stopwords）.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;figure&gt;
  &lt;img src=&quot;assets&#x2F;image-20250906111816-u8ibtvm.png&quot; alt=&quot;image&quot;&gt;
  &lt;figcaption&gt;How Super Weights behave: (1) Super weights are often found in an early layer&amp;#x27;s down projection (2) Super activations are propagated through skip connections. (3) This has a effect of suppressing stopword likelihoods in the final logits.&lt;&#x2F;figcaption&gt;
&lt;&#x2F;figure&gt;​
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;mlp.down_proj&lt;&#x2F;code&gt;​：在 Transformer 架构中，Feed Forward 层（也就是 MLP 层）一般是两层神经网络，表示为 $\operatorname{FFN}(x) = W_2(\operatorname{ReLU}(W_1x + b_1)) + b_2)$，即先经过一个 &lt;code&gt;up_proj&lt;&#x2F;code&gt;​ 进行升维，一个 &lt;code&gt;activation&lt;&#x2F;code&gt;​ 进行非线性变换，再经过一个 &lt;code&gt;down_proj&lt;&#x2F;code&gt;​ 进行降维。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;reichtumqian.pages.dev&#x2F;blog&#x2F;lun-wen-yue-du-the-super-weight-in-large-language-models&#x2F;assets&#x2F;image-20250906103003-ltmazal.png&quot; alt=&quot;image&quot; &#x2F;&gt;​&lt;&#x2F;p&gt;
&lt;p&gt;Stopword 指的是那些非常常见，但是信息量很低的词，例如 &lt;code&gt;the&lt;&#x2F;code&gt;​、&lt;code&gt;a&lt;&#x2F;code&gt;​、&lt;code&gt;is&lt;&#x2F;code&gt;​、&lt;code&gt;of&lt;&#x2F;code&gt;​ 等。&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Super Outliers&lt;&#x2F;strong&gt;: We refer to both super weights and super activations as &lt;em&gt;super outliers&lt;&#x2F;em&gt;, which are critical to model quality. Fortunately, there are no more than a handful of scalar super outliers per tensor.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;contribution-of-this-work&quot;&gt;Contribution of This Work&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;strong&gt;Super Weights&lt;&#x2F;strong&gt;: We discover a tiny subset of outliers in LLMs, at most six scalars, that are disproportionately important; pruning these super weights destroys model quality.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Identifying Super Weights&lt;&#x2F;strong&gt;: We present a data-free way to identify super weights using only a single forward pass and provide an index of super weights for existing, open LLMs.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Super Activations&lt;&#x2F;strong&gt;: We analyze how super weights influence inference and relate them to the activation outliers observed in prior work.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Compression&lt;&#x2F;strong&gt;: By preserving super outliers, we show that round-to-nearest quantization increases effectiveness noticeably; preserving super outliers improves compression quality.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;identification-of-super-weights&quot;&gt;Identification of Super Weights&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;strong&gt;Super Weights Create Super Activations&lt;&#x2F;strong&gt;: The super activations’ channel (the position in vector) aligns with the super weights’, and the activation first appears right after the super weights.&lt;&#x2F;p&gt;
&lt;figure&gt;
  &lt;img src=&quot;assets&#x2F;image-20250906105604-xtl5z4e.png&quot; alt=&quot;image&quot;&gt;
  &lt;figcaption&gt;Pruning the super weight decreases the super activation&amp;#x27;s magnitude by 75%.&lt;&#x2F;figcaption&gt;
&lt;&#x2F;figure&gt;​
&lt;p&gt;&lt;strong&gt;The Mechanism behind Super Activations&lt;&#x2F;strong&gt;: The Hadamard product of the &lt;code&gt;gate&lt;&#x2F;code&gt;​ and &lt;code&gt;up&lt;&#x2F;code&gt;​ projection creates a relatively large activation. The super weights further amplify it and create super activations.&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;Gate 指的是对输入信息进行过滤和放缩的操作，假设 &lt;code&gt;A&lt;&#x2F;code&gt;​ 是输入向量；&lt;code&gt;g&lt;&#x2F;code&gt;​ 是与 &lt;code&gt;A&lt;&#x2F;code&gt;​ 等长的门向量，其元素在 &lt;code&gt;0~1&lt;&#x2F;code&gt;​ 之间。那么 gate 操作后的输出为 &lt;code&gt;B = A ⊙ g&lt;&#x2F;code&gt;​，其中 &lt;code&gt;⊙&lt;&#x2F;code&gt;​ 是逐元素（Hadamard）乘法。&lt;&#x2F;p&gt;
&lt;p&gt;虽然经典 Transformer 架构中的 FFN 层没有 gate 层，但是现代 Transformer，如 Llama、Mistral 等模型中有。&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Identifying Super Weight by Activation Spikes&lt;&#x2F;strong&gt;: Super weights can be located by detecting the spikes in the &lt;code&gt;down_proj&lt;&#x2F;code&gt;​ inputs and outputs distributions across the layers. This dectection only requires a single input prompt, rather than a set of validation data or use-case examples.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Identifying Steps&lt;&#x2F;strong&gt;: Let $W \in \mathbb{R}^{D \times H}$ be the &lt;code&gt;down_proj&lt;&#x2F;code&gt;​ weight matrix, where $D$ is the dimension of the activation feature and $H$ is the intermediate hidden dimension. Let $X \in \mathbb{R}^{L \times H}$ be the input matrix, where $L$ is the sequence length. Then the output of &lt;code&gt;down_proj&lt;&#x2F;code&gt;​ is&lt;&#x2F;p&gt;
&lt;p&gt;$$
Y = XW^\top, \quad
\text{where} \quad Y_{ij} = \sum_{k=1}^d X_{ik}W_{jk}.
$$&lt;&#x2F;p&gt;
&lt;p&gt;Suppose $Y_{ij}$ is a super activation, $X_{ik}$ and $W_{jk}$ are outliers, then $Y_{ij} \approx X_{ik}W_{jk}$.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Plot extreme outliers in the input and output activations of &lt;code&gt;mlp.down_proj&lt;&#x2F;code&gt;​.&lt;&#x2F;li&gt;
&lt;li&gt;Determine the layer and coordinates of the super weights.&lt;&#x2F;li&gt;
&lt;li&gt;Remove detected super weights and repeat the above process, until the magnitudes of large maximum activations are greatly suppressed.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;figure&gt;
  &lt;img src=&quot;assets&#x2F;image-20250906111713-x3jh79f.png&quot; alt=&quot;image&quot;&gt;
  &lt;figcaption&gt;How to identify the super weights: The input has a large activation on layer 2. The value&amp;#x27;s channel index tells the row of super weight. The output has a large activation at layer 2. This value&amp;#x27;s channel index gives us the column of the super weight.&lt;&#x2F;figcaption&gt;
&lt;&#x2F;figure&gt;​
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;mechanisms-of-super-weights&quot;&gt;Mechanisms of Super Weights&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;strong&gt;Super Weights (partially) Operate via Super Activations&lt;&#x2F;strong&gt;: We want to assess the super weight’s impact on model quality is solely mediated by super activations or other factors. We conduct experiments under three conditions:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Original model&lt;&#x2F;li&gt;
&lt;li&gt;Remove super weights (Prune SW): Set the weight scalar as zero.&lt;&#x2F;li&gt;
&lt;li&gt;Remove super weights and restore super activation (Prune SW, +SA): Set the weight scalar as zero, and restore super activation at the layer where it first appears.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;The results show that super activations contribute substantially to the model’s performance, they do not fully account for the super weight’s overall influence on quality.&lt;&#x2F;p&gt;
&lt;figure&gt;
  &lt;img src=&quot;assets&#x2F;image-20250906151402-b1r818u.png&quot; alt=&quot;image&quot;&gt;
  &lt;figcaption&gt;Super Weight Importance: &amp;amp;quot;Prune SW&amp;amp;quot; indicates pruning single super weight, &amp;amp;quot;Prune Non-SW&amp;amp;quot; indicates pruning other 7,000 largest-magnitude weights, &amp;amp;quot;Prune SW,+SA&amp;amp;quot; indicates pruning super weight but restoring super activation. The experiment is conducted to assess the model&amp;#x27;s accuracy on seven zero-shot datasets and perplexity on C4 and Wiki-2.&lt;&#x2F;figcaption&gt;
&lt;&#x2F;figure&gt;​
&lt;p&gt;&lt;strong&gt;Super Weights Affect Output Token Probability Distributions&lt;&#x2F;strong&gt;:&lt;&#x2F;p&gt;
&lt;figure&gt;
  &lt;img src=&quot;assets&#x2F;image-20250906153301-pkr83su.png&quot; alt=&quot;image&quot;&gt;
  &lt;figcaption&gt;Super Weights Suppress Stopwords: Removing super weights results in 2 to 5 times larger stopword probabilities, while non-stopwords decrease by 2 to 3 times.&lt;&#x2F;figcaption&gt;
&lt;&#x2F;figure&gt;​
&lt;p&gt;&lt;strong&gt;Sensitivity of Super Weights&lt;&#x2F;strong&gt;: We investigate how does increasing the magnitude of super weights affect model quality.&lt;&#x2F;p&gt;
&lt;figure&gt;
  &lt;img src=&quot;assets&#x2F;image-20250906154045-bid5jgo.png&quot; alt=&quot;image&quot;&gt;
  &lt;figcaption&gt;Amplifying Super Weight Improves Quality: There exists some scaling where quality is improved.&lt;&#x2F;figcaption&gt;
&lt;&#x2F;figure&gt;​
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;super-outlier-aware-quantization&quot;&gt;Super-Outlier Aware Quantization&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;strong&gt;Quantization&lt;&#x2F;strong&gt;: The presence of outliers significantly degrade quantization quality. However, super outliers carry significant importance for model quality, making their preservation during&lt;br &#x2F;&gt;
quantization critical.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Round-to-Nearest Quantization&lt;&#x2F;strong&gt;: Here we consider the asymmetric round-to-nearest quantization&lt;&#x2F;p&gt;
&lt;p&gt;$$
Q(\mathbf{X})=\mathrm{Round}\left(\frac{\mathbf{X}-\mathrm{MIN}(\mathbf{X})}{\Delta}\right),Q^{-1}(\mathbf{\hat{X}})=\Delta\cdot\mathbf{\hat{X}}+\mathrm{MIN}(\mathbf{X})
$$&lt;&#x2F;p&gt;
&lt;p&gt;where $\mathbf{X}$ is the tensor to be quantized, $\mathrm{MIN}(\mathbf{X})$ is the smallest element in $\mathbf{X}$, and $\Delta=\frac{\mathrm{MAX}(\mathbf{X})-\mathrm{MIN}(\mathbf{X})}{2^{N-1}-1}$ is the quantization step with $N$ being the number of bits. So super outliers in $\mathbf{X}$ drastically increase the step size, increasing the quantization error.&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;量化步长 $\Delta$ 衡量了量化后两个相邻离散值之间的距离，可以类比于图像的分辨率。假设 $\mathbf{X}$ 中大部分值都在 $[-1.0, 1.0]$ 区间内，突然出现了一个超大的离群值（outlier），这会导致量化步长 $\Delta$ 激增，从而导致精度下降严重。&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Solution to Outlier Quantization&lt;&#x2F;strong&gt;:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Hold out the super outlier to prevent adverse effects on inlier quantization.&lt;&#x2F;li&gt;
&lt;li&gt;Restore the super outlier’s value after dequantization.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;strong&gt;Activation Quantization&lt;&#x2F;strong&gt;: We replace the super activation with the median, then quantize, dequantize and restore it.&lt;&#x2F;p&gt;
&lt;p&gt;$$
\hat{A}=\mathrm{RESTORE}(Q^{-1}(Q(\mathrm{REPLACE}(A)))
$$&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Weight Quantization&lt;&#x2F;strong&gt;: First, we identify super weights. Second, we clip the outlier weights, quantize, and dequantize the clipped weights. Third, restore the half-precision super weights after dequantization.&lt;&#x2F;p&gt;
&lt;p&gt;$$
\hat{W}=\mathrm{RESTORE}(Q^{-1}(Q(\mathrm{CLIP}_z(W)))
$$&lt;&#x2F;p&gt;
&lt;p&gt;We parameterize clipping using a z-score.&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;z-score 方法来自于统计学，给定一个阈值 &lt;code&gt;z&lt;&#x2F;code&gt;​，其衡量每个元素偏离平均值的程度。一旦某个元素的偏离值超过阈值 &lt;code&gt;z&lt;&#x2F;code&gt;​，则会被视作离群值。上面的 &lt;code&gt;CLIP&lt;&#x2F;code&gt;​ 操作即将离群值裁剪掉。&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;figure&gt;
  &lt;img src=&quot;assets&#x2F;image-20250906175810-cc0bc8e.png&quot; alt=&quot;image&quot;&gt;
  &lt;figcaption&gt;Round-to-nearest with super-activation handling is competitive. Here, &amp;amp;quot;Naive W8A8&amp;amp;quot; indicates the naive round-to-nearest quantification, &amp;amp;quot;SmoothQuant&amp;amp;quot; is an advanced quantification method.&lt;&#x2F;figcaption&gt;
&lt;&#x2F;figure&gt;​
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;experiments&quot;&gt;Experiments&lt;&#x2F;h2&gt;
&lt;p&gt;We first evaluate the perplexity (PPL) of different quantization method for Wiki-2 and C4.&lt;&#x2F;p&gt;
&lt;figure&gt;
  &lt;img src=&quot;assets&#x2F;image-20250906181755-c29ddf6.png&quot; alt=&quot;image&quot;&gt;
  &lt;figcaption&gt;Handling the super activation improves activation quantization: FP16 indicates the un-quantized model.&lt;&#x2F;figcaption&gt;
&lt;&#x2F;figure&gt;​
&lt;p&gt;We also evaluate the accuracy on zero-shot benchmarks.&lt;&#x2F;p&gt;
&lt;figure&gt;
  &lt;img src=&quot;assets&#x2F;image-20250906182114-jbxzt7u.png&quot; alt=&quot;image&quot;&gt;
  &lt;figcaption&gt;Restoring super weight improves block scaling: Here &amp;amp;quot;RTN&amp;amp;quot; refers to &amp;amp;quot;round-to-nearest&amp;amp;quot;.&lt;&#x2F;figcaption&gt;
&lt;&#x2F;figure&gt;​
&lt;blockquote&gt;
&lt;p&gt;Block size 是量化中的一个概念，指的是为了更好地适应 weight tensor 的局部变化，将大的 weight tensor 切割为多个小块独立进行量化&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;大 Block Size：量化粗超，但是高效&lt;&#x2F;li&gt;
&lt;li&gt;小 Block Size：量化精细，但是计算和存储开销大&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;blockquote&gt;
</content>
        </entry>
</feed>
