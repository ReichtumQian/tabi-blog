<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet href="https://reichtumqian.pages.dev/feed_style.xsl" type="text/xsl"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="zh">
    <tabi:metadata xmlns:tabi="https://github.com/welpo/tabi">
        <tabi:base_url>https:&#x2F;&#x2F;reichtumqian.pages.dev</tabi:base_url>
        <tabi:separator>
            •
        </tabi:separator>
        <tabi:about_feeds>This is a web feed, also known as an Atom feed. Subscribe by copying the URL from the address bar into your newsreader</tabi:about_feeds>
        <tabi:visit_the_site>Visit website</tabi:visit_the_site>
        <tabi:recent_posts>Recent posts</tabi:recent_posts>
        <tabi:last_updated_on>Updated on $DATE</tabi:last_updated_on>
        <tabi:default_theme></tabi:default_theme>
        <tabi:post_listing_date>date</tabi:post_listing_date>
        <tabi:current_section>Statistics</tabi:current_section>
    </tabi:metadata><title>Reichtum's Blog - Statistics</title>
        <subtitle>Reichtum&#x27;s Blog</subtitle>
    <link href="https://reichtumqian.pages.dev/tags/statistics/atom.xml" rel="self" type="application/atom+xml"/>
    <link href="https://reichtumqian.pages.dev/tags/statistics/" rel="alternate" type="text/html"/>
    <generator uri="https://www.getzola.org/">Zola</generator><updated>2025-10-12T00:00:00+00:00</updated><id>https://reichtumqian.pages.dev/tags/statistics/atom.xml</id><entry xml:lang="zh">
        <title>期望、方差、协方差</title>
        <published>2025-10-12T00:00:00+00:00</published>
        <updated>2025-10-12T00:00:00+00:00</updated>
        <author>
            <name>Reichtum</name>
        </author>
        <link rel="alternate" href="https://reichtumqian.pages.dev/blog/qi-wang-fang-chai-xie-fang-chai/" type="text/html"/>
        <id>https://reichtumqian.pages.dev/blog/qi-wang-fang-chai-xie-fang-chai/</id>
        
            <content type="html">&lt;p&gt;期望、方差、协方差是统计中的重要概念，在机器学习理论中很常用。&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;sui-ji-bian-liang-de-qi-wang-fang-chai-xie-fang-chai&quot;&gt;随机变量的期望、方差、协方差&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;strong&gt;期望（Expected Value）&lt;&#x2F;strong&gt; ：期望是&lt;u&gt;随机变量的长期平均值&lt;&#x2F;u&gt;。&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;若 $X$ 是离散的，可能的取值为 $x_1, x_2, \cdots$，对应概率为 $P(X = x_i)$，则&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;$$
\mathbb{E}[X]=\sum_ix_iP(X=x_i).
$$&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;若 $X$ 是连续随机变量，其概率密度函数为 $f(x)$，则&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;$$
\mathbb{E}[X]=\int_{-\infty}^{\infty}xf(x)\mathrm{d}x
$$&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;方差（Variance）&lt;&#x2F;strong&gt; ：方差衡量&lt;u&gt;单个随机变量在期望值附近的波动程度&lt;&#x2F;u&gt;，其定义为&lt;&#x2F;p&gt;
&lt;p&gt;$$
Var(X)=\mathbb{E}[(X-\mathbb{E}[X])^2].
$$&lt;&#x2F;p&gt;
&lt;p&gt;更实用的计算公式为&lt;&#x2F;p&gt;
&lt;p&gt;$$
Var(X)=\mathbb{E}[X^2]-(\mathbb{E}[X])^2.
$$&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;协方差（Covariance）&lt;&#x2F;strong&gt; ：协方差衡量两个随机变量之间的线性关系&lt;&#x2F;p&gt;
&lt;p&gt;$$
Cov(X,Y)=\mathbb{E}[(X-\mathbb{E}[X])(Y-\mathbb{E}[Y])]
$$&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;若 $Cov(X,Y) &amp;gt; 0$：$X$ 与 $Y$ 倾向于相同方向变化，当 $X$ 取值大于期望值时，$Y$ 也趋于取值大于期望值。$Cov(X,Y) &amp;lt; 0$ 则刚好相反。&lt;&#x2F;li&gt;
&lt;li&gt;若 $Cov(X,Y) = 0$： 说明 $X$ 和 $Y$ 之间没有线性关系。如果两个随机变量相互独立，则协方差必定为 $0$。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;sui-ji-xiang-liang-de-xie-fang-chai-ju-zhen&quot;&gt;随机向量的协方差矩阵&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;strong&gt;协方差矩阵（Covariance Matrix）&lt;&#x2F;strong&gt; ：给定随机向量 $\mathbf{x} = [X_1, X_2, \cdots, X_n]$，其协方差矩阵衡量了&lt;u&gt;各个元素之间的方差和协方差关系&lt;&#x2F;u&gt;：&lt;&#x2F;p&gt;
&lt;p&gt;$$
\Sigma=\mathbb{E}[(\mathbf{X} - \mathbb{E}(\mathbf{X})(\mathbf{X} - \mathbb{E}(\mathbf{X})^T]
=\mathbb{E}[(\mathbf{X}-\boldsymbol{\mu})(\mathbf{X}-\boldsymbol{\mu})^T]
$$&lt;&#x2F;p&gt;
&lt;p&gt;$$
\Sigma=
\begin{pmatrix}
Var(X_1) &amp;amp; Cov(X_1,X_2) &amp;amp; \cdots &amp;amp; Cov(X_1,X_n) \\
Cov(X_2,X_1) &amp;amp; Var(X_2) &amp;amp; \cdots &amp;amp; Cov(X_2,X_n) \\
\vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\
Cov(X_n,X_1) &amp;amp; Cov(X_n,X_2) &amp;amp; \cdots &amp;amp; Var(X_n)
\end{pmatrix}
$$&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;对角线元素：各个随机变量自身的方差。&lt;&#x2F;li&gt;
&lt;li&gt;非对角线元素：不同变量两两之间的协方差。&lt;&#x2F;li&gt;
&lt;li&gt;对称性：协方差矩阵一定是对称矩阵，且一定是&lt;u&gt;半正定&lt;&#x2F;u&gt;的。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;strong&gt;二次型&lt;&#x2F;strong&gt; &lt;strong&gt;$\mathbf{z}^T \Sigma \mathbf{z}$&lt;&#x2F;strong&gt;：考虑用向量 $\mathbf{z}$ 对随机向量 $X$ 做线性组合，得到新的随机变量 $W$：&lt;&#x2F;p&gt;
&lt;p&gt;$$
W = \mathbf{z}^T \mathbf{X} = z_1X_1 + \cdots + z_nX_n.
$$&lt;&#x2F;p&gt;
&lt;p&gt;此时 $\mathbf{z}^T \Sigma \mathbf{z}$ 恰好表示了 $W$ 的方差 $Var(W)$：&lt;&#x2F;p&gt;
&lt;p&gt;$$
\begin{aligned}
Var(W) &amp;amp; =Var(\mathbf{z}^T\mathbf{X}) \\
&amp;amp; =\mathbb{E}[(\mathbf{z}^T\mathbf{X}-\mathbb{E}[\mathbf{z}^T\mathbf{X}])^2] \\
&amp;amp; =\mathbb{E}[(\mathbf{z}^T\mathbf{X}-\mathbf{z}^T\mathbb{E}[\mathbf{X}])^2] \\
&amp;amp; =\mathbb{E}[(\mathbf{z}^T(\mathbf{X}-\boldsymbol{\mu}))^2] \\
&amp;amp; =\mathbb{E}[\mathbf{z}^T(\mathbf{X}-\boldsymbol{\mu})(\mathbf{X}-\boldsymbol{\mu})^T\mathbf{z}] \\
&amp;amp; =\mathbf{z}^T\mathbb{E}[(\mathbf{X}-\boldsymbol{\mu})(\mathbf{X}-\boldsymbol{\mu})^T]\mathbf{z} \\
&amp;amp; =\mathbf{z}^T\Sigma\mathbf{z}
\end{aligned}
$$&lt;&#x2F;p&gt;
&lt;p&gt;‍&lt;&#x2F;p&gt;
</content>
        </entry><entry xml:lang="zh">
        <title>Approximate KL Divergence using Fisher Information Matrix</title>
        <published>2025-09-18T00:00:00+00:00</published>
        <updated>2025-09-18T00:00:00+00:00</updated>
        <author>
            <name>Reichtum</name>
        </author>
        <link rel="alternate" href="https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/" type="text/html"/>
        <id>https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/</id>
        
            <content type="html">&lt;blockquote&gt;
&lt;p&gt;The proof comes from &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1801.10112&quot;&gt;[1801.10112] Riemannian Walk for Incremental Learning: Understanding Forgetting and Intransigence&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;ji-ben-gai-nian&quot;&gt;基本概念&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;strong&gt;KL 散度&lt;&#x2F;strong&gt;：给定两个分布 $P(x)$ 和 $Q(x)$，它们之间的 KL 散度为&lt;&#x2F;p&gt;
&lt;p&gt;$$
D_{KL}(P || Q) = \mathbb{E}_{x \sim P}[\log P(x) - \log Q(x)].
$$&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;为什么 KL 散度不是两个分布的对数直接减一下？因为信息论中真实分布是 $P$，而我们用 $Q$ 去编码数据，因此需要从 $P$ 中去取数据。&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Fisher 矩阵&lt;&#x2F;strong&gt;：给定概率密度函数 $p(x | \theta)$，Fisher 信息矩阵定义为&lt;&#x2F;p&gt;
&lt;p&gt;$$
F(\theta):=\mathbb{E}_{x\sim p(\cdot\mid\theta)}\Bigg[\left(\frac{\partial}{\partial\theta}\log p(x|\theta)\right)\left(\frac{\partial}{\partial\theta}\log p(x|\theta)\right)^\top\Bigg]
$$&lt;&#x2F;p&gt;
&lt;p&gt;其中 $u_i (x;\theta) :=\frac{\partial}{\partial\theta_i}\log p(x|\theta)$ 为 $\theta_i$ 的 score function。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Fisher 矩阵的对角元&lt;&#x2F;strong&gt;：一般我们假设 score function 的期望为 $0$，即&lt;&#x2F;p&gt;
&lt;p&gt;$$
\mathbb{E}_{x\sim p(\cdot|\theta)}[u_i(x;\theta)]=0.
$$&lt;&#x2F;p&gt;
&lt;p&gt;此时 Fisher 矩阵的对角元素&lt;&#x2F;p&gt;
&lt;p&gt;$$
F_{ii} = \mathbb{E}\left[u_i^2\right] = \mathbb{E} \left[(u_i - \mathbb{E}[u_i])^2 \right] = \operatorname{Var}(u_i).
$$&lt;&#x2F;p&gt;
&lt;p&gt;即表示对于真实数据产生的样本，参数 $\theta_i$ 对对数似然的一阶梯度的方差。&lt;u&gt;如果方差很大，则说明不同样本会给出很不一样的导数信号&lt;&#x2F;u&gt;，也就是 $\theta_i$ 很重要。&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;kl-san-du-yu-fisher-ju-zhen-de-guan-xi&quot;&gt;KL 散度与 Fisher 矩阵的关系&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;strong&gt;使用 Fisher 矩阵逼近 KL 散度&lt;&#x2F;strong&gt;：设 $\Delta \theta \to 0$，则&lt;&#x2F;p&gt;
&lt;p&gt;$$
D_{KL}(p_{\theta}\|p_{\theta+\Delta\theta})\approx\frac{1}{2}\Delta\theta^{\top}F_{\theta}\Delta\theta,
$$&lt;&#x2F;p&gt;
&lt;p&gt;其中 $F_\theta$ 为 $\theta$ 处的 Fisher 矩阵。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;证明&lt;&#x2F;strong&gt;：这里我们记 $p_\theta(\mathbf{z})=p_\theta(\mathbf{y}|\mathbf{x})$ 和 $\mathbb{E}_{\mathbf{z}}[\cdot]=\mathbb{E}_{\mathbf{x}\sim\mathcal{D},\mathbf{y}\sim p_{\theta}(\mathbf{y}|\mathbf{x})}[\cdot]$。根据 KL 散度的定义&lt;&#x2F;p&gt;
&lt;p&gt;$$
D_{KL}(p_{\theta}(\mathbf{z})\|p_{\theta+\Delta\theta}(\mathbf{z}))=\mathbb{E}_{\mathbf{z}}\left[\log p_{\theta}(\mathbf{z})-\log p_{\theta+\Delta\theta}(\mathbf{z})\right].
$$&lt;&#x2F;p&gt;
&lt;p&gt;将 $\log p_{\theta + \Delta \theta}(\mathbf{z})$ 在 $\theta$ 处展开&lt;&#x2F;p&gt;
&lt;p&gt;$$
\log p_{\theta+\Delta\theta}\approx\log p_{\theta}+\Delta\theta^{\top}\frac{\partial\log p_{\theta}}{\partial\theta}+\frac{1}{2}\Delta\theta^{\top}\frac{\partial^{2}\log p_{\theta}}{\partial\theta^{2}}\Delta\theta .
$$&lt;&#x2F;p&gt;
&lt;p&gt;将 $\log p_{\theta+\Delta\theta}$ 的展开式代入到第一个式子，并且消去 $\mathbb{E}_{\mathbf{z}}[\log p_{\theta}(\mathbf{z})]$ 得到&lt;&#x2F;p&gt;
&lt;p&gt;$$
\begin{aligned}
D_{KL}(p_{\theta}\|p_{\theta+\Delta\theta})\approx-:\Delta\theta^\top:\mathbb{E}_\mathbf{z}\left[\frac{\partial\log p_\theta}{\partial\theta}\right]-\frac{1}{2}\Delta\theta^\top:\mathbb{E}_\mathbf{z}\left[\frac{\partial^2\log p_\theta}{\partial\theta^2}\right]\Delta\theta
\end{aligned} \tag{1}
$$&lt;&#x2F;p&gt;
&lt;p&gt;对于 (1) 式右侧第一项，由于 $\mathbf{x} \sim \mathcal{D}$ 以及 $\mathbf{y} \sim p_\theta(\mathbf{y}|\mathbf{x})$，通过计算可以将其消去：&lt;&#x2F;p&gt;
&lt;p&gt;$$
\begin{aligned}\mathbb{E}_{\mathbf{z}}\left[\frac{\partial\log p_{\theta}(\mathbf{z})}{\partial\theta}\right]&amp;amp;=\mathbb{E}_{\mathbf{x}\sim\mathcal{D}}\left[\sum_{\mathbf{y}}p_{\theta}(\mathbf{y}|\mathbf{x})\frac{\partial\log p_{\theta}(\mathbf{y}|\mathbf{x})}{\partial\theta}\right]:,\\&amp;amp;=\mathbb{E}_{\mathbf{x}\sim\mathcal{D}}\left[\sum_{\mathbf{y}}p_{\theta}(\mathbf{y}|\mathbf{x})\frac{1}{p_{\theta}(\mathbf{y}|\mathbf{x})}\frac{\partial p_{\theta}(\mathbf{y}|\mathbf{x})}{\partial\theta}\right]:,\\&amp;amp;=\mathbb{E}_{\mathbf{x}\sim\mathcal{D}}\left[\frac{\partial}{\partial\theta}\sum_{\mathbf{y}}p_{\theta}(\mathbf{y}|\mathbf{x})\right]:,\\&amp;amp;=\mathbb{E}_{\mathbf{x}\sim\mathcal{D}}[0]=0:.\end{aligned} \tag{2}
$$&lt;&#x2F;p&gt;
&lt;p&gt;对于 (1) 式右侧第二项&lt;&#x2F;p&gt;
&lt;p&gt;$$
\frac{\partial^2\log p}{\partial\theta^2}=\frac{\partial}{\partial\theta}\left(\frac{1}{p}\frac{\partial p}{\partial\theta}\right)
\Rightarrow
\frac{\partial^2\log p}{\partial\theta^2}=-\frac{1}{p^2}\frac{\partial p}{\partial\theta}\frac{\partial p}{\partial\theta}^\top+\frac{1}{p}\frac{\partial^2p}{\partial\theta^2}
$$&lt;&#x2F;p&gt;
&lt;p&gt;其中&lt;&#x2F;p&gt;
&lt;p&gt;$$
\frac{1}{p^2}\frac{\partial p}{\partial\theta}\frac{\partial p}{\partial\theta}^\top=\left(\frac{\partial\log p}{\partial\theta}\right)\left(\frac{\partial\log p}{\partial\theta}\right)^\top
$$&lt;&#x2F;p&gt;
&lt;p&gt;因此得到 (1) 式右侧第二项为&lt;&#x2F;p&gt;
&lt;p&gt;$$
\begin{aligned}
&amp;amp; \mathbb{E}_{\mathbf{z}}\left[-\frac{\partial^{2}\operatorname{log}p_{\theta}(\mathbf{z})}{\partial\theta^{2}}\right]=-\mathbb{E}_{\mathbf{z}}\left[\frac{1}{p_{\theta}(\mathbf{z})}\frac{\partial^{2}p_{\theta}(\mathbf{z})}{\partial\theta^{2}}\right] \\
&amp;amp; +\mathbb{E}_{\mathbf{z}}\left[\left(\frac{\partial\log p_\theta(\mathbf{z})}{\partial\theta}\right)\left(\frac{\partial\log p_\theta(\mathbf{z})}{\partial\theta}\right)^\top\right], \\
&amp;amp; =-\mathbb{E}_{\mathbf{z}}\left[\frac{1}{p_{\theta}(\mathbf{z})}\frac{\partial^{2}p_{\theta}(\mathbf{z})}{\partial\theta^{2}}\right]+\tilde{F}_{\theta}.
\end{aligned} \tag{3}
$$&lt;&#x2F;p&gt;
&lt;p&gt;这里 $\tilde{F}_\theta$ 为 True Fisher，其与 Empirical Fisher 的区别在于其期望是取自模型分布 $\mathbf{x} \sim \mathcal{D}$ 以及 $\mathbf{y} \sim p_\theta(\mathbf{y}|\mathbf{x})$ 而非真实分布 $(\mathbf{x}, \mathbf{y}) \sim \mathcal{D}$：&lt;&#x2F;p&gt;
&lt;p&gt;$$
{F}_\theta=\mathbb{E}_{\mathbf{z}\sim p_\theta}
\begin{bmatrix}
g(\mathbf{z};\theta)g(\mathbf{z};\theta)^\top
\end{bmatrix}, \quad
{F}_\theta=\mathbb{E}_{(\mathbf{x},\mathbf{y})\sim\mathcal{D}}\left[g(\mathbf{x},\mathbf{y};\theta)g(\mathbf{x},\mathbf{y};\theta)^\top\right]
$$&lt;&#x2F;p&gt;
&lt;p&gt;仿照 (2) 的推导过程，我们可以得到 (3) 右侧第一项也为 $0$。并且在 optimum 最优点处，模型的分布 $\mathbf{x} \sim \mathcal{D}, \mathbf{y} \sim p_\theta(\mathbf{y}|\mathbf{x})$ 逼近真实分布 $(\mathbf{x}, \mathbf{y}) \sim \mathcal{D}$，此时 $F_\theta = \tilde{F}_\theta$，因此&lt;&#x2F;p&gt;
&lt;p&gt;$$
D_{KL}(p_{\theta}\|p_{\theta+\Delta\theta})\approx \tilde{F}_{\theta} \approx F_\theta.
$$&lt;&#x2F;p&gt;
&lt;p&gt;‍&lt;&#x2F;p&gt;
&lt;p&gt;‍&lt;&#x2F;p&gt;
</content>
        </entry><entry xml:lang="zh">
        <title>先验、后验概率、贝叶斯公式</title>
        <published>2025-09-01T00:00:00+00:00</published>
        <updated>2025-09-01T00:00:00+00:00</updated>
        <author>
            <name>Reichtum</name>
        </author>
        <link rel="alternate" href="https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/" type="text/html"/>
        <id>https://reichtumqian.pages.dev/blog/blog-xian-yan-hou-yan-gai-lu-bei-xie-si-gong-shi/</id>
        
            <content type="html">&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;xian-yan-hou-yan-de-ding-yi&quot;&gt;先验、后验的定义&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;strong&gt;先验概率 Prior Probability&lt;&#x2F;strong&gt;：假设我们观测到数据 $D$，其由事物背后看不见的性质（参数 $\theta$）控制。&lt;em&gt;先验概率&lt;&#x2F;em&gt;指的是在未观测任何数据前，我们对一个参数 $\theta$ 的信念（表现为概率）&lt;&#x2F;p&gt;
&lt;p&gt;$$
P(\theta).
$$&lt;&#x2F;p&gt;
&lt;p&gt;以抛硬币为例，我们让 $\theta$ 表示&lt;u&gt;该硬币朝上的概率&lt;&#x2F;u&gt;（这个是硬币本身的性质，类似于神经网络参数）。我们在没抛任何一枚硬币前，若我们认为该硬币是均匀的概率是 $80\%$​，则我们的先验表达为：&lt;&#x2F;p&gt;
&lt;p&gt;$$
P(\theta = 0.5) = 0.8,
$$&lt;&#x2F;p&gt;
&lt;p&gt;即对于事件&lt;u&gt;硬币朝上概率的概率为 &lt;&#x2F;u&gt;​&lt;u&gt;$50\%$&lt;&#x2F;u&gt;（也就是均匀的）的信任度为 $80\%$​。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;似然 Likelihood&lt;&#x2F;strong&gt;：似然表示我们假设某个参数 $\theta$ 为真的情况下，能观测到数据 $D$ 的概率&lt;&#x2F;p&gt;
&lt;p&gt;$$
P(D | \theta).
$$&lt;&#x2F;p&gt;
&lt;p&gt;例如我们假设硬币是均匀的，即 $\theta = 0.5$，我们观察到抛 $10$ 次出现 $7$ 次正面的现象 $D$ 的概率为&lt;&#x2F;p&gt;
&lt;p&gt;$$
P(D | \theta = 0.5).
$$&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;后验概率 Posterior Probability&lt;&#x2F;strong&gt;：后验概率表示观测到新数据 $D$ 后，我们对参数 $\theta$ 更新后的信念（从先验的主观臆断到后验的数据观测）&lt;&#x2F;p&gt;
&lt;p&gt;$$
P(\theta | D).
$$&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;证据 Evidence &#x2F; 边缘似然 Marginal Likelihood&lt;&#x2F;strong&gt;：对于数据 $D$，我们定义其在所有可能的 $\theta$ 下出现的总概率为 &lt;em&gt;Evidence&lt;&#x2F;em&gt;。在离散情况下&lt;&#x2F;p&gt;
&lt;p&gt;$$
P(D) = \sum P(D|\theta_i) P(\theta_i)
$$&lt;&#x2F;p&gt;
&lt;p&gt;在连续情况下&lt;&#x2F;p&gt;
&lt;p&gt;$$
P(D) = \int P(D|\theta) P(\theta) \mathrm{d}\theta.
$$&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;bei-xie-si-gong-shi&quot;&gt;贝叶斯公式&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;strong&gt;贝叶斯公式&lt;&#x2F;strong&gt;：贝叶斯公式将先验概率、似然、后验概率联系在了一起：&lt;&#x2F;p&gt;
&lt;p&gt;$$
P(\theta|D)=\frac{P(D|\theta)\cdot P(\theta)}{P(D)}
$$&lt;&#x2F;p&gt;
&lt;p&gt;左侧 $P(\theta | D)$ 是后验概率，$P(D|\theta)$ 是似然，$P(\theta)$ 是先验概率，$P(D)$ 是边缘似然。在实际计算中，$P(D)$ 非常难计算，因此我们一般认为&lt;&#x2F;p&gt;
&lt;p&gt;$$
P(\theta|D)\propto P(D|\theta)\cdot P(\theta).
$$&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;投硬币例子&lt;&#x2F;strong&gt;：例如我们对硬币的公平性有所怀疑，提出了两个假设 $\theta_1 = 0.5$ 和 $\theta_2 = 0.8$（表示正面概率）。在没有证据前，我们认为它们都有可能，即&lt;&#x2F;p&gt;
&lt;p&gt;$$
P(\theta = 0.5) = 0.5, \quad P(\theta = 0.8) = 0.5.
$$&lt;&#x2F;p&gt;
&lt;p&gt;然后我们观测到数据 $D$ 为&lt;u&gt;10次抛掷，7次正面&lt;&#x2F;u&gt;。如果 $\theta = 0.5$，那么观测到 $D$ 的概率为&lt;&#x2F;p&gt;
&lt;p&gt;$$
P(D|\theta_1=0.5)=C(10,7)\cdot(0.5)^7(0.5)^3\approx0.117
$$&lt;&#x2F;p&gt;
&lt;p&gt;如果 $\theta = 0.8$，那么观测到 $D$ 的概率为&lt;&#x2F;p&gt;
&lt;p&gt;$$
P(D|\theta_2=0.8)=C(10,7)\cdot(0.8)^7(0.2)^3\approx0.201
$$&lt;&#x2F;p&gt;
&lt;p&gt;因此我们可以得到后验概率&lt;&#x2F;p&gt;
&lt;p&gt;$$
P(\theta_1=0.5|D)\propto0.117\times0.5=0.0585
$$&lt;&#x2F;p&gt;
&lt;p&gt;$$
P(\theta_2=0.8|D)\propto0.201\times0.5=0.1005
$$&lt;&#x2F;p&gt;
&lt;p&gt;由于只有这两种情况，我们不妨做个归一化：$P(D) = 0.0585 + 0.1005 = 0.159$，得到&lt;&#x2F;p&gt;
&lt;p&gt;$$
P(\theta_1=0.5|D)=\frac{0.0585}{0.159}\approx0.368, \quad
P(\theta_2=0.8|D)=\frac{0.1005}{0.159}\approx0.632.
$$&lt;&#x2F;p&gt;
&lt;p&gt;‍&lt;&#x2F;p&gt;
</content>
        </entry><entry xml:lang="zh">
        <title>Fisher 矩阵与弹性权重巩固 Elastic Weight Consolidation, EWC</title>
        <published>2025-09-01T00:00:00+00:00</published>
        <updated>2025-09-01T00:00:00+00:00</updated>
        <author>
            <name>Reichtum</name>
        </author>
        <link rel="alternate" href="https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/" type="text/html"/>
        <id>https://reichtumqian.pages.dev/blog/fisher-ju-zhen-yu-dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc/</id>
        
            <content type="html">&lt;p&gt;‍&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;yu-bei-zhi-shi-si-ran-han-shu&quot;&gt;预备知识：似然函数&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;strong&gt;似然函数&lt;&#x2F;strong&gt;：似然函数 $L(\theta | D)$ 表示在参数为 $\theta$ 的模型下，观测到数据 $D$ 的概率，即&lt;&#x2F;p&gt;
&lt;p&gt;$$
L(\theta|D)=p(D|\theta)=\prod_{i=1}^Np(x_i|\theta).
$$&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;对数似然&lt;&#x2F;strong&gt;：由于似然函数的计算是乘法，有各种各样的问题。我们希望将其转换为加法或者减法，而取对数是一种很自然的想法&lt;&#x2F;p&gt;
&lt;p&gt;$$
\mathcal{L}(\theta|D)=\log L(\theta|D)=\sum_{i=1}^N\log p(x_i|\theta).
$$&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;最大化似然估计 Maximum Likelihood Estimation, MLE&lt;&#x2F;strong&gt;：如果我们能够调整 $\theta$，那么我们肯定希望在 $\theta$ 下观测到 $D$ 的概率越高越好，也就是最大化似然函数&lt;&#x2F;p&gt;
&lt;p&gt;$$
\theta_{MLE}=\arg\max_\theta\mathcal{L}(\theta|D).
$$&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;yu-bei-zhi-shi-score-han-shu&quot;&gt;预备知识：Score 函数&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;strong&gt;Score 函数的定义&lt;&#x2F;strong&gt;：定义 Score 函数为对数似然函数关于 $\theta$ 的梯度，其表示着在&lt;u&gt;当前 &lt;&#x2F;u&gt;​&lt;u&gt;$\theta$&lt;&#x2F;u&gt;​&lt;u&gt; 位置如何调整参数能最快地提高模型对数据的解释能力&lt;&#x2F;u&gt;。&lt;&#x2F;p&gt;
&lt;p&gt;$$
s(\theta) := \nabla_\theta \mathcal{L}(\theta|D)
$$&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Score 函数的期望&lt;&#x2F;strong&gt;：假设数据 $D$ 是由一个真实的参数 $\theta^\ast$ 生成的，那么 Score 函数在该点的期望为零：&lt;&#x2F;p&gt;
&lt;p&gt;$$
\mathbb{E}_{D\sim p(D|\theta^*)}[s(\theta^*)]=0,
$$&lt;&#x2F;p&gt;
&lt;p&gt;需要注意的是，这个期望为 $0$ 是一个关于所有可能数据集的&lt;u&gt;理论平均性质&lt;&#x2F;u&gt;。对于我们手中任何一个具体的数据集 $D$，由于采样的随机性，计算出的 $s(\theta^*)$ 的值几乎总是不为 $0$ 的。&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;fisher-ju-zhen&quot;&gt;Fisher 矩阵&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;strong&gt;Fisher 信息矩阵&lt;&#x2F;strong&gt;：Fisher 信息矩阵量化了&lt;u&gt;数据 &lt;&#x2F;u&gt;​&lt;u&gt;$D$&lt;&#x2F;u&gt;​&lt;u&gt; 中包含了多少模型参数 &lt;&#x2F;u&gt;​&lt;u&gt;$\theta$&lt;&#x2F;u&gt;​&lt;u&gt; 的信息&lt;&#x2F;u&gt;，其有两种等价的定义。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;定义 1. Score 函数的方差&lt;&#x2F;strong&gt;：定义 Fisher 信息矩阵为 Score 函数的协方差矩阵&lt;&#x2F;p&gt;
&lt;p&gt;$$
F(\theta)=\mathbb{E}_{x\sim p(x|\theta)}[s(\theta)s(\theta)^\top]
$$&lt;&#x2F;p&gt;
&lt;p&gt;在实际问题中，对于每个样本的梯度向量 $s_k(\theta)$，我们通过以下公式计算 Fisher 信息矩阵&lt;&#x2F;p&gt;
&lt;p&gt;$$
\hat{F}(\theta)=\frac{1}{N}\sum_{k=1}^Ns_k(\theta)s_k(\theta)^\top
$$&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;定义 2. 对数似然函数 Hessian 矩阵的负期望&lt;&#x2F;strong&gt;：我们也可以用对数似然函数的 Hessian 矩阵的负期望来定义 Fisher 矩阵&lt;&#x2F;p&gt;
&lt;p&gt;$$
F(\theta)=-\mathbb{E}_{x\sim p(x|\theta)}[\nabla_{\theta}^{2}\mathcal{L}(\theta|D)]
$$&lt;&#x2F;p&gt;
&lt;p&gt;在实际计算中，对数据集中每个样本 $x_k$ 计算对数似然的 Hessian 矩阵 $\nabla_\theta^2\mathcal{L}(\theta|x_k)=\nabla_\theta^2\log p(x_k|\theta)$，取负号后求和：&lt;&#x2F;p&gt;
&lt;p&gt;$$
\hat{F}(\theta)=-\frac{1}{N}\sum_{k=1}^{N}\nabla_{\theta}^{2}\log p(x_{k}|\theta)
$$&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Fisher 矩阵元素含义&lt;&#x2F;strong&gt;：Fisher 矩阵的对角元素 $F_{ii}$ 衡量了数据中关于某个参数 $\theta_i$ 的信息量，$F_{ii}$ 越大说明 $\theta_i$ 对模型越重要。非对角元素 $F_{ij}$ 表示了不同参数 $\theta_i$ 和 $\theta_j$ 估计值之间的相关性&#x2F;耦合度。&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;dan-xing-quan-zhong-gong-gu-elastic-weight-consolidation-ewc&quot;&gt;弹性权重巩固 Elastic Weight Consolidation, EWC&lt;&#x2F;h2&gt;
&lt;p&gt;EWC 是一种持续学习算法，其目标是在学习新任务（任务B）时，减缓对旧任务（任务A）知识的遗忘。这里介绍其数学基础与基本想法。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;EWC 核心思想&lt;&#x2F;strong&gt;：对于旧任务（任务A）中越重要的参数，在学习新任务（任务B）时就越要&lt;u&gt;限制它的改动&lt;&#x2F;u&gt;。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;EWC 损失函数&lt;&#x2F;strong&gt;：假设已经完成了任务 A 的训练得到了最优参数 $\theta_A^\ast$。现在要学习任务 B，则 EWC 的损失函数表示为&lt;&#x2F;p&gt;
&lt;p&gt;$$
L(\theta)=L_B(\theta)+\frac{\lambda}{2}\sum_iF_i(\theta_i-\theta_{A,i}^*)^2,
$$&lt;&#x2F;p&gt;
&lt;p&gt;其中 $L_B(\theta)$ 是任务 B 的标准损失函数，$\frac{\lambda}{2}\sum_iF_i(\theta_i-\theta_{A,i}^*)^2$ 是 EWC 增加的&lt;u&gt;正则化惩罚项&lt;&#x2F;u&gt;，$\lambda$ 是正则化参数，$(\theta_i-\theta_{A,i}^*)^2$ 是当前参数 $\theta_i$ 与任务 A 最优参数 $\theta_{A,i}^\ast$ 的二次距离，$F_i$ 是&lt;u&gt;在 &lt;&#x2F;u&gt;​&lt;u&gt;$\theta_{A}^\ast$&lt;&#x2F;u&gt;​&lt;u&gt; 处的 Fisher 矩阵&lt;&#x2F;u&gt;的对角元素，充当了&lt;u&gt;重要性权重&lt;&#x2F;u&gt;。&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;如果参数 $\theta_i$ 对任务 A 很重要（$F_i$ 很大），那么对它的任何改动 $(\theta_i - \theta_{A,i})^2$ 都会被放大，从而产生巨大的惩罚，迫使模型不要轻易改动它。&lt;&#x2F;li&gt;
&lt;li&gt;如果参数 $\theta_i$ 对任务 A 不重要（$F_i$ 很小），惩罚就小，模型可以自由调整它来适应任务 $B$。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;strong&gt;一些疑问和注意点&lt;&#x2F;strong&gt;：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;为什么只用对角元素：由于完整的 Fisher 矩阵过于庞大，EWC 中&lt;u&gt;只使用了 Fisher 矩阵的对角元素&lt;&#x2F;u&gt;以表示重要性，忽略了参数之间的相关性。&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Fisher 矩阵是固定的吗：注意 EWC 使用的 Fisher 矩阵是 $\theta_A^\ast$ 处的，而&lt;u&gt;非每次参数更新时更新&lt;&#x2F;u&gt;的，这样能准确捕捉对 A 任务重要的参数。&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;为什么用 Fisher 矩阵对角而非 Score 函数分量：理想情况下 $\theta_A^\ast$ 处的 Score 函数为 $0$（极值点），而 Fisher 矩阵衡量了&lt;u&gt;不同样本对某个参数的需求&lt;&#x2F;u&gt;，如果 $F_i$ 很大，则稍微一改动，便会影响多个样本的拟合结果。&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;‍&lt;&#x2F;p&gt;
</content>
        </entry><entry xml:lang="zh">
        <title>KL 散度、交叉熵与对数似然</title>
        <published>2025-08-21T00:00:00+00:00</published>
        <updated>2025-08-21T00:00:00+00:00</updated>
        <author>
            <name>Reichtum</name>
        </author>
        <link rel="alternate" href="https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/" type="text/html"/>
        <id>https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/</id>
        
            <content type="html">&lt;h2 id=&quot;kl-san-du&quot;&gt;KL 散度&lt;&#x2F;h2&gt;
&lt;p&gt;KL 散度（Kullback-Leibler Divergence）是一种非对称的度量，用于量化一个概率分布和另一个参考概率分布的差异。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;KL 散度的定义&lt;&#x2F;strong&gt;：给定概率分布 $P(x)$ 和 $Q(x)$，若它们是离散概率分布，则 &lt;em&gt;KL 散度&lt;&#x2F;em&gt;定义为&lt;&#x2F;p&gt;
&lt;p&gt;$$
D_{KL} (P ||Q) := \sum_x P(x) \log \frac{P(x)}{Q(x)}.
$$&lt;&#x2F;p&gt;
&lt;p&gt;若 $P(x)$ 和 $Q(x)$ 是连续概率分布，对应概率密度函数为 $p(x)$ 和 $q(x)$，则 KL 散度为&lt;&#x2F;p&gt;
&lt;p&gt;$$
D_{KL} (P ||Q) := \int_{-\infty}^{\infty} p(x) \log \frac{p(x)}{q(x)} \mathrm{d} x.
$$&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;KL 散度的性质&lt;&#x2F;strong&gt;：KL 散度满足除了对称性外的度量性质&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;非负性：$D_{KL}(P || Q) \geq 0$，且 $D_{KL}(P || Q) = 0$ 当且仅当 $P(x) \equiv Q(x)$。&lt;&#x2F;li&gt;
&lt;li&gt;非对称性：$D_{KL}(P || Q) \neq D_{KL}(Q || P)$。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;strong&gt;KL 散度的信息论解释&lt;&#x2F;strong&gt;：$D_{KL}(P || Q)$ 表示使用 $Q$ 来编码 $P$ 时，平均每个样本所需的额外信息量（比特数）。KL 散度越小，说明 $Q$ 对 $P$ 的近似程度越好，因此&lt;strong&gt;最小化 KL 散度&lt;&#x2F;strong&gt;也是机器学习中常用的优化目标。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;xin-xi-shang-yu-jiao-cha-shang&quot;&gt;信息熵与交叉熵&lt;&#x2F;h2&gt;
&lt;p&gt;信息熵（Information Entropy）用于衡量一个随机变量的不确定性，一个系统越混乱，越不可预测，则其信息熵越高。交叉熵（Cross Entropy）衡量着我们使用&lt;strong&gt;错误的&lt;&#x2F;strong&gt;分布 $Q$ 去衡量真实分布 $P$ 时所需要的平均编码长度。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;信息熵的定义&lt;&#x2F;strong&gt;：信息熵定义为一个随机变量所包含信息的平均期望，给定离散随机变量 $X$，其可取 $x_1, x_2, \cdots, x_n$，对应概率 $P(x_1), P(x_2), \cdots, P(x_n)$，则&lt;em&gt;信息熵&lt;&#x2F;em&gt;定义为&lt;&#x2F;p&gt;
&lt;p&gt;$$
H(x) = - \sum_{i = 1}^n P(x_i) \log_bP(x_i),
$$&lt;&#x2F;p&gt;
&lt;p&gt;其中 $b$ 决定了熵的单位，$b = 2$ 表示 bit，$b=e$ 表示 nat，$b = 10$ 表示 hart。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;交叉熵的定义&lt;&#x2F;strong&gt;：给定概率分布 $P(x)$ 和 $Q(x)$，&lt;em&gt;交叉熵&lt;&#x2F;em&gt;函数为&lt;&#x2F;p&gt;
&lt;p&gt;$$
H(P, Q) := - \sum_xP(x)\log Q(x).
$$&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;交叉熵的信息论理解&lt;&#x2F;strong&gt;：如果 $Q$ 能完美预测真实分布 $P$，那么交叉熵就等于真实分布的信息熵 $H(P)$，此时编码成本最低。如果 $Q$ 的预测非常不准，那么交叉熵就会远大于信息熵。因此在机器学习中我们往往希望&lt;strong&gt;最小化交叉熵&lt;&#x2F;strong&gt;。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;dui-shu-si-ran&quot;&gt;对数似然&lt;&#x2F;h2&gt;
&lt;p&gt;似然函数在统计学中用于&lt;strong&gt;评估模型参数对观测数据的拟合程度&lt;&#x2F;strong&gt;，似然函数越大说明当前模型的参数对观测数据的拟合程度越高。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;似然函数 Likelihood Function&lt;&#x2F;strong&gt;：给定数据集 $X = \{x_1, x_2, \cdots, x_n\}$ 和由参数 $\theta$ 控制的概率模型 $P(X|\theta)$，&lt;em&gt;似然函数&lt;&#x2F;em&gt;定义为：&lt;&#x2F;p&gt;
&lt;p&gt;$$
L(\theta|X) := P(X|\theta) = \prod_{i = 1}^n P(x_i|\theta).
$$&lt;&#x2F;p&gt;
&lt;p&gt;即表示着在 $\theta$ 参数情况下，从概率模型中抽取得到数据集 $X$ 的概率。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;最大化似然估计 MLE&lt;&#x2F;strong&gt;：显然 $L(\theta|X)$ 越大，那么模型就越可能生成当前的数据集，也就是更加贴合数据集。因此一般我们的目标是寻找一组参数 $\hat{\theta}$，使得似然函数最大化&lt;&#x2F;p&gt;
&lt;p&gt;$$
\hat{\theta}_{MLE} = \arg\max_\theta L(\theta|X).
$$&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;对数似然函数 Log-Likelihood Function&lt;&#x2F;strong&gt;：由于似然函数的格式是连乘，在计算上既复杂又容易数值下溢，因此通常会使用&lt;em&gt;对数似然函数 Log-Likelihood Function&lt;&#x2F;em&gt;：&lt;&#x2F;p&gt;
&lt;p&gt;$$
\log L(\theta|X) = \sum_{i = 1}^n \log P(x_i|\theta).
$$&lt;&#x2F;p&gt;
&lt;p&gt;可以看出最大化似然估计也等价于最大化对数似然估计，因此实际优化中一般我们都使用最大对数似然。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;san-zhe-de-guan-xi&quot;&gt;三者的关系&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;strong&gt;KL 散度与交叉熵&lt;&#x2F;strong&gt;：KL 散度为交叉熵与真实分布熵的差，即&lt;&#x2F;p&gt;
&lt;p&gt;$$
D_{KL}(P||Q) = H(P,Q) - H(P).
$$&lt;&#x2F;p&gt;
&lt;p&gt;因此&lt;strong&gt;最小化 KL 散度等价于最小化 Cross-Entropy&lt;&#x2F;strong&gt;，而在计算时由于交叉熵更容易计算，因此通常使用交叉熵函数。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;KL 散度与对数似然&lt;&#x2F;strong&gt;：这里我们假设数据集由数据分布 $P_{\text{data}}(x)$ 生成，分布模型为 $P_{\text{model}}(x|\theta)$，此时&lt;&#x2F;p&gt;
&lt;p&gt;$$
D_{KL}(P_{\text{data}} || P_{\text{model}}) = \sum_{x} P_{\text{data}}(x) \log P_{\text{data}}(x) - \sum_{x} P_{\text{data}}(x)\log P_{\text{model}}(x)
$$&lt;&#x2F;p&gt;
&lt;p&gt;右侧第一项即 $P_{\text{data}}$ 的信息熵，由于 $P_{\text{data}}$ 是固定的，因此此项是一个常数，而第二项即 $P_{\text{data}}$ 和 $P_{\text{model}}$ 的交叉熵。因此&lt;strong&gt;最小化 KL 散度等价于最大化对数似然&lt;&#x2F;strong&gt;。&lt;&#x2F;p&gt;
&lt;p&gt;‍&lt;&#x2F;p&gt;
</content>
        </entry>
</feed>
