<!doctype html><html lang=zh><head><meta charset=UTF-8><meta content="default-src 'self';font-src 'self' data:;img-src 'self' https://* data:;media-src 'self';style-src 'self';frame-src player.vimeo.com https://www.youtube-nocookie.com;connect-src 'self';script-src 'self' 'self'" http-equiv=Content-Security-Policy><meta content="width=device-width,initial-scale=1.0" name=viewport><meta content=https://reichtumqian.pages.dev name=base><title>
Reichtum's Blog • Approximate KL Divergence using Fisher Information Matrix</title><link title="Reichtum's Blog - Atom Feed" href=https://reichtumqian.pages.dev/atom.xml rel=alternate type=application/atom+xml><link href="https://reichtumqian.pages.dev/custom_subset.css?h=0b9535a28bc3d5bf2321" rel=stylesheet><link href="https://reichtumqian.pages.dev/main.css?h=28b3fcbb58f2f22a8c44" rel=stylesheet><meta content="light dark" name=color-scheme><meta content="Reichtum's Blog" name=description><meta content="Reichtum's Blog" property=og:description><meta content="Approximate KL Divergence using Fisher Information Matrix" property=og:title><meta content=article property=og:type><meta content=en_GB property=og:locale><meta content=https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/ property=og:url><meta content="Reichtum's Blog" property=og:site_name><noscript><link href=https://reichtumqian.pages.dev/no_js.css rel=stylesheet></noscript><script src=https://reichtumqian.pages.dev/js/initializeTheme.min.js></script><script defer src=https://reichtumqian.pages.dev/js/themeSwitcher.min.js></script><script src="https://reichtumqian.pages.dev/js/searchElasticlunr.min.js?h=3626c0ef99daa745b31e" defer></script><script defer src=https://reichtumqian.pages.dev/js/lunr/lunrStemmerSupport.min.js></script><script defer src=https://reichtumqian.pages.dev/js/lunr/lunr.zh.min.js></script><body><header><nav class=navbar><div class=nav-title><a class=home-title href=https://reichtumqian.pages.dev/>Reichtum's Blog</a></div><div class=nav-navs><ul><li><a class="nav-links no-hover-padding" href=https://reichtumqian.pages.dev/blog/>blog </a><li><a class="nav-links no-hover-padding" href=https://reichtumqian.pages.dev/archive/>archive </a><li><a class="nav-links no-hover-padding" href=https://reichtumqian.pages.dev/tags/>tags </a><li><a class="nav-links no-hover-padding" href=https://reichtumqian.pages.dev/projects/>projects </a><li class=menu-icons-container><ul class=menu-icons-group><li class="js menu-icon"><div aria-label="Press $SHORTCUT to open search" class="search-icon interactive-icon" title="Press $SHORTCUT to open search" id=search-button role=button tabindex=0><svg viewbox="0 -960 960 960" xmlns=http://www.w3.org/2000/svg><path d="M784-120 532-372q-30 24-69 38t-83 14q-109 0-184.5-75.5T120-580q0-109 75.5-184.5T380-840q109 0 184.5 75.5T640-580q0 44-14 83t-38 69l252 252-56 56ZM380-400q75 0 127.5-52.5T560-580q0-75-52.5-127.5T380-760q-75 0-127.5 52.5T200-580q0 75 52.5 127.5T380-400Z"/></svg></div><li class="theme-switcher-wrapper js"><div aria-label="Toggle dark mode" title="Toggle dark/light mode" aria-pressed=false class=theme-switcher role=button tabindex=0></div><div aria-label="Reset mode to default" class="theme-resetter arrow" title="Reset mode to default" aria-hidden=true role=button tabindex=0></div></ul></ul></div></nav></header><div class=content><main><article class=h-entry><h1 class="p-name article-title">Approximate KL Divergence using Fisher Information Matrix</h1><a class="u-url u-uid" href=https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/></a><ul class=meta><span class="hidden p-author h-card"> <a class=u-url href=https://reichtumqian.pages.dev rel=author title=Reichtum>Reichtum</a> </span><li><time class=dt-published datetime=2025-09-18>18th Sep 2025</time><li title="1148 words"><span aria-hidden=true class=separator>•</span>6 min read<li class=tag><span aria-hidden=true class=separator>•</span>Tags: <li class=tag><a class=p-category href=https://reichtumqian.pages.dev/tags/statistics/>Statistics</a>, <li class=tag><a class=p-category href=https://reichtumqian.pages.dev/tags/machine-learning/>Machine Learning</a></ul><section class="e-content body"><blockquote><p>The proof comes from <a href=https://arxiv.org/abs/1801.10112>[1801.10112] Riemannian Walk for Incremental Learning: Understanding Forgetting and Intransigence</a></blockquote><hr><h2 id=ji-ben-gai-nian>基本概念</h2><p><strong>KL 散度</strong>：给定两个分布 $P(x)$ 和 $Q(x)$，它们之间的 KL 散度为<p>$$ D_{KL}(P || Q) = \mathbb{E}_{x \sim P}[\log P(x) - \log Q(x)]. $$<blockquote><p>为什么 KL 散度不是两个分布的对数直接减一下？因为信息论中真实分布是 $P$，而我们用 $Q$ 去编码数据，因此需要从 $P$ 中去取数据。</blockquote><p><strong>Fisher 矩阵</strong>：给定概率密度函数 $p(x | \theta)$，Fisher 信息矩阵定义为<p>$$ F(\theta):=\mathbb{E}_{x\sim p(\cdot\mid\theta)}\Bigg[\left(\frac{\partial}{\partial\theta}\log p(x|\theta)\right)\left(\frac{\partial}{\partial\theta}\log p(x|\theta)\right)^\top\Bigg] $$<p>其中 $u_i (x;\theta) :=\frac{\partial}{\partial\theta_i}\log p(x|\theta)$ 为 $\theta_i$ 的 score function。<p><strong>Fisher 矩阵的对角元</strong>：一般我们假设 score function 的期望为 $0$，即<p>$$ \mathbb{E}_{x\sim p(\cdot|\theta)}[u_i(x;\theta)]=0. $$<p>此时 Fisher 矩阵的对角元素<p>$$ F_{ii} = \mathbb{E}\left[u_i^2\right] = \mathbb{E} \left[(u_i - \mathbb{E}[u_i])^2 \right] = \operatorname{Var}(u_i). $$<p>即表示对于真实数据产生的样本，参数 $\theta_i$ 对对数似然的一阶梯度的方差。<u>如果方差很大，则说明不同样本会给出很不一样的导数信号</u>，也就是 $\theta_i$ 很重要。<hr><h2 id=kl-san-du-yu-fisher-ju-zhen-de-guan-xi>KL 散度与 Fisher 矩阵的关系</h2><p><strong>使用 Fisher 矩阵逼近 KL 散度</strong>：设 $\Delta \theta \to 0$，则<p>$$ D_{KL}(p_{\theta}\|p_{\theta+\Delta\theta})\approx\frac{1}{2}\Delta\theta^{\top}F_{\theta}\Delta\theta, $$<p>其中 $F_\theta$ 为 $\theta$ 处的 Fisher 矩阵。<p><strong>证明</strong>：这里我们记 $p_\theta(\mathbf{z})=p_\theta(\mathbf{y}|\mathbf{x})$ 和 $\mathbb{E}_{\mathbf{z}}[\cdot]=\mathbb{E}_{\mathbf{x}\sim\mathcal{D},\mathbf{y}\sim p_{\theta}(\mathbf{y}|\mathbf{x})}[\cdot]$。根据 KL 散度的定义<p>$$ D_{KL}(p_{\theta}(\mathbf{z})\|p_{\theta+\Delta\theta}(\mathbf{z}))=\mathbb{E}_{\mathbf{z}}\left[\log p_{\theta}(\mathbf{z})-\log p_{\theta+\Delta\theta}(\mathbf{z})\right]. $$<p>将 $\log p_{\theta + \Delta \theta}(\mathbf{z})$ 在 $\theta$ 处展开<p>$$ \log p_{\theta+\Delta\theta}\approx\log p_{\theta}+\Delta\theta^{\top}\frac{\partial\log p_{\theta}}{\partial\theta}+\frac{1}{2}\Delta\theta^{\top}\frac{\partial^{2}\log p_{\theta}}{\partial\theta^{2}}\Delta\theta . $$<p>将 $\log p_{\theta+\Delta\theta}$ 的展开式代入到第一个式子，并且消去 $\mathbb{E}_{\mathbf{z}}[\log p_{\theta}(\mathbf{z})]$ 得到<p>$$ \begin{aligned} D_{KL}(p_{\theta}\|p_{\theta+\Delta\theta})\approx-:\Delta\theta^\top:\mathbb{E}_\mathbf{z}\left[\frac{\partial\log p_\theta}{\partial\theta}\right]-\frac{1}{2}\Delta\theta^\top:\mathbb{E}_\mathbf{z}\left[\frac{\partial^2\log p_\theta}{\partial\theta^2}\right]\Delta\theta \end{aligned} \tag{1} $$<p>对于 (1) 式右侧第一项，由于 $\mathbf{x} \sim \mathcal{D}$ 以及 $\mathbf{y} \sim p_\theta(\mathbf{y}|\mathbf{x})$，通过计算可以将其消去：<p>$$ \begin{aligned}\mathbb{E}_{\mathbf{z}}\left[\frac{\partial\log p_{\theta}(\mathbf{z})}{\partial\theta}\right]&=\mathbb{E}_{\mathbf{x}\sim\mathcal{D}}\left[\sum_{\mathbf{y}}p_{\theta}(\mathbf{y}|\mathbf{x})\frac{\partial\log p_{\theta}(\mathbf{y}|\mathbf{x})}{\partial\theta}\right]:,\\&=\mathbb{E}_{\mathbf{x}\sim\mathcal{D}}\left[\sum_{\mathbf{y}}p_{\theta}(\mathbf{y}|\mathbf{x})\frac{1}{p_{\theta}(\mathbf{y}|\mathbf{x})}\frac{\partial p_{\theta}(\mathbf{y}|\mathbf{x})}{\partial\theta}\right]:,\\&=\mathbb{E}_{\mathbf{x}\sim\mathcal{D}}\left[\frac{\partial}{\partial\theta}\sum_{\mathbf{y}}p_{\theta}(\mathbf{y}|\mathbf{x})\right]:,\\&=\mathbb{E}_{\mathbf{x}\sim\mathcal{D}}[0]=0:.\end{aligned} \tag{2} $$<p>对于 (1) 式右侧第二项<p>$$ \frac{\partial^2\log p}{\partial\theta^2}=\frac{\partial}{\partial\theta}\left(\frac{1}{p}\frac{\partial p}{\partial\theta}\right) \Rightarrow \frac{\partial^2\log p}{\partial\theta^2}=-\frac{1}{p^2}\frac{\partial p}{\partial\theta}\frac{\partial p}{\partial\theta}^\top+\frac{1}{p}\frac{\partial^2p}{\partial\theta^2} $$<p>其中<p>$$ \frac{1}{p^2}\frac{\partial p}{\partial\theta}\frac{\partial p}{\partial\theta}^\top=\left(\frac{\partial\log p}{\partial\theta}\right)\left(\frac{\partial\log p}{\partial\theta}\right)^\top $$<p>因此得到 (1) 式右侧第二项为<p>$$ \begin{aligned} & \mathbb{E}_{\mathbf{z}}\left[-\frac{\partial^{2}\operatorname{log}p_{\theta}(\mathbf{z})}{\partial\theta^{2}}\right]=-\mathbb{E}_{\mathbf{z}}\left[\frac{1}{p_{\theta}(\mathbf{z})}\frac{\partial^{2}p_{\theta}(\mathbf{z})}{\partial\theta^{2}}\right] \\ & +\mathbb{E}_{\mathbf{z}}\left[\left(\frac{\partial\log p_\theta(\mathbf{z})}{\partial\theta}\right)\left(\frac{\partial\log p_\theta(\mathbf{z})}{\partial\theta}\right)^\top\right], \\ & =-\mathbb{E}_{\mathbf{z}}\left[\frac{1}{p_{\theta}(\mathbf{z})}\frac{\partial^{2}p_{\theta}(\mathbf{z})}{\partial\theta^{2}}\right]+\tilde{F}_{\theta}. \end{aligned} \tag{3} $$<p>这里 $\tilde{F}_\theta$ 为 True Fisher，其与 Empirical Fisher 的区别在于其期望是取自模型分布 $\mathbf{x} \sim \mathcal{D}$ 以及 $\mathbf{y} \sim p_\theta(\mathbf{y}|\mathbf{x})$ 而非真实分布 $(\mathbf{x}, \mathbf{y}) \sim \mathcal{D}$：<p>$$ {F}_\theta=\mathbb{E}_{\mathbf{z}\sim p_\theta} \begin{bmatrix} g(\mathbf{z};\theta)g(\mathbf{z};\theta)^\top \end{bmatrix}, \quad {F}_\theta=\mathbb{E}_{(\mathbf{x},\mathbf{y})\sim\mathcal{D}}\left[g(\mathbf{x},\mathbf{y};\theta)g(\mathbf{x},\mathbf{y};\theta)^\top\right] $$<p>仿照 (2) 的推导过程，我们可以得到 (3) 右侧第一项也为 $0$。并且在 optimum 最优点处，模型的分布 $\mathbf{x} \sim \mathcal{D}, \mathbf{y} \sim p_\theta(\mathbf{y}|\mathbf{x})$ 逼近真实分布 $(\mathbf{x}, \mathbf{y}) \sim \mathcal{D}$，此时 $F_\theta = \tilde{F}_\theta$，因此<p>$$ D_{KL}(p_{\theta}\|p_{\theta+\Delta\theta})\approx \tilde{F}_{\theta} \approx F_\theta. $$<p>‍<p>‍</section></article></main><div id=button-container><div id=toc-floating-container><input class=toggle id=toc-toggle type=checkbox><label class=overlay for=toc-toggle></label><label title="Toggle Table of Contents" class=button for=toc-toggle id=toc-button><svg viewbox="0 -960 960 960" xmlns=http://www.w3.org/2000/svg><path d="M414.82-193.094q-18.044 0-30.497-12.32-12.453-12.319-12.453-30.036t12.453-30.086q12.453-12.37 30.497-12.37h392.767q17.237 0 29.927 12.487 12.69 12.486 12.69 30.203 0 17.716-12.69 29.919t-29.927 12.203H414.82Zm0-244.833q-18.044 0-30.497-12.487Q371.87-462.9 371.87-480.45t12.453-29.92q12.453-12.369 30.497-12.369h392.767q17.237 0 29.927 12.511 12.69 12.512 12.69 29.845 0 17.716-12.69 30.086-12.69 12.37-29.927 12.37H414.82Zm0-245.167q-18.044 0-30.497-12.32t-12.453-30.037q0-17.716 12.453-30.086 12.453-12.369 30.497-12.369h392.767q17.237 0 29.927 12.486 12.69 12.487 12.69 30.203 0 17.717-12.69 29.92-12.69 12.203-29.927 12.203H414.82ZM189.379-156.681q-32.652 0-55.878-22.829t-23.226-55.731q0-32.549 23.15-55.647 23.151-23.097 55.95-23.097 32.799 0 55.313 23.484 22.515 23.484 22.515 56.246 0 32.212-22.861 54.893-22.861 22.681-54.963 22.681Zm0-245.167q-32.652 0-55.878-23.134-23.226-23.135-23.226-55.623 0-32.487 23.467-55.517t56.12-23.03q32.102 0 54.721 23.288 22.62 23.288 22.62 55.775 0 32.488-22.861 55.364-22.861 22.877-54.963 22.877Zm-.82-244.833q-32.224 0-55.254-23.288-23.03-23.289-23.03-55.623 0-32.333 23.271-55.364 23.272-23.03 55.495-23.03 32.224 0 55.193 23.288 22.969 23.289 22.969 55.622 0 32.334-23.21 55.364-23.21 23.031-55.434 23.031Z"/></svg></label><div class=toc-content><div class=toc-container><ul><li><a href=https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/#ji-ben-gai-nian>基本概念</a><li><a href=https://reichtumqian.pages.dev/blog/approximate-kl-divergence-using-fisher-information-matrix/#kl-san-du-yu-fisher-ju-zhen-de-guan-xi>KL 散度与 Fisher 矩阵的关系</a></ul></div></div></div><a title="Go to the top of the page" class=no-hover-padding href=# id=top-button> <svg viewbox="0 0 20 20" fill=currentColor><path d="M3.293 9.707a1 1 0 010-1.414l6-6a1 1 0 011.414 0l6 6a1 1 0 01-1.414 1.414L11 5.414V17a1 1 0 11-2 0V5.414L4.707 9.707a1 1 0 01-1.414 0z"/></svg> </a></div><link href=https://reichtumqian.pages.dev/katex.min.css rel=stylesheet><script defer src=https://reichtumqian.pages.dev/js/katex.min.js></script><span class=hidden id=copy-success> Copied! </span><span class=hidden id=copy-init> Copy code to clipboard </span><script defer src=https://reichtumqian.pages.dev/js/copyCodeToClipboard.min.js></script></div><footer><section><nav class="socials nav-navs"><ul><li><a class="nav-links no-hover-padding social" href=https://reichtumqian.pages.dev/atom.xml> <img alt=feed loading=lazy src=https://reichtumqian.pages.dev/social_icons/rss.svg title=feed> </a></ul></nav><nav class=nav-navs></nav><div class=credits><small> Powered by <a href=https://www.getzola.org>Zola</a> & <a href=https://github.com/welpo/tabi>tabi</a> </small></div></section><div class="search-modal js" aria-labelledby=modalTitle id=searchModal role=dialog><h1 class=visually-hidden id=modalTitle>Search</h1><div id=modal-content><div id=searchBar><div aria-hidden=true class=search-icon><svg viewbox="0 -960 960 960" xmlns=http://www.w3.org/2000/svg><path d="M784-120 532-372q-30 24-69 38t-83 14q-109 0-184.5-75.5T120-580q0-109 75.5-184.5T380-840q109 0 184.5 75.5T640-580q0 44-14 83t-38 69l252 252-56 56ZM380-400q75 0 127.5-52.5T560-580q0-75-52.5-127.5T380-760q-75 0-127.5 52.5T200-580q0 75 52.5 127.5T380-400Z"/></svg></div><input aria-controls=results-container aria-expanded=false autocomplete=off id=searchInput placeholder=Search… role=combobox spellcheck=false><div class="close-icon interactive-icon" title="Clear search" id=clear-search role=button tabindex=0><svg viewbox="0 -960 960 960" xmlns=http://www.w3.org/2000/svg><path d="m256-200-56-56 224-224-224-224 56-56 224 224 224-224 56 56-224 224 224 224-56 56-224-224-224 224Z"/></svg></div></div><div id=results-container><div id=results-info><span id=zero_results> No results</span><span id=one_results> 1 result</span><span id=many_results> $NUMBER results</span><span id=two_results> $NUMBER results</span><span id=few_results> $NUMBER results</span></div><div id=results role=listbox></div></div></div></div></footer>