<!doctype html><html lang=zh><head><meta charset=UTF-8><meta content="default-src 'self';font-src 'self' data:;img-src 'self' https://* data:;media-src 'self';style-src 'self';frame-src player.vimeo.com https://www.youtube-nocookie.com;connect-src 'self';script-src 'self' 'self'" http-equiv=Content-Security-Policy><meta content="width=device-width,initial-scale=1.0" name=viewport><meta content=https://reichtumqian.pages.dev name=base><title>
Reichtum's Blog • KL 散度、交叉熵与对数似然</title><link title="Reichtum's Blog - Atom Feed" href=https://reichtumqian.pages.dev/atom.xml rel=alternate type=application/atom+xml><link href="https://reichtumqian.pages.dev/custom_subset.css?h=0b9535a28bc3d5bf2321" rel=stylesheet><link href="https://reichtumqian.pages.dev/main.css?h=28b3fcbb58f2f22a8c44" rel=stylesheet><meta content="light dark" name=color-scheme><meta content="Reichtum's Blog" name=description><meta content="Reichtum's Blog" property=og:description><meta content="KL 散度、交叉熵与对数似然" property=og:title><meta content=article property=og:type><meta content=en_GB property=og:locale><meta content=https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/ property=og:url><meta content="Reichtum's Blog" property=og:site_name><noscript><link href=https://reichtumqian.pages.dev/no_js.css rel=stylesheet></noscript><script src=https://reichtumqian.pages.dev/js/initializeTheme.min.js></script><script defer src=https://reichtumqian.pages.dev/js/themeSwitcher.min.js></script><script src="https://reichtumqian.pages.dev/js/searchElasticlunr.min.js?h=3626c0ef99daa745b31e" defer></script><script defer src=https://reichtumqian.pages.dev/js/lunr/lunrStemmerSupport.min.js></script><script defer src=https://reichtumqian.pages.dev/js/lunr/lunr.zh.min.js></script><body><header><nav class=navbar><div class=nav-title><a class=home-title href=https://reichtumqian.pages.dev/>Reichtum's Blog</a></div><div class=nav-navs><ul><li><a class="nav-links no-hover-padding" href=https://reichtumqian.pages.dev/blog/>blog </a><li><a class="nav-links no-hover-padding" href=https://reichtumqian.pages.dev/archive/>archive </a><li><a class="nav-links no-hover-padding" href=https://reichtumqian.pages.dev/tags/>tags </a><li><a class="nav-links no-hover-padding" href=https://reichtumqian.pages.dev/projects/>projects </a><li class=menu-icons-container><ul class=menu-icons-group><li class="js menu-icon"><div aria-label="Press $SHORTCUT to open search" class="search-icon interactive-icon" title="Press $SHORTCUT to open search" id=search-button role=button tabindex=0><svg viewbox="0 -960 960 960" xmlns=http://www.w3.org/2000/svg><path d="M784-120 532-372q-30 24-69 38t-83 14q-109 0-184.5-75.5T120-580q0-109 75.5-184.5T380-840q109 0 184.5 75.5T640-580q0 44-14 83t-38 69l252 252-56 56ZM380-400q75 0 127.5-52.5T560-580q0-75-52.5-127.5T380-760q-75 0-127.5 52.5T200-580q0 75 52.5 127.5T380-400Z"/></svg></div><li class="theme-switcher-wrapper js"><div aria-label="Toggle dark mode" title="Toggle dark/light mode" aria-pressed=false class=theme-switcher role=button tabindex=0></div><div aria-label="Reset mode to default" class="theme-resetter arrow" title="Reset mode to default" aria-hidden=true role=button tabindex=0></div></ul></ul></div></nav></header><div class=content><main><article class=h-entry><h1 class="p-name article-title">KL 散度、交叉熵与对数似然</h1><a class="u-url u-uid" href=https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/></a><ul class=meta><span class="hidden p-author h-card"> <a class=u-url href=https://reichtumqian.pages.dev rel=author title=Reichtum>Reichtum</a> </span><li><time class=dt-published datetime=2025-08-21>21st Aug 2025</time><li title="1129 words"><span aria-hidden=true class=separator>•</span>6 min read<li class=tag><span aria-hidden=true class=separator>•</span>Tags: <li class=tag><a class=p-category href=https://reichtumqian.pages.dev/tags/machine-learning/>Machine Learning</a>, <li class=tag><a class=p-category href=https://reichtumqian.pages.dev/tags/statistics/>Statistics</a></ul><section class="e-content body"><h2 id=kl-san-du>KL 散度</h2><p>KL 散度（Kullback-Leibler Divergence）是一种非对称的度量，用于量化一个概率分布和另一个参考概率分布的差异。<p><strong>KL 散度的定义</strong>：给定概率分布 $P(x)$ 和 $Q(x)$，若它们是离散概率分布，则 <em>KL 散度</em>定义为<p>$$ D_{KL} (P ||Q) := \sum_x P(x) \log \frac{P(x)}{Q(x)}. $$<p>若 $P(x)$ 和 $Q(x)$ 是连续概率分布，对应概率密度函数为 $p(x)$ 和 $q(x)$，则 KL 散度为<p>$$ D_{KL} (P ||Q) := \int_{-\infty}^{\infty} p(x) \log \frac{p(x)}{q(x)} \mathrm{d} x. $$<p><strong>KL 散度的性质</strong>：KL 散度满足除了对称性外的度量性质<ul><li>非负性：$D_{KL}(P || Q) \geq 0$，且 $D_{KL}(P || Q) = 0$ 当且仅当 $P(x) \equiv Q(x)$。<li>非对称性：$D_{KL}(P || Q) \neq D_{KL}(Q || P)$。</ul><p><strong>KL 散度的信息论解释</strong>：$D_{KL}(P || Q)$ 表示使用 $Q$ 来编码 $P$ 时，平均每个样本所需的额外信息量（比特数）。KL 散度越小，说明 $Q$ 对 $P$ 的近似程度越好，因此<strong>最小化 KL 散度</strong>也是机器学习中常用的优化目标。<h2 id=xin-xi-shang-yu-jiao-cha-shang>信息熵与交叉熵</h2><p>信息熵（Information Entropy）用于衡量一个随机变量的不确定性，一个系统越混乱，越不可预测，则其信息熵越高。交叉熵（Cross Entropy）衡量着我们使用<strong>错误的</strong>分布 $Q$ 去衡量真实分布 $P$ 时所需要的平均编码长度。<p><strong>信息熵的定义</strong>：信息熵定义为一个随机变量所包含信息的平均期望，给定离散随机变量 $X$，其可取 $x_1, x_2, \cdots, x_n$，对应概率 $P(x_1), P(x_2), \cdots, P(x_n)$，则<em>信息熵</em>定义为<p>$$ H(x) = - \sum_{i = 1}^n P(x_i) \log_bP(x_i), $$<p>其中 $b$ 决定了熵的单位，$b = 2$ 表示 bit，$b=e$ 表示 nat，$b = 10$ 表示 hart。<p><strong>交叉熵的定义</strong>：给定概率分布 $P(x)$ 和 $Q(x)$，<em>交叉熵</em>函数为<p>$$ H(P, Q) := - \sum_xP(x)\log Q(x). $$<p><strong>交叉熵的信息论理解</strong>：如果 $Q$ 能完美预测真实分布 $P$，那么交叉熵就等于真实分布的信息熵 $H(P)$，此时编码成本最低。如果 $Q$ 的预测非常不准，那么交叉熵就会远大于信息熵。因此在机器学习中我们往往希望<strong>最小化交叉熵</strong>。<h2 id=dui-shu-si-ran>对数似然</h2><p>似然函数在统计学中用于<strong>评估模型参数对观测数据的拟合程度</strong>，似然函数越大说明当前模型的参数对观测数据的拟合程度越高。<p><strong>似然函数 Likelihood Function</strong>：给定数据集 $X = \{x_1, x_2, \cdots, x_n\}$ 和由参数 $\theta$ 控制的概率模型 $P(X|\theta)$，<em>似然函数</em>定义为：<p>$$ L(\theta|X) := P(X|\theta) = \prod_{i = 1}^n P(x_i|\theta). $$<p>即表示着在 $\theta$ 参数情况下，从概率模型中抽取得到数据集 $X$ 的概率。<p><strong>最大化似然估计 MLE</strong>：显然 $L(\theta|X)$ 越大，那么模型就越可能生成当前的数据集，也就是更加贴合数据集。因此一般我们的目标是寻找一组参数 $\hat{\theta}$，使得似然函数最大化<p>$$ \hat{\theta}_{MLE} = \arg\max_\theta L(\theta|X). $$<p><strong>对数似然函数 Log-Likelihood Function</strong>：由于似然函数的格式是连乘，在计算上既复杂又容易数值下溢，因此通常会使用<em>对数似然函数 Log-Likelihood Function</em>：<p>$$ \log L(\theta|X) = \sum_{i = 1}^n \log P(x_i|\theta). $$<p>可以看出最大化似然估计也等价于最大化对数似然估计，因此实际优化中一般我们都使用最大对数似然。<h2 id=san-zhe-de-guan-xi>三者的关系</h2><p><strong>KL 散度与交叉熵</strong>：KL 散度为交叉熵与真实分布熵的差，即<p>$$ D_{KL}(P||Q) = H(P,Q) - H(P). $$<p>因此<strong>最小化 KL 散度等价于最小化 Cross-Entropy</strong>，而在计算时由于交叉熵更容易计算，因此通常使用交叉熵函数。<p><strong>KL 散度与对数似然</strong>：这里我们假设数据集由数据分布 $P_{\text{data}}(x)$ 生成，分布模型为 $P_{\text{model}}(x|\theta)$，此时<p>$$ D_{KL}(P_{\text{data}} || P_{\text{model}}) = \sum_{x} P_{\text{data}}(x) \log P_{\text{data}}(x) - \sum_{x} P_{\text{data}}(x)\log P_{\text{model}}(x) $$<p>右侧第一项即 $P_{\text{data}}$ 的信息熵，由于 $P_{\text{data}}$ 是固定的，因此此项是一个常数，而第二项即 $P_{\text{data}}$ 和 $P_{\text{model}}$ 的交叉熵。因此<strong>最小化 KL 散度等价于最大化对数似然</strong>。<p>‍</section></article></main><div id=button-container><div id=toc-floating-container><input class=toggle id=toc-toggle type=checkbox><label class=overlay for=toc-toggle></label><label title="Toggle Table of Contents" class=button for=toc-toggle id=toc-button><svg viewbox="0 -960 960 960" xmlns=http://www.w3.org/2000/svg><path d="M414.82-193.094q-18.044 0-30.497-12.32-12.453-12.319-12.453-30.036t12.453-30.086q12.453-12.37 30.497-12.37h392.767q17.237 0 29.927 12.487 12.69 12.486 12.69 30.203 0 17.716-12.69 29.919t-29.927 12.203H414.82Zm0-244.833q-18.044 0-30.497-12.487Q371.87-462.9 371.87-480.45t12.453-29.92q12.453-12.369 30.497-12.369h392.767q17.237 0 29.927 12.511 12.69 12.512 12.69 29.845 0 17.716-12.69 30.086-12.69 12.37-29.927 12.37H414.82Zm0-245.167q-18.044 0-30.497-12.32t-12.453-30.037q0-17.716 12.453-30.086 12.453-12.369 30.497-12.369h392.767q17.237 0 29.927 12.486 12.69 12.487 12.69 30.203 0 17.717-12.69 29.92-12.69 12.203-29.927 12.203H414.82ZM189.379-156.681q-32.652 0-55.878-22.829t-23.226-55.731q0-32.549 23.15-55.647 23.151-23.097 55.95-23.097 32.799 0 55.313 23.484 22.515 23.484 22.515 56.246 0 32.212-22.861 54.893-22.861 22.681-54.963 22.681Zm0-245.167q-32.652 0-55.878-23.134-23.226-23.135-23.226-55.623 0-32.487 23.467-55.517t56.12-23.03q32.102 0 54.721 23.288 22.62 23.288 22.62 55.775 0 32.488-22.861 55.364-22.861 22.877-54.963 22.877Zm-.82-244.833q-32.224 0-55.254-23.288-23.03-23.289-23.03-55.623 0-32.333 23.271-55.364 23.272-23.03 55.495-23.03 32.224 0 55.193 23.288 22.969 23.289 22.969 55.622 0 32.334-23.21 55.364-23.21 23.031-55.434 23.031Z"/></svg></label><div class=toc-content><div class=toc-container><ul><li><a href=https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/#kl-san-du>KL 散度</a><li><a href=https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/#xin-xi-shang-yu-jiao-cha-shang>信息熵与交叉熵</a><li><a href=https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/#dui-shu-si-ran>对数似然</a><li><a href=https://reichtumqian.pages.dev/blog/blog-kl-san-du-jiao-cha-shang-yu-dui-shu-si-ran/#san-zhe-de-guan-xi>三者的关系</a></ul></div></div></div><a title="Go to the top of the page" class=no-hover-padding href=# id=top-button> <svg viewbox="0 0 20 20" fill=currentColor><path d="M3.293 9.707a1 1 0 010-1.414l6-6a1 1 0 011.414 0l6 6a1 1 0 01-1.414 1.414L11 5.414V17a1 1 0 11-2 0V5.414L4.707 9.707a1 1 0 01-1.414 0z"/></svg> </a></div><link href=https://reichtumqian.pages.dev/katex.min.css rel=stylesheet><script defer src=https://reichtumqian.pages.dev/js/katex.min.js></script><span class=hidden id=copy-success> Copied! </span><span class=hidden id=copy-init> Copy code to clipboard </span><script defer src=https://reichtumqian.pages.dev/js/copyCodeToClipboard.min.js></script></div><footer><section><nav class="socials nav-navs"><ul><li><a class="nav-links no-hover-padding social" href=https://reichtumqian.pages.dev/atom.xml> <img alt=feed loading=lazy src=https://reichtumqian.pages.dev/social_icons/rss.svg title=feed> </a></ul></nav><nav class=nav-navs></nav><div class=credits><small> Powered by <a href=https://www.getzola.org>Zola</a> & <a href=https://github.com/welpo/tabi>tabi</a> </small></div></section><div class="search-modal js" aria-labelledby=modalTitle id=searchModal role=dialog><h1 class=visually-hidden id=modalTitle>Search</h1><div id=modal-content><div id=searchBar><div aria-hidden=true class=search-icon><svg viewbox="0 -960 960 960" xmlns=http://www.w3.org/2000/svg><path d="M784-120 532-372q-30 24-69 38t-83 14q-109 0-184.5-75.5T120-580q0-109 75.5-184.5T380-840q109 0 184.5 75.5T640-580q0 44-14 83t-38 69l252 252-56 56ZM380-400q75 0 127.5-52.5T560-580q0-75-52.5-127.5T380-760q-75 0-127.5 52.5T200-580q0 75 52.5 127.5T380-400Z"/></svg></div><input aria-controls=results-container aria-expanded=false autocomplete=off id=searchInput placeholder=Search… role=combobox spellcheck=false><div class="close-icon interactive-icon" title="Clear search" id=clear-search role=button tabindex=0><svg viewbox="0 -960 960 960" xmlns=http://www.w3.org/2000/svg><path d="m256-200-56-56 224-224-224-224 56-56 224 224 224-224 56 56-224 224 224 224-56 56-224-224-224 224Z"/></svg></div></div><div id=results-container><div id=results-info><span id=zero_results> No results</span><span id=one_results> 1 result</span><span id=many_results> $NUMBER results</span><span id=two_results> $NUMBER results</span><span id=few_results> $NUMBER results</span></div><div id=results role=listbox></div></div></div></div></footer>