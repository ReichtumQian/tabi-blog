+++

title = "期望、方差、协方差"

date = "2025-10-12"

[taxonomies]

tags = ["Statistics"]

+++

期望、方差、协方差是统计中的重要概念，在机器学习理论中很常用。

---

## 随机变量的期望、方差、协方差

**期望（Expected Value）** ：期望是<u>随机变量的长期平均值</u>。

- 若 $X$ 是离散的，可能的取值为 $x_1, x_2, \cdots$，对应概率为 $P(X = x_i)$，则

$$
\mathbb{E}[X]=\sum_ix_iP(X=x_i).
$$

- 若 $X$ 是连续随机变量，其概率密度函数为 $f(x)$，则

$$
\mathbb{E}[X]=\int_{-\infty}^{\infty}xf(x)\mathrm{d}x
$$

**方差（Variance）** ：方差衡量<u>单个随机变量在期望值附近的波动程度</u>，其定义为

$$
Var(X)=\mathbb{E}[(X-\mathbb{E}[X])^2].
$$

更实用的计算公式为

$$
Var(X)=\mathbb{E}[X^2]-(\mathbb{E}[X])^2.
$$

**协方差（Covariance）** ：协方差衡量两个随机变量之间的线性关系

$$
Cov(X,Y)=\mathbb{E}[(X-\mathbb{E}[X])(Y-\mathbb{E}[Y])]
$$

- 若 $Cov(X,Y) > 0$：$X$ 与 $Y$ 倾向于相同方向变化，当 $X$ 取值大于期望值时，$Y$ 也趋于取值大于期望值。$Cov(X,Y) < 0$ 则刚好相反。
- 若 $Cov(X,Y) = 0$： 说明 $X$ 和 $Y$ 之间没有线性关系。如果两个随机变量相互独立，则协方差必定为 $0$。

---

## 随机向量的协方差矩阵

**协方差矩阵（Covariance Matrix）** ：给定随机向量 $\mathbf{x} = [X_1, X_2, \cdots, X_n]$，其协方差矩阵衡量了<u>各个元素之间的方差和协方差关系</u>：

$$
\Sigma=\mathbb{E}[(\mathbf{X} - \mathbb{E}(\mathbf{X})(\mathbf{X} - \mathbb{E}(\mathbf{X})^T]
=\mathbb{E}[(\mathbf{X}-\boldsymbol{\mu})(\mathbf{X}-\boldsymbol{\mu})^T]
$$

$$
\Sigma=
\begin{pmatrix}
Var(X_1) & Cov(X_1,X_2) & \cdots & Cov(X_1,X_n) \\
Cov(X_2,X_1) & Var(X_2) & \cdots & Cov(X_2,X_n) \\
\vdots & \vdots & \ddots & \vdots \\
Cov(X_n,X_1) & Cov(X_n,X_2) & \cdots & Var(X_n)
\end{pmatrix}
$$

- 对角线元素：各个随机变量自身的方差。
- 非对角线元素：不同变量两两之间的协方差。
- 对称性：协方差矩阵一定是对称矩阵，且一定是<u>半正定</u>的。

**二次型** **$\mathbf{z}^T \Sigma \mathbf{z}$**：考虑用向量 $\mathbf{z}$ 对随机向量 $X$ 做线性组合，得到新的随机变量 $W$：

$$
W = \mathbf{z}^T \mathbf{X} = z_1X_1 + \cdots + z_nX_n.
$$

此时 $\mathbf{z}^T \Sigma \mathbf{z}$ 恰好表示了 $W$ 的方差 $Var(W)$：

$$
\begin{aligned}
Var(W) & =Var(\mathbf{z}^T\mathbf{X}) \\
 & =\mathbb{E}[(\mathbf{z}^T\mathbf{X}-\mathbb{E}[\mathbf{z}^T\mathbf{X}])^2] \\
 & =\mathbb{E}[(\mathbf{z}^T\mathbf{X}-\mathbf{z}^T\mathbb{E}[\mathbf{X}])^2] \\
 & =\mathbb{E}[(\mathbf{z}^T(\mathbf{X}-\boldsymbol{\mu}))^2] \\
 & =\mathbb{E}[\mathbf{z}^T(\mathbf{X}-\boldsymbol{\mu})(\mathbf{X}-\boldsymbol{\mu})^T\mathbf{z}] \\
 & =\mathbf{z}^T\mathbb{E}[(\mathbf{X}-\boldsymbol{\mu})(\mathbf{X}-\boldsymbol{\mu})^T]\mathbf{z} \\
 & =\mathbf{z}^T\Sigma\mathbf{z}
\end{aligned}
$$

‍
